"""
í˜ë¥´ì†Œë‚˜ ìƒì„± ë° LLM ê´€ë ¨ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
"""
from typing import List
from openai import OpenAI
from models import (
    TargetCustomer, PersonaData, UserVideoInput,
    ReferenceImage, SceneImagePrompt, StoryboardScene, StoryboardOutput
)
import os
from dotenv import load_dotenv
import asyncio

# LangChain imports
# ì¶œë ¥ êµ¬ì¡° ì •í™•í•˜ê²Œ ë‚˜ì˜¤ê²Œ í•˜ê¸° ìœ„í•œ outputparser
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
# OpenAI ì±„íŒ… ëª¨ë¸ìš© Runnable ë¸”ë¡ - Runnable ê·œê²© ë•ë¶„ì— invoke / ainvoke / batch / streamì´ ê¸°ë³¸ íƒ‘ì¬ë˜ì–´, ë‹¤ë¥¸ LangChain êµ¬ì„±ìš”ì†Œì™€ ë°”ë¡œ ì´ì–´ ë¶™ì—¬ ì“¸ ìˆ˜ ìˆìŒ
from langchain_openai import ChatOpenAI
# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
OpenAI_API_KEY = os.getenv("OPENAI_API_KEY")
# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ê¸°ì¡´ í˜¸í™˜ì„±ìš©)
client = OpenAI(api_key=OpenAI_API_KEY)
# LangChain ChatOpenAI ì´ˆê¸°í™”
llm = ChatOpenAI(
    model="gpt-4.1-nano-2025-04-14",
    openai_api_key=OpenAI_API_KEY
)

# ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ì¸í„°í˜ì´ìŠ¤
async def get_trend_data(country: str, gender: str, age_range: List[str], interests: List[str]) -> dict:
    """
    ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íƒ€ê²Ÿ ê³ ê°ì— ë§ëŠ” íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¸í„°í˜ì´ìŠ¤
    
    Args:
        country: êµ­ê°€ ì •ë³´
        gender: ì„±ë³„
        age_range: ì—°ë ¹ëŒ€ ë¦¬ìŠ¤íŠ¸ 
        interests: ê´€ì‹¬ì‚¬ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        dict: íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¨ íŠ¸ë Œë“œ ë°ì´í„°
        
    Note:
        í˜„ì¬ëŠ” ë¹ˆ dict ë°˜í™˜. ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ API ì—°ë™ ì‹œ ì´ í•¨ìˆ˜ ë‚´ìš©ë§Œ êµì²´í•˜ë©´ ë¨.
    """
    print(f"ğŸ“Š íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ëŒ€ê¸° ì¤‘... (íƒ€ê²Ÿ: {country} {gender} {age_range} {interests})")
    
    # TODO: ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ API í˜¸ì¶œ ë¡œì§ìœ¼ë¡œ êµì²´
    # ì˜ˆì‹œ: 
    # async with httpx.AsyncClient() as client:
    #     response = await client.post("https://trend-db-api.com/query", json={
    #         "country": country, "gender": gender, "age_range": age_range, "interests": interests
    #     })
    #     return response.json()
    
    # í˜„ì¬ëŠ” ë¹ˆ ë°ì´í„° ë°˜í™˜ (LLMì´ ìì²´ íŒë‹¨ìœ¼ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„±í•˜ë„ë¡)
    return {}
# ==================================================================================

"""
    ì‚¬ìš©ì ì…ë ¥ 1ë‹¨ê³„ : LangChainê³¼ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ í™œìš©í•œ ì •êµí•œ íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ ìƒì„±
    1. ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ì¡°íšŒ
    2. LangChain OutputParserë¡œ êµ¬ì¡°í™”ëœ í˜ë¥´ì†Œë‚˜ ìƒì„±
    3. íŠ¸ë Œë“œ ë°ì´í„° ì—†ì„ ì‹œ LLMì´ ìì²´ íŒë‹¨ìœ¼ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„±
"""
async def generate_persona(customer: TargetCustomer) -> PersonaData:
    age_ranges_str = ", ".join(customer.age_range)
    interests_str = ", ".join(customer.interests)
    
    # 1ë‹¨ê³„: ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ì¡°íšŒ
    print("ğŸ“Š íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤...") # ë””ë²„ê¹…ìš©
    trend_data = await get_trend_data(
        country=customer.country,
        gender=customer.gender,
        age_range=customer.age_range,
        interests=customer.interests
    )
    
    # íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§¤íŒ… (ë¹ˆ ë°ì´í„°ì¸ ê²½ìš° "ë°ì´í„° ì—†ìŒ" í‘œì‹œ)
    import json
    if trend_data:
        trend_data_str = json.dumps(trend_data, indent=2, ensure_ascii=False)
        print("ğŸ“ˆ íŠ¸ë Œë“œ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ")
    else:
        trend_data_str = "í˜„ì¬ íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”."
        print("ğŸ“ˆ íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ - LLM ìì²´ íŒë‹¨ìœ¼ë¡œ ì§„í–‰")
    
    # 2ë‹¨ê³„: LangChain OutputParser ì„¤ì •
    parser = PydanticOutputParser(pydantic_object=PersonaData)
    
    # 3ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
    prompt = PromptTemplate(
        template="""
ë‹¹ì‹ ì€ ìµœì‹  íŠ¸ë Œë“œì— ì •í†µí•œ ì „ë¬¸ ë§ˆì¼€í„°ì´ì ì†Œë¹„ì ì‹¬ë¦¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ íƒ€ê²Ÿ ê³ ê° ì •ë³´ì™€ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬, ê´‘ê³  ìº í˜ì¸ì— ì§ì ‘ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‚´ì•„ìˆëŠ” í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

### íƒ€ê²Ÿ ê³ ê° ì •ë³´
- êµ­ê°€/ë¬¸í™”: {country}
- ì—°ë ¹ëŒ€: {age_ranges}
- ì„±ë³„: {gender}
- ì–¸ì–´/ë¬¸í™”ê¶Œ: {language}
- ê´€ì‹¬ì‚¬: {interests}

### íŠ¸ë Œë“œ ë°ì´í„°
{trend_data}

### ìƒì„± ì§€ì¹¨
**ì¤‘ìš”**: íŠ¸ë Œë“œ ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë¶€ì¡±í•œ ê²½ìš°, ë‹¹ì‹ ì˜ ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ íƒ€ê²Ÿ ê³ ê°ì¸µì˜ ì¼ë°˜ì ì¸ íŠ¹ì„±ì„ ë¶„ì„í•˜ì—¬ í˜ë¥´ì†Œë‚˜ë¥¼ êµ¬ì„±í•˜ì„¸ìš”.

ì‘ë‹µì€ ë‹¤ìŒ ë‘ ë¶€ë¶„ìœ¼ë¡œ ëª…í™•íˆ ë¶„ë¦¬í•´ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. **persona_description**: êµ¬ì²´ì ì¸ í˜ë¥´ì†Œë‚˜ ì„¤ëª…
   - ì´ë¦„, ë‚˜ì´, ì§ì—… ë“± ê¸°ë³¸ ì •ë³´
   - ë¼ì´í”„ìŠ¤íƒ€ì¼ê³¼ ê°€ì¹˜ê´€
   - ì†Œë¹„ íŒ¨í„´ê³¼ ë¯¸ë””ì–´ ì´ìš© ìŠµê´€
   - ì¼ìƒì ì¸ í–‰ë™ê³¼ ê´€ì‹¬ì‚¬

2. **marketing_insights**: ì´ í˜ë¥´ì†Œë‚˜ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•œ ë§ˆì¼€íŒ… ì „ëµ
   - íš¨ê³¼ì ì¸ ê´‘ê³  ë©”ì‹œì§€ ë°©í–¥ì„±
   - ì„ í˜¸í•˜ëŠ” ê´‘ê³  í˜•ì‹
   - êµ¬ë§¤ ê²°ì • ìš”ì¸ê³¼ ë™ê¸°
   - ì£¼ì˜í•´ì•¼ í•  ë§ˆì¼€íŒ… í¬ì¸íŠ¸

{format_instructions}
        """,
        input_variables=["country", "age_ranges", "gender", "language", "interests", "trend_data"],
        partial_variables={"format_instructions": parser.get_format_instructions()}
    )
    
    # 4ë‹¨ê³„: LangChain ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰
    chain = prompt | llm | parser
    
    print("ğŸ¤– LangChainì„ í†µí•œ í˜ë¥´ì†Œë‚˜ ìƒì„± ì¤‘...")
    result = await chain.ainvoke({
        # íƒ€ê²Ÿ ê³ ê° ì •ë³´ ì „ë‹¬
        "country": customer.country,
        "age_ranges": age_ranges_str,
        "gender": customer.gender,
        "language": customer.language,
        "interests": interests_str,
        "trend_data": trend_data_str
    })
    
    print("âœ… í˜ë¥´ì†Œë‚˜ ìƒì„± ì™„ë£Œ")
    return result

# ==================================================================================
# LLM ê¸°ë°˜ ê´‘ê³  ì˜ìƒ ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
async def create_ad_example(persona: PersonaData) -> str:
    """í˜ë¥´ì†Œë‚˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì´ ì „ë¬¸ì ì¸ ê´‘ê³  ê¸°íšì„ ìƒì„± (ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì œì™¸)"""
    
    try:
        completion = client.chat.completions.create(
            model="gpt-4.1-nano-2025-04-14",
            messages=[
                {
                    "role": "system",
                    "content": """
ë‹¹ì‹ ì€ í˜ë¥´ì†Œë‚˜ ë¶„ì„ì— ê¸°ë°˜í•˜ì—¬ ê´‘ê³  ì „ëµì„ ìˆ˜ë¦½í•˜ëŠ” 'ê´‘ê³  ê¸°íš ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ ì •ë³´ë¥¼ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ì—¬, íš¨ê³¼ì ì¸ ê´‘ê³  ê¸°íšì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

**[ì‘ì—… ëª©í‘œ]**
í˜ë¥´ì†Œë‚˜ ë§ì¶¤í˜• ê´‘ê³  ì»¨ì…‰ê³¼ ì „ëµì„ ê¸°íší•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. (ì´ë¯¸ì§€ ìƒì„±ì€ ì œì™¸)

**[ì‘ì—… ìˆ˜í–‰ ë‹¨ê³„]**

**1ë‹¨ê³„: í˜ë¥´ì†Œë‚˜ ë¶„ì„**
- ì£¼ì–´ì§„ í˜ë¥´ì†Œë‚˜ì˜ ë¼ì´í”„ìŠ¤íƒ€ì¼, ê°€ì¹˜ê´€, ì†Œë¹„ íŒ¨í„´, ê³ ë¯¼(Pain Point)ì„ íŒŒì•…í•©ë‹ˆë‹¤.
- ì´ í˜ë¥´ì†Œë‚˜ê°€ ì–´ë–¤ ë©”ì‹œì§€ì™€ ì½˜í…ì¸ ì— ê°€ì¥ í¬ê²Œ ë°˜ì‘í• ì§€ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

**2ë‹¨ê³„: ê´‘ê³  ì»¨ì…‰ ê¸°íš**
- 1ë‹¨ê³„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ í˜•ì‹ì— ë§ì¶° ê´‘ê³  ì˜ìƒ ì»¨ì…‰ì„ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
    - **[í•µì‹¬ ë©”ì‹œì§€]**: í˜ë¥´ì†Œë‚˜ì˜ ë§ˆìŒì„ ì‚¬ë¡œì¡ì„ ë‹¨ í•œ ì¤„ì˜ ë§¤ë ¥ì ì¸ ë¬¸ì¥.
    - **[ê´‘ê³  ì»¨ì…‰]**: ì œí’ˆ/ì„œë¹„ìŠ¤ê°€ í˜ë¥´ì†Œë‚˜ì˜ ì¼ìƒì— ì–´ë–»ê²Œ ê¸ì •ì ì¸ ë³€í™”ë¥¼ ì£¼ëŠ”ì§€ êµ¬ì²´ì ì¸ ìŠ¤í† ë¦¬ë¼ì¸ìœ¼ë¡œ ì„¤ëª….
    - **[ì˜ìƒ ë¶„ìœ„ê¸°]**: ì˜ìƒì˜ ì „ì²´ì ì¸ ìƒ‰ê°, ì¡°ëª…, ìŒì•…, í¸ì§‘ ìŠ¤íƒ€ì¼ ë“±ì„ ê·¸ë ¤ì§€ë“¯ ë¬˜ì‚¬.
    - **[íƒ€ê²Ÿ ë°˜ì‘ ì „ëµ]**: ì´ í˜ë¥´ì†Œë‚˜ê°€ ê´‘ê³ ë¥¼ ë³´ê³  ì–´ë–¤ ê°ì •ì„ ëŠë¼ê³ , ì–´ë–¤ í–‰ë™ì„ í•˜ê¸°ë¥¼ ê¸°ëŒ€í•˜ëŠ”ì§€ ëª…ì‹œ.
    - **[ì°¨ë³„í™” í¬ì¸íŠ¸]**: ê²½ìŸì‚¬ ëŒ€ë¹„ ìš°ë¦¬ë§Œì˜ ë…íŠ¹í•œ ì–´í•„ í¬ì¸íŠ¸.

**3ë‹¨ê³„: ì½˜í…ì¸  êµ¬ì„±ì•ˆ**
- ê´‘ê³  ì˜ìƒì˜ ì „ì²´ì ì¸ íë¦„ê³¼ êµ¬ì„±ì„ ì œì•ˆí•©ë‹ˆë‹¤.
    - **[ë„ì…ë¶€]**: ì‹œì²­ìì˜ ê´€ì‹¬ì„ ëŒ ë°©ë²•
    - **[ì „ê°œë¶€]**: ë¬¸ì œ ì œê¸°ì™€ ì†”ë£¨ì…˜ ì œì‹œ ë°©ë²•  
    - **[ì ˆì •ë¶€]**: ê°€ì¥ ì„íŒ©íŠ¸ ìˆëŠ” ë©”ì‹œì§€ ì „ë‹¬ ë°©ë²•
    - **[ë§ˆë¬´ë¦¬]**: í–‰ë™ ìœ ë„(CTA)ì™€ ê¸°ì–µì— ë‚¨ì„ ì—”ë”©

**[ì¤€ìˆ˜ ì‚¬í•­]**
- ëª¨ë“  ê²°ê³¼ë¬¼ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
- ê° ë‹¨ê³„ì˜ ê²°ê³¼ë¬¼ì€ ì œëª©ê³¼ í•¨ê»˜ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ì—¬ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
"""
                },
                {
                    "role": "user",
                    "content": f"""
ë‹¤ìŒ íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ë¥¼ ë¶„ì„í•˜ì—¬ ê´‘ê³  ê¸°íšì•ˆì„ ìƒì„±í•´ì£¼ì„¸ìš”:

{persona.persona_description}

ìœ„ í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì´ í˜ë¥´ì†Œë‚˜ì—ê²Œ íš¨ê³¼ì ì¼ êµ¬ì²´ì ì´ê³  ì°½ì˜ì ì¸ ê´‘ê³  ê¸°íšì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
                }
            ],
            temperature=0.8,
        )
        
        return completion.choices[0].message.content
        
    except Exception as e:
        print(f"âš ï¸ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ (ê´‘ê³  ê¸°íš): {e}")

# ==================================================================================

# 3ë‹¨ê³„: ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ì¥ë©´ë³„ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ìƒì„± (LangChain + Pydantic)
async def generate_scene_image_prompts_with_llm(user_description: str) -> StoryboardOutput:
    """ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ LLMì´ ì¥ë©´ì„ ë‚˜ëˆ„ê³  ê° ì¥ë©´ë³„ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„± (LangChain ì‚¬ìš©)"""
    
    try:
        # StoryboardOutputìš© Pydantic Output Parser ì„¤ì •
        parser = PydanticOutputParser(pydantic_object=StoryboardOutput)
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
        prompt = PromptTemplate(
            template="""ë‹¹ì‹ ì€ ê´‘ê³  ì˜ìƒ ì œì‘ ì „ë¬¸ê°€ì´ì AI ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ ì œê³µí•œ ê´‘ê³  ì˜ìƒ ì•„ì´ë””ì–´ë¥¼ ë¶„ì„í•˜ì—¬:
1. ë¨¼ì € 3~6ê°œì˜ ì¥ë©´ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ìŠ¤í† ë¦¬ë¥¼ êµ¬ì„±
2. ê° ì¥ë©´ë³„ë¡œ {SceneImagePrompt} êµ¬ì¡°ì— ë§ëŠ” ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±

í”„ë¡¬í”„íŠ¸ ì‘ì„± ì›ì¹™:
- í•µì‹¬ ìš”ì†Œë§Œ ëª…í™•íˆ, ë¶€ì°¨ í•­ëª©ì€ í•„ìš”í•  ë•Œë§Œ ì¶”ê°€
- í° í‹€ë¶€í„° ì±„ìš°ê³  ì„¸ë¶€ì‚¬í•­ì€ ì ì§„ì ìœ¼ë¡œ ì‘ì„±
- ê³¼ë„í•œ ìƒì„¸ëŠ” í”¼í•˜ê³  ì¬í˜„ì„± ë†’ì€ í‚¤ì›Œë“œ ì‚¬ìš©

ê° ì¥ë©´ì˜ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ëŠ” ë‹¤ìŒ ìˆœì„œë¡œ êµ¬ì„±:
1. Subject (ì£¼ì²´): @userì˜ ìƒíƒœ, ì˜ìƒ, ì•¡ì…˜
2. Scene (ë°°ê²½): êµ¬ì²´ì ì¸ ì¥ì†Œì™€ í™˜ê²½
3. Composition (êµ¬ë„): ì¹´ë©”ë¼ ì•µê¸€ê³¼ í”„ë ˆì´ë° (mid-shot, close-up, wide-shot ë“±)
4. Lighting (ì¡°ëª…): ê´‘ì›ê³¼ ë¶„ìœ„ê¸° (natural light, warm lighting ë“±)
5. Style (ìŠ¤íƒ€ì¼): í™”í’ê³¼ ë§¤ì²´ (cinematic, commercial photography ë“±)
6. Mood (ë¬´ë“œ): ê°ì •ê³¼ ë¶„ìœ„ê¸° (confident, friendly, energetic ë“±)

ì‚¬ìš©ì ì…ë ¥: {user_input}

{format_instructions}""",
            input_variables=["user_input"],
            partial_variables={
                "format_instructions": parser.get_format_instructions(),
                "SceneImagePrompt": "SceneImagePrompt"
            }
        )
        
        # ì²´ì¸ ìƒì„± ë° ì‹¤í–‰
        chain = prompt | llm | parser
        # invokeí•¨ìˆ˜ëŠ” ë™ê¸° ,ainvokeëŠ” ë¹„ë™ê¸°
        result = await chain.ainvoke({"user_input": user_description})
        
        return result
            
    except Exception as e:
        print(f"âš ï¸ LangChain LLM í˜¸ì¶œ ì‹¤íŒ¨ (ì¥ë©´ í”„ë¡¬í”„íŠ¸ ìƒì„±): {e}")
        raise e

# ==================================================================================
# Runway API ê´€ë ¨ import ì¶”ê°€
import httpx
import asyncio
import time
from typing import Optional

# ==================================================================================
# 4ë‹¨ê³„: Runway APIë¥¼ í™œìš©í•œ ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„±
async def generate_images_with_runway(storyboard: StoryboardOutput) -> StoryboardOutput:
    """Runway APIë¥¼ ì‚¬ìš©í•´ì„œ ìŠ¤í† ë¦¬ë³´ë“œì˜ ê° ì¥ë©´ì„ ì‹¤ì œ ì´ë¯¸ì§€ë¡œ ìƒì„±"""
    
    runway_api_key = os.getenv("Runway_API_KEY")
    if not runway_api_key:
        raise ValueError("Runway_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print(f"ğŸ¬ ì´ {len(storyboard.scenes)} ì¥ë©´ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    
    # ê° ì¥ë©´ë³„ë¡œ ì´ë¯¸ì§€ ìƒì„±
    updated_scenes = []
    for i, scene in enumerate(storyboard.scenes, 1):
        print(f"\nğŸ–¼ï¸ ì¥ë©´ {i} ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        
        try:
            # Runway APIë¡œ ì´ë¯¸ì§€ ìƒì„± - SceneImagePromptì˜ ëª¨ë“  í•„ë“œ ì „ë‹¬
            image_url = await create_image_with_runway(
                prompt_text=scene.image_prompt.promptText,
                ratio=scene.image_prompt.ratio,
                seed=scene.image_prompt.seed,
                model=scene.image_prompt.model,
                reference_images=[ref.model_dump() for ref in scene.image_prompt.referenceImages],
                public_figure_moderation=scene.image_prompt.publicFigureModeration,
                api_key=runway_api_key
            )
            
            # ìƒì„±ëœ ì´ë¯¸ì§€ URLì„ ì¥ë©´ì— ì¶”ê°€
            scene.generated_image_url = image_url
            scene.generation_status = "success"
            print(f"âœ… ì¥ë©´ {i} ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {image_url}")
            
        except Exception as e:
            print(f"âŒ ì¥ë©´ {i} ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            scene.generated_image_url = None
            scene.generation_status = "failed"
            scene.error_message = str(e)
        
        updated_scenes.append(scene)
        
        # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ (Rate limiting ë°©ì§€)
        if i < len(storyboard.scenes):
            await asyncio.sleep(2)
    
    # ì—…ë°ì´íŠ¸ëœ ì¥ë©´ë“¤ë¡œ ìƒˆ ìŠ¤í† ë¦¬ë³´ë“œ ë°˜í™˜
    return StoryboardOutput(
        total_scenes=storyboard.total_scenes,
        estimated_duration=storyboard.estimated_duration,
        video_concept=storyboard.video_concept,
        scenes=updated_scenes
    )

async def create_image_with_runway(
    prompt_text: str,
    ratio: str = "16:9",
    seed: Optional[int] = None,
    model: str = "gen4_image",
    reference_images: List = None,
    public_figure_moderation: str = "auto",
    api_key: str = None
) -> str:
    """Runway APIë¥¼ ì‚¬ìš©í•´ì„œ ë‹¨ì¼ ì´ë¯¸ì§€ ìƒì„±"""
    
    base_url = "https://api.dev.runwayml.com/v1"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "X-Runway-Version": "2024-11-06"  # API ë²„ì „ í—¤ë” ì¶”ê°€
    }
    
    # ìš”ì²­ í˜ì´ë¡œë“œ êµ¬ì„±
    payload = {
        "promptText": prompt_text,
        "ratio": ratio,
        "model": model
    }
    
    # ì„ íƒì  íŒŒë¼ë¯¸í„°ë“¤ ì¶”ê°€
    if seed is not None:
        payload["seed"] = seed
        
    if reference_images:
        payload["referenceImages"] = reference_images
        
    if public_figure_moderation != "auto":
        payload["publicFigureThreshold"] = public_figure_moderation
    
    async with httpx.AsyncClient(timeout=180) as client:  # 3ë¶„ìœ¼ë¡œ ë‹¨ì¶•
        # 1. ì´ë¯¸ì§€ ìƒì„± ì‘ì—… ìš”ì²­
        print(f"ğŸ“¤ Runway API ìš”ì²­ ì¤‘...")
        print(f"   í”„ë¡¬í”„íŠ¸: {prompt_text}...")
        print(f"   ë¹„ìœ¨: {ratio}, ëª¨ë¸: {model}")
        
        response = await client.post(
            f"{base_url}/text_to_image",
            headers=headers,
            json=payload
        )
        
        print(f"ğŸ“‹ API ì‘ë‹µ ìƒíƒœ: {response.status_code}")
        
        if response.status_code != 200:
            print(f"âŒ API ì‘ë‹µ ë‚´ìš©: {response.text}")
            raise Exception(f"Runway API ìš”ì²­ ì‹¤íŒ¨: {response.status_code} - {response.text}")
        
        task_data = response.json()
        task_id = task_data["id"]
        print(f"ğŸ“‹ ì‘ì—… ID: {task_id}")
        
        # 2. ì‘ì—… ì™„ë£Œê¹Œì§€ í´ë§
        max_attempts = 36  # ìµœëŒ€ 3ë¶„ ëŒ€ê¸° (5ì´ˆ * 36)
        for attempt in range(max_attempts):
            print(f"â³ ì´ë¯¸ì§€ ìƒì„± ì§„í–‰ í™•ì¸ ì¤‘... ({attempt + 1}/{max_attempts})")
            
            # ì‘ì—… ìƒíƒœ í™•ì¸
            status_response = await client.get(
                f"{base_url}/tasks/{task_id}",
                headers=headers
            )
            
            if status_response.status_code != 200:
                print(f"âŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {status_response.status_code} - {status_response.text}")
                raise Exception(f"ì‘ì—… ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {status_response.status_code}")
            
            status_data = status_response.json()
            status = status_data.get("status")
            progress = status_data.get("progress", 0)
            
            print(f"   ìƒíƒœ: {status}, ì§„í–‰ë„: {progress}%")
            
            if status == "SUCCEEDED":
                # ì„±ê³µ! ì´ë¯¸ì§€ URL ë°˜í™˜
                image_output = status_data.get("output")
                if not image_output:
                    raise Exception("ì´ë¯¸ì§€ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                # Runway APIê°€ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ëŠ” ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì¶”ì¶œ
                if isinstance(image_output, list) and len(image_output) > 0:
                    image_url = image_output[0]
                else:
                    image_url = image_output
                
                print(f"âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {image_url}")
                return image_url
                
            elif status == "FAILED":
                error_msg = status_data.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                print(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {error_msg}")
                raise Exception(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {error_msg}")
                
            elif status in ["PENDING", "RUNNING"]:
                # ì•„ì§ ì§„í–‰ ì¤‘, 5ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
                await asyncio.sleep(5)
                continue
            else:
                print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ: {status}")
                raise Exception(f"ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—… ìƒíƒœ: {status}")
        
        # ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼
        print("âŒ ì´ë¯¸ì§€ ìƒì„± ì‹œê°„ ì´ˆê³¼")
        raise Exception("ì´ë¯¸ì§€ ìƒì„± ì‹œê°„ ì´ˆê³¼ (3ë¶„)")

# ==================================================================================