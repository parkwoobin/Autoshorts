"""
í˜ë¥´ì†Œë‚˜ ìƒì„± ë° LLM ê´€ë ¨ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ - ì •ë¦¬ëœ LangChain í†µí•© ë²„ì „
ë¹„ìš© íš¨ìœ¨ì„±ê³¼ ì½”ë“œ ê°„ì†Œí™”ì— ì¤‘ì ì„ ë‘” ë¦¬íŒ©í† ë§
"""
from typing import List,Dict
from models import (
    TargetCustomer, PersonaData, ReferenceImageWithDescription,
    ReferenceImage, SceneImagePrompt, StoryboardOutput
)
import os
from dotenv import load_dotenv
import asyncio
import httpx

# LangChain imports
# 
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
OpenAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ë¹„ìš© íš¨ìœ¨ì ì¸ LLM ì„¤ì •
# í…ìŠ¤íŠ¸ ìƒì„±ìš© - ì‚¬ìš©ìê°€ ìš”ì²­í•œ ëª¨ë¸ë¡œ ë³€ê²½
text_llm = ChatOpenAI(
    model="gpt-4.1-nano-2025-04-14",  # ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸
    openai_api_key=OpenAI_API_KEY,
    temperature=0.7
)

# ì´ë¯¸ì§€ ë¶„ì„ìš© ëª¨ë¸ ì„¤ì •
vision_llm = ChatOpenAI(
    model="gpt-4o",  # ì´ë¯¸ì§€ ë¶„ì„ ì „ìš©
    openai_api_key=OpenAI_API_KEY,
    temperature=0.2  # ë‚®ì€ ì˜¨ë„ëŠ” ì´ë¯¸ì§€ì²˜ëŸ¼ ê°ê´€ì ì¸ ë¬˜ì‚¬ì— ìœ ë¦¬ -> ì˜¨ë„ê°€ ë†’ìœ¼ë©´ ì°½ì˜ì ì´ì§€ë§Œ ì£¼ê´€ì ì¸ í•´ì„ì´ ì„ì¸ ë‹µë³€ì´ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ
)

# ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ì¸í„°í˜ì´ìŠ¤
# ==================================================================================
async def get_trend_data(country: str, gender: str, age_range: List[str], interests: List[str]) -> dict:
    """
    ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íƒ€ê²Ÿ ê³ ê°ì— ë§ëŠ” íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¸í„°í˜ì´ìŠ¤
    
    Args:
        country: êµ­ê°€ ì •ë³´
        gender: ì„±ë³„
        age_range: ì—°ë ¹ëŒ€ ë¦¬ìŠ¤íŠ¸ 
        interests: ê´€ì‹¬ì‚¬ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        dict: íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¨ íŠ¸ë Œë“œ ë°ì´í„°
        
    Note:
        í˜„ì¬ëŠ” ë¹ˆ dict ë°˜í™˜. ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ API ì—°ë™ ì‹œ ì´ í•¨ìˆ˜ ë‚´ìš©ë§Œ êµì²´í•˜ë©´ ë¨.
    """
    print(f"ğŸ“Š íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ëŒ€ê¸° ì¤‘... (íƒ€ê²Ÿ: {country} {gender} {age_range} {interests})")
    
    # TODO: ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ API í˜¸ì¶œ ë¡œì§ìœ¼ë¡œ êµì²´
    # ì˜ˆì‹œ: 
    # async with httpx.AsyncClient() as client:
    #     response = await client.post("https://trend-db-api.com/query", json={
    #         "country": country, "gender": gender, "age_range": age_range, "interests": interests
    #     })
    #     return response.json()
    
    # í˜„ì¬ëŠ” ë¹ˆ ë°ì´í„° ë°˜í™˜ (LLMì´ ìì²´ íŒë‹¨ìœ¼ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„±í•˜ë„ë¡)
    return {}

# ==================================================================================
"""
    ì‚¬ìš©ì ì…ë ¥ 1ë‹¨ê³„ : LangChainê³¼ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ í™œìš©í•œ ì •êµí•œ íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ ìƒì„±
    1. ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ì¡°íšŒ - ì¶”í›„ êµ¬í˜„
    2. LangChain OutputParserë¡œ êµ¬ì¡°í™”ëœ í˜ë¥´ì†Œë‚˜ ìƒì„±
    3. íŠ¸ë Œë“œ ë°ì´í„° ì—†ì„ ì‹œ LLMì´ ìì²´ íŒë‹¨ìœ¼ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„±
"""
async def generate_persona(customer: TargetCustomer) -> PersonaData:
    # LLMì—ê²Œ ë¦¬ìŠ¤íŠ¸í˜•íƒœë¡œ ì „ë‹¬í•˜ëŠ”ê²ƒë³´ë‹¤ëŠ” ë¬¸ìì—´ë¡œ ì „ë‹¬í•˜ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì ì„
    age_ranges_str = ", ".join(customer.age_range)
    interests_str = ", ".join(customer.interests) if customer.interests else "ì—†ìŒ"
    
    # ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ì¡°íšŒ
    print("ğŸ“Š íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤...") # ë””ë²„ê¹…ìš©
    trend_data = await get_trend_data(
        country=customer.country,
        gender=customer.gender,
        age_range=customer.age_range,
        interests=customer.interests
    )
    
    # íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§¤íŒ… (ë¹ˆ ë°ì´í„°ì¸ ê²½ìš° "ë°ì´í„° ì—†ìŒ" í‘œì‹œ)
    import json
    if trend_data:
        trend_data_str = json.dumps(trend_data, indent=2, ensure_ascii=False)
        print("ğŸ“ˆ íŠ¸ë Œë“œ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ")
    else:
        trend_data_str = "íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”."
        print("ğŸ“ˆ íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ - LLM ìì²´ íŒë‹¨ìœ¼ë¡œ ì§„í–‰")
    
    # LangChain OutputParser ì„¤ì •í–ˆë”ë‹ˆ ëë‹¤ê°€ ì•ˆëë‹¤ê°€ í•¨ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì•ˆì— ì¶œë ¥ êµ¬ì¡° ì§€ì¹¨ê³¼ ì§€ì‹œì‚¬í•­ì„ ê°™ì´ ì…ë ¥í•˜ë‹¤ë³´ë‹ˆ í—·ê°ˆë ¤ì„œ ë¹„ì–´ìˆëŠ” ì¶œë ¥ í¬ë§·ìœ¼ë¡œ ë‹µë³€í•  ë•Œê°€ ìˆìŒ
    # OutputParser ëŒ€ì‹  with_structured_output()ì‚¬ìš©ì´ ê¶Œì¥ë¨
    # LLMì˜ ì‘ë‹µì„ PersonaData ëª¨ë¸ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”
    # parser = PydanticOutputParser(pydantic_object=PersonaData)
    
    # LLMì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€: AIì˜ ì—­í• ê³¼ í•µì‹¬ ì§€ì‹œì‚¬í•­ ì •ì˜
    system_template = """
    ë‹¹ì‹ ì€ ìµœì‹  íŠ¸ë Œë“œì— ì •í†µí•œ ì „ë¬¸ ë§ˆì¼€í„°ì´ì ì†Œë¹„ì ì‹¬ë¦¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
    ì£¼ì–´ì§„ íƒ€ê²Ÿ ê³ ê° ì •ë³´ì™€ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬, ê´‘ê³  ìˆí¼ ê¸°íšì— ì§ì ‘ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‚´ì•„ìˆëŠ” í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

    ### ìƒì„± ì§€ì¹¨
    **ì¤‘ìš”**: íŠ¸ë Œë“œ ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë¶€ì¡±í•œ ê²½ìš°, ë‹¹ì‹ ì˜ ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ íƒ€ê²Ÿ ê³ ê°ì¸µì˜ ì¼ë°˜ì ì¸ íŠ¹ì„±ì„ ë¶„ì„í•˜ì—¬ í˜ë¥´ì†Œë‚˜ë¥¼ êµ¬ì„±í•˜ì„¸ìš”.
    ì‘ë‹µì€ ë‹¤ìŒ ì„¸ ë¶€ë¶„ìœ¼ë¡œ ëª…í™•íˆ ë¶„ë¦¬í•´ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”:
    1. **target_customer**: ì…ë ¥ë°›ì€ íƒ€ê²Ÿ ê³ ê° ì •ë³´ ê·¸ëŒ€ë¡œ ë°˜ì˜
    2. **persona_description**: êµ¬ì²´ì ì¸ í˜ë¥´ì†Œë‚˜ ì„¤ëª… (ì´ë¦„, ë‚˜ì´, ì§ì—…, ë¼ì´í”„ìŠ¤íƒ€ì¼, ì†Œë¹„ íŒ¨í„´ ë“±)
    3. **marketing_insights**: ì´ í˜ë¥´ì†Œë‚˜ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•œ ë§ˆì¼€íŒ… ì „ëµ (íš¨ê³¼ì ì¸ ë©”ì‹œì§€, ì„ í˜¸ ê´‘ê³  í˜•ì‹ ë“±)
    """
    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)

     # ë³€í•˜ëŠ” ì‹¤ì œ ë°ì´í„° ë¶€ë¶„ ì •ì˜
    human_template = """
    ### íƒ€ê²Ÿ ê³ ê° ì •ë³´
    - êµ­ê°€/ë¬¸í™”: {country}
    - ì—°ë ¹ëŒ€: {age_ranges}
    - ì„±ë³„: {gender}
    - ì–¸ì–´/ë¬¸í™”ê¶Œ: {language}
    - ê´€ì‹¬ì‚¬: {interests}

    ### íŠ¸ë Œë“œ ë°ì´í„°
    {trend_data}
    """
    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

    # 3. ChatPromptTemplateìœ¼ë¡œ ì‹œìŠ¤í…œê³¼ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì¡°í•©
    prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])

    # Pydantic ëª¨ë¸(PersonaData)ì„ LLMì— ì§ì ‘ ë°”ì¸ë”©í•˜ì—¬ JSON ëª¨ë“œ í™œì„±í™” (Tool Calling ê¸°ëŠ¥)
    # ì²´ì¸ì˜ ìµœì¢… ì¶œë ¥ êµ¬ì¡°ëŠ” PersonaDataê°€ ë¨
    structured_llm = text_llm.with_structured_output(PersonaData)

    # LangChain ì²´ì¸ ì¬êµ¬ì„± 
    chain = prompt | structured_llm

    print("ğŸ¤– LangChainì„ í†µí•œ í˜ë¥´ì†Œë‚˜ ìƒì„± ì¤‘...")
    # ainvokeëŠ” ë¹„ë™ê¸° í˜¸ì¶œ
    result = await chain.ainvoke({
    "country": customer.country,
    "age_ranges": age_ranges_str,
    "gender": customer.gender,
    "language": customer.language,
    "interests": interests_str,
    "trend_data": trend_data_str
    })

    return result

# ==================================================================================
""" 
    í˜ë¥´ì†Œë‚˜, ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸, ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ê´‘ê³  ì»¨ì…‰ ìƒì„±
    ì´ ë‹¨ê³„ì˜ ëª©ì  : ìƒì„±ëœ ê´‘ê³  ì˜ˆì‹œ í…œí”Œë¦¿ì— ë§ì¶° ì‚¬ìš©ìê°€ ì†ì‰½ê²Œ ìˆ˜ì •Â·í™•ì¥í•  ìˆ˜ ìˆëŠ” ê°€ì´ë“œë¼ì¸ì„ ì œê³µ
"""
async def create_ad_concept(persona: PersonaData, reference_images: List[ReferenceImage] = None) -> str:
    
    # ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„ (ìˆëŠ” ê²½ìš°ë§Œ)
    image_analysis = ""
    analyzed_images = []
    if reference_images:
        print(f"ğŸ” {len(reference_images)}ê°œì˜ ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
        # ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ëŠ” ë¦¬ìŠ¤íŠ¸ì•ˆì— ë”•ì…”ë„ˆë¦¬ë¡œ ë‹´ê²¨ ìˆìŒ
        analyzed_images = await analyze_reference_images(reference_images)
        print("âœ… ì°¸ì¡° ì´ë¯¸ì§€ ê²°ê³¼ ë””ë²„ê¹…")
        print(analyzed_images)  # ë””ë²„ê¹…ìš© ì¶œë ¥
        # ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ í”„ë¡¬í”„íŠ¸ì— ë„£ì„ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜
        image_analysis = "\n### ğŸ“¸ ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„\n"
        for img in analyzed_images:
            # ex) product : ë¯¸ë‹ˆë©€í•œ ë””ìì¸ì˜ í°ìƒ‰ ë³‘. ê¹¨ë—í•˜ê³  ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ëŠë‚Œì„ ì¤€ë‹¤.
            image_analysis += f"**{img['tag']}**: {img['analysis']}\n"
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ : AIì˜ ì—­í• ê³¼ ì¶œë ¥ í˜•ì‹ ì§€ì‹œ
    system_template = """
    ë‹¹ì‹ ì€ ë›°ì–´ë‚œ ê´‘ê³  ê¸°íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, íƒ€ê²Ÿ ê³ ê°ì„ ì‚¬ë¡œì¡ì„ íš¨ê³¼ì ì¸ ê´‘ê³  ì»¨ì…‰ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.

    ### ì¤‘ìš” ì§€ì¹¨
    - 'ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„' ì„¹ì…˜ì´ ì…ë ¥ ë°ì´í„°ì— **ìˆëŠ” ê²½ìš°ì—ë§Œ**, í•´ë‹¹ ë‚´ìš©ì„ 'í•µì‹¬ í™œìš© ì „ëµ'ì— ë°˜ì˜í•˜ì„¸ìš”.
    - 'ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„' ì„¹ì…˜ì´ **ì—†ë‹¤ë©´**, ì ˆëŒ€ ì°¸ì¡° ì´ë¯¸ì§€ì— ëŒ€í•´ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
    
    ### ì œì•ˆí•  ê´‘ê³  ì»¨ì…‰ í¬ë§·
    ì•„ë˜ í¬ë§·ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬, ê° í•­ëª©ì— ëŒ€í•´ ê¹Šì´ ìˆëŠ” ë‚´ìš©ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
    **âœ¨ ê´‘ê³  í•œ ì¤„ ìš”ì•½ (Catchy One-liner)**
    : ê´‘ê³  ì „ì²´ë¥¼ ê´€í†µí•˜ëŠ”, ê·€ì— ê½‚íˆëŠ” í•œ ë¬¸ì¥ ìºì¹˜í”„ë ˆì´ì¦ˆ.
    **ğŸ¯ í•µì‹¬ ë©”ì‹œì§€ (Core Message)**
    : ì´ ê´‘ê³ ë¥¼ í†µí•´ íƒ€ê²Ÿ ê³ ê°ì˜ ì–´ë–¤ ê°ì •ì´ë‚˜ ìš•êµ¬ë¥¼ ê±´ë“œë¦´ ê²ƒì¸ì§€ ëª…í™•íˆ ì„œìˆ .
    **ğŸ¬ í¬ë¦¬ì—ì´í‹°ë¸Œ ì»¨ì…‰ (Creative Concept)**
    : ê´‘ê³ ì˜ êµ¬ì²´ì ì¸ ì‹œë‚˜ë¦¬ì˜¤ë‚˜ ìŠ¤í† ë¦¬. ì§§ì§€ë§Œ ê°•ë ¥í•œ ë‚´ëŸ¬í‹°ë¸Œë¥¼ ì œì‹œ.
    **ğŸ¨ ì˜ìƒ ë¶„ìœ„ê¸° (Visual Mood & Tone)**
    : ì˜ìƒì˜ ìƒ‰ê°, ì†ë„, ì‚¬ìš´ë“œ ë“± ì „ì²´ì ì¸ ì‹œê°ì , ì²­ê°ì  ìŠ¤íƒ€ì¼.
    **ğŸ’¡ í•µì‹¬ í™œìš© ì „ëµ (Key Strategy)**
    : (ë§Œì•½ 'ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„' ë‚´ìš©ì´ ìˆë‹¤ë©´) íƒ€ê²Ÿ ê³ ê° ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ì™€ ì°¸ì¡° ì´ë¯¸ì§€ì˜ ê°•ì ì„ ì–´ë–»ê²Œ ê²°í•©í• ì§€ ì„œìˆ .
    : (ë§Œì•½ 'ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„' ë‚´ìš©ì´ ì—†ë‹¤ë©´) ì˜¤ì§ í˜ë¥´ì†Œë‚˜ì˜ íŠ¹ì§•ê³¼ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ë§Œì„ í™œìš©í•œ ì°½ì˜ì ì¸ í™•ì‚° ì „ëµì„ ì œì•ˆ.
    """
    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)

    # ì‚¬ìš©ì ë©”ì‹œì§€: ë¶„ì„í•  ë°ì´í„° ì „ë‹¬
    human_template = """
    ì•„ë˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê´‘ê³  ì»¨ì…‰ ì œì•ˆì„ ì‹œì‘í•´ì£¼ì„¸ìš”.

    ### íƒ€ê²Ÿ ê³ ê° í˜ë¥´ì†Œë‚˜
    {persona_description}

    ### íƒ€ê²Ÿ ê³ ê° ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸
    {marketing_insights}

    {image_analysis}
"""
    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

    # ChatPromptTemplateìœ¼ë¡œ ì¡°í•©
    concept_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
    # Pydantic ëª¨ë¸ ì •ì˜ ì•ˆí•˜ê³  ì¶œë ¥ êµ¬ì¡°ë¥¼ ëª…ì‹œí•˜ì§€ ì•Šì•„ì„œ LLMì´ ììœ ë¡­ê²Œ ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ í•¨
    # ì²´ì¸ì˜ ìµœì¢… ì¶œë ¤ êµ¬ì¡°ëŠ” LLMì˜ ë‹µë³€ì´ ë¨ 
    concept_chain = concept_prompt | text_llm
    
    print("ğŸ’¡ ê´‘ê³  ì»¨ì…‰ ìƒì„± ì¤‘...")
    result = await concept_chain.ainvoke({
        "persona_description": persona.persona_description,
        "marketing_insights": persona.marketing_insights,
        "image_analysis": image_analysis
    })
    
    print("âœ… ê´‘ê³  ì»¨ì…‰ ìƒì„± ì™„ë£Œ")
    #LLMì˜ ë‹µë³€ë§Œ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ content ì†ì„± ì‚¬ìš©
    return {
        "ad_concept": result.content,
        "image_analyses": analyzed_images
    }

# ==================================================================================
"""
    ì‚¬ìš©ìê°€ ì•ì„  ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ê´‘ê³  ì»¨ì…‰ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´‘ê³  ì œì‘ ì•„ì´ë””ì–´ë¥¼ ì‘ì„±
    ì‚¬ìš©ìì˜ ê´‘ê³  ì•„ì´ë””ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì´ ì¥ë©´ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
"""
# Dict[str,str] íƒ€ì…íŒíŠ¸ ì‚¬ìš© -> ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì „ë‹¬
async def generate_scene_prompts(user_description: str, enriched_images: List[ReferenceImageWithDescription]) -> StoryboardOutput:

    # AI ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ì‹œí‚¬ ë¬¸ìì—´ ì¤€ë¹„
    reference_info = ""
    if enriched_images:
        reference_info = "\n### ğŸ“¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì°¸ì¡° ì´ë¯¸ì§€ ì •ë³´ (JSON í˜•ì‹)\n"
        for ref_img in enriched_images:
            # model_dump_jsonì„ ì‚¬ìš©í•´ Pydantic ê°ì²´ë¥¼ ì½ê¸° ì¢‹ì€ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            reference_info += f"- @{ref_img.tag}: {ref_img.model_dump_json(indent=2)}\n"
        reference_info += "\n"

    # ì‹œìŠ¤í…œ ë©”ì‹œì§€: AIì˜ ì—­í• ê³¼ ë°ì´í„° 'ë³€í™˜' ì§€ì‹œì‚¬í•­ ê°•í™”
    # persona_utils.py íŒŒì¼ì˜ generate_scene_prompts í•¨ìˆ˜ ë‚´ë¶€

    system_template = """
    ë‹¹ì‹ ì€ AI ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„± ì „ë¬¸ê°€ì´ì, AI ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ì™€ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µëœ ì°¸ì¡° ì´ë¯¸ì§€ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬, 3ê°œì˜ ì¥ë©´ìœ¼ë¡œ êµ¬ì„±ëœ ì™„ì „í•œ `StoryboardOutput` JSON ê°ì²´ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

    ### â­ ê°€ì¥ ì¤‘ìš”í•œ ì‘ì„± ì›ì¹™
    - **`prompt_text`ëŠ” ì˜ì–´ë¡œ ì‘ì„±**: `scenes` ì•ˆì˜ ëª¨ë“  `prompt_text` í•„ë“œëŠ” ì´ë¯¸ì§€ ìƒì„± AIê°€ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆë„ë¡ **ë°˜ë“œì‹œ ì˜ì–´ë¡œ ì‘ì„±**í•´ì£¼ì„¸ìš”.
    - **ë‚˜ë¨¸ì§€ í•„ë“œëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±**: `video_concept`ê³¼ ê°™ì€ ë‹¤ë¥¸ ëª¨ë“  í…ìŠ¤íŠ¸ í•„ë“œëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.

    ### ğŸš¨ ê°€ì¥ ì¤‘ìš”í•œ ê·œì¹™: ì°¸ì¡° ì´ë¯¸ì§€ ì²˜ë¦¬ ë°©ë²•

    **1. ì°½ì˜ì  íŒë‹¨ ìš°ì„  (Creative Judgment First):**
    - ì°¸ì¡° ì´ë¯¸ì§€ ì‚¬ìš©ì€ **ì„ íƒ ì‚¬í•­**ì´ë©°, í•„ìˆ˜ê°€ ì•„ë‹™ë‹ˆë‹¤.
    - ì˜¤ì§ í•´ë‹¹ ì¥ë©´ì˜ ì•„ì´ë””ì–´ë¥¼ **ë”ìš± ê°•í™”í•˜ê±°ë‚˜ ëª…í™•í•˜ê²Œ ì „ë‹¬**í•˜ëŠ” ë° ë„ì›€ì´ ëœë‹¤ê³  íŒë‹¨ë  ë•Œë§Œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    - ë§Œì•½ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œìœ¼ë¡œ ì¥ë©´ì„ ë¬˜ì‚¬í•˜ëŠ” ê²ƒì´ ë” ì°½ì˜ì ì´ê±°ë‚˜ íš¨ê³¼ì ì´ë¼ë©´, **ê³¼ê°í•˜ê²Œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.** ì´ ê²½ìš° **`reference_images` í‚¤ë¥¼ ì•„ì˜ˆ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”**(ë¹ˆ ë¦¬ìŠ¤íŠ¸ë„ ê¸ˆì§€).

    **2. ì°¸ì¡° ì´ë¯¸ì§€ ì‚¬ìš© ì‹œ ì¤€ìˆ˜ ì‚¬í•­ (Rules for When You *Do* Use an Image):**
    - **ë‘ ê°€ì§€ ì‘ì—…(`prompt_text`ì— @íƒœê·¸ í¬í•¨, `reference_images` ë¦¬ìŠ¤íŠ¸ ì±„ìš°ê¸°)ì„ í•œ ì„¸íŠ¸ë¡œ ë°˜ë“œì‹œ ìˆ˜í–‰**í•´ì•¼ í•©ë‹ˆë‹¤.
    - ìµœì¢… `reference_images` ë¦¬ìŠ¤íŠ¸ì—ëŠ” `analysis` í•„ë“œë¥¼ ì œì™¸í•˜ê³  `uri`ì™€ `tag`ë§Œ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.

    **3. ì°¸ì¡° ì´ë¯¸ì§€ê°€ ì²˜ìŒë¶€í„° ì—†ëŠ” ê²½ìš° (When No Images are Provided at All):**
    - 'ì‚¬ìš© ê°€ëŠ¥í•œ ì°¸ì¡° ì´ë¯¸ì§€ ì •ë³´'ê°€ ë¹„ì–´ìˆë‹¤ë©´, ëª¨ë“  ì¥ë©´ì—ì„œ `reference_images` í‚¤ë¥¼ ë„£ì§€ ë§ˆì„¸ìš”.

    ### ğŸ“ ìµœì¢… ì¶œë ¥ êµ¬ì¡° (StoryboardOutput)
    ë‹¹ì‹ ì€ ë°˜ë“œì‹œ ì•„ë˜ ì„¤ëª…ëœ `StoryboardOutput` ì „ì²´ êµ¬ì¡°ì— ë§ëŠ” JSON ê°ì²´ í•˜ë‚˜ë§Œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

    - `scenes` (í•„ìˆ˜): `SceneImagePrompt` êµ¬ì¡°ë¥¼ ë”°ë¥´ëŠ” ì¥ë©´ ê°ì²´ë“¤ì˜ ëª©ë¡.
    - `total_scenes` (í•„ìˆ˜): ìƒì„±ëœ ì´ ì¥ë©´ì˜ ìˆ˜ 3.
    - `estimated_duration` (í•„ìˆ˜): ì „ì²´ ì˜ìƒì˜ ì˜ˆìƒ ê¸¸ì´ (ì´ˆ ë‹¨ìœ„ ì •ìˆ˜, ì¥ë©´ë‹¹ 5ì´ˆë¡œ ê³„ì‚°).
    - `video_concept` (í•„ìˆ˜): ê´‘ê³  ì˜ìƒì˜ í•µì‹¬ ì»¨ì…‰ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½.

    #### ì „ì²´ ì¶œë ¥ ì˜ˆì‹œ (ì´ êµ¬ì¡°ì™€ í•„ë“œ ì´ë¦„ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”):
    {{
    "scenes": [
        {{
        "model": "gen4_image",
        "prompt_text": "A modern, minimalist cafe exterior with natural sunlight.@background",
        "ratio": "1280:720",
        "reference_images": [
            {{
            "uri": "https://...",
            "tag": "background"
            }}
        ],
        "seed": 42,
        }},
        {{
        "model": "gen4_image",
        "prompt_text": "A close-up shot of @product, a delicious-looking jokbal dish.",
        "ratio": "1280:720",
        "seed": 42
        }}
    ],
    "total_scenes": 2,
    "estimated_duration": 10,
    "video_concept": "ë°”ìœ ì¼ìƒ ì†, ë§›ìˆëŠ” ìŒì‹ê³¼ í•¨ê»˜í•˜ëŠ” ì—¬ìœ ë¡œìš´ ìˆœê°„ì„ í†µí•´ ì–»ëŠ” í–‰ë³µì„ í‘œí˜„í•©ë‹ˆë‹¤."
    }}

    [ìµœì¢… í™•ì¸ ì§€ì‹œ]
    ì¶œë ¥í•˜ê¸° ì „, ë‹¹ì‹ ì´ ìƒì„±í•œ JSONì´ `scenes`, `total_scenes`, `estimated_duration`, `video_concept` í•„ë“œë¥¼ ëª¨ë‘ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ ë°˜ë“œì‹œ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•˜ì‹­ì‹œì˜¤.
    - `reference_images` ë¦¬ìŠ¤íŠ¸ì— ê°ì²´ê°€ ìˆë‹¤ë©´, ê°™ì€ ì¥ë©´ì˜ `prompt_text`ì— í•´ë‹¹ `@íƒœê·¸`ê°€ ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆê¹Œ?
    - ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì¥ë©´ì—ëŠ” `reference_images` í‚¤ê°€ ì—†ëŠ”ì§€ í™•ì¸í–ˆìŠµë‹ˆê¹Œ?
    """
    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)

    # ì‚¬ìš©ì ë©”ì‹œì§€ í…œí”Œë¦¿
    human_template = """
    ### ğŸ’¬ ì‚¬ìš©ìì˜ ê´‘ê³  ì•„ì´ë””ì–´
    {user_description}
    {reference_info}
    ---
    ìœ„ ì•„ì´ë””ì–´ì™€ ì°¸ì¡° ì´ë¯¸ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì§€ì¹¨ì— ë”°ë¼ ì™„ì „í•œ ìŠ¤í† ë¦¬ë³´ë“œ JSON ê°ì²´ë¥¼ ìƒì„±í•´ì£¼ì‹­ì‹œì˜¤.
    """
    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)
    
    # ì²´ì¸ êµ¬ì„±
    storyboard_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
    structured_llm = text_llm.with_structured_output(StoryboardOutput)
    storyboard_chain = storyboard_prompt | structured_llm

    print("ğŸ¬ ì¥ë©´ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
    
    result = await storyboard_chain.ainvoke({
        "user_description": user_description,
        "reference_info": reference_info,
    })

    print("âœ… ì¥ë©´ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
    return result

# ==================================================================================
"""ìŠ¤í† ë¦¬ë³´ë“œ ì¥ë©´ ì´ë¯¸ì§€ë¥¼ Runway APIë¡œ ìƒì„±"""
async def generate_images_sequentially(
    scenes: List[SceneImagePrompt],
    api_key: str
) -> List[Dict]:
    """ì—¬ëŸ¬ ì¥ë©´ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ 'ì§ë ¬'ë¡œ ì´ë¯¸ì§€ ìƒì„±ì„ ìš”ì²­í•˜ê³  ëª¨ë“  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json","X-Runway-Version": "2024-11-06"}
    base_url = "https://api.dev.runwayml.com/v1"
    
    generated_images = []
    total_scenes = len(scenes)
    
    print(f"\nğŸš€ ì´ {total_scenes}ê°œì˜ ì´ë¯¸ì§€ ìƒì„±ì„ ì§ë ¬ë¡œ ì‹œì‘í•©ë‹ˆë‹¤...")

    for i, scene in enumerate(scenes):
        print(f"\n--- [ì¥ë©´ {i+1}/{total_scenes}] ìƒì„± ì‹œì‘ ---")
        
        payload = scene.model_dump(by_alias=True, exclude_none=True)
        
        if payload.get("referenceImages"):
            for ref_img_dict in payload["referenceImages"]:
                ref_img_dict["weight"] = 0.5

        async with httpx.AsyncClient(timeout=180) as client:
            try:
                # 1. ì‘ì—… ìš”ì²­
                print(f"ğŸ“¤ Runway API ìš”ì²­: {scene.prompt_text[:40]}...")
                response = await client.post(f"{base_url}/text_to_image", headers=headers, json=payload)
                
                if response.status_code != 200:
                    raise Exception(f"API ìš”ì²­ ì‹¤íŒ¨: {response.text}")
                
                task_id = response.json()["id"]
                print(f"  -> ì‘ì—… ID: {task_id}")

                # 2. ì‘ì—… ì™„ë£Œê¹Œì§€ í´ë§
                for attempt in range(36):
                    print(f"â³ ì´ë¯¸ì§€ ìƒì„± ì§„í–‰ í™•ì¸ ì¤‘... ({attempt + 1}/{36})")
                    status_response = await client.get(f"{base_url}/tasks/{task_id}", headers=headers)
                    status_data = status_response.json()
                    status = status_data.get("status")
                    progress = status_data.get("progress", 0)
                    print(f" Â  ìƒíƒœ: {status}, ì§„í–‰ë„: {progress}%")

                    if status == "SUCCEEDED":
                        print(f"âœ… [ì¥ë©´ {i+1}] ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
                        generated_images.append({
                            "scene_index": i + 1,
                            "status": "success",
                            "image_url": status_data.get("output", [None])[0],
                            "prompt": scene.prompt_text
                        })
                        break
                    elif status == "FAILED":
                        error_msg = status_data.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                        print(f"âŒ [ì¥ë©´ {i+1}] ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {error_msg}")
                        generated_images.append({"scene_index": i + 1, "status": "failed", "error": error_msg, "prompt": scene.prompt_text})
                        break
                    
                    await asyncio.sleep(5)
                else:
                    raise Exception("ì´ë¯¸ì§€ ìƒì„± ì‹œê°„ ì´ˆê³¼")

            except Exception as e:
                print(f"âŒ [ì¥ë©´ {i+1}] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                generated_images.append({"scene_index": i + 1, "status": "error", "error": str(e), "prompt": scene.prompt_text})

    print("\nğŸ‰ ëª¨ë“  ì´ë¯¸ì§€ ìƒì„± ì‘ì—… ì™„ë£Œ!")
    return generated_images
# ==================================================================================

"""ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„ : ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ ê´‘ê³  ì½˜ì…‰íŠ¸ ë° í¬ë¦¬ì—ì´í‹°ë¸Œ ë°©í–¥ì„±ì„ ë„ì¶œ"""
async def analyze_reference_images(reference_images: List[ReferenceImage]) -> List[dict]:
    if not reference_images:
        return []
    # ë¶„ì„ ê²°ê³¼ ì €ì¥í•  ë³€ìˆ˜
    analyzed_result = []
    
    for ref_image in reference_images:
        try:
            message = HumanMessage(
                content=[
                    {
                        "type": "text",
                        "text": f"""ì´ ì´ë¯¸ì§€ë¥¼ {ref_image.tag}ë¡œ ê´‘ê³ ì— í™œìš©í•˜ë ¤ê³  í•©ë‹ˆë‹¤.
                        ì£¼ìš” íŠ¹ì§•ê³¼ ê´‘ê³  í™œìš© í¬ì¸íŠ¸ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”"""
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": ref_image.uri,
                            "detail": "auto"  # lowì™€ highê°€ ìˆìŒ , í•µì‹¬ì€ ì´ë¯¸ì§€ì˜ ì„¸ë¶€ì ì¸ ë¶€ë¶„ê¹Œì§€ ë¶„ì„ì´ ê°€ëŠ¥í•˜ëƒë§ˆëƒì˜ ì°¨ì´
                        }
                    }
                ]
            )
            # LLMì— ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­
            result = await vision_llm.ainvoke([message])
            
            analyzed_result.append({
                "tag": ref_image.tag,
                "uri": ref_image.uri,
                "analysis": result.content
            })
            print(f"âœ… @{ref_image.tag} ë¶„ì„ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ @{ref_image.tag} ë¶„ì„ ì‹¤íŒ¨: {e}")
            analyzed_result.append({
                "tag": ref_image.tag,
                "uri": ref_image.uri,
                "analysis": "ì´ë¯¸ì§€ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            })
    
    return analyzed_result

# ==================================================================================