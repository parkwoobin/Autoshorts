"""
í˜ë¥´ì†Œë‚˜ ìƒì„± ë° LLM ê´€ë ¨ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ - ì •ë¦¬ëœ LangChain í†µí•© ë²„ì „
ë¹„ìš© íš¨ìœ¨ì„±ê³¼ ì½”ë“œ ê°„ì†Œí™”ì— ì¤‘ì ì„ ë‘” ë¦¬íŒ©í† ë§
"""
from typing import List,Dict
from models import (
    TargetCustomer, PersonaData, ReferenceImageWithDescription,
    ReferenceImage, SceneImagePrompt, StoryboardOutput
)
import os
from dotenv import load_dotenv
import asyncio
import httpx

# LangChain imports
# 
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
OpenAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ë¹„ìš© íš¨ìœ¨ì ì¸ LLM ì„¤ì •
# í…ìŠ¤íŠ¸ ìƒì„±ìš© - ì‚¬ìš©ìê°€ ìš”ì²­í•œ ëª¨ë¸ë¡œ ë³€ê²½
text_llm = ChatOpenAI(
    model="gpt-4.1-nano-2025-04-14",  # ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸
    openai_api_key=OpenAI_API_KEY,
    temperature=0.7
)

# ì´ë¯¸ì§€ ë¶„ì„ìš© ëª¨ë¸ ì„¤ì •
vision_llm = ChatOpenAI(
    model="gpt-4o",  # ì´ë¯¸ì§€ ë¶„ì„ ì „ìš©
    openai_api_key=OpenAI_API_KEY,
    temperature=0.2  # ë‚®ì€ ì˜¨ë„ëŠ” ì´ë¯¸ì§€ì²˜ëŸ¼ ê°ê´€ì ì¸ ë¬˜ì‚¬ì— ìœ ë¦¬ -> ì˜¨ë„ê°€ ë†’ìœ¼ë©´ ì°½ì˜ì ì´ì§€ë§Œ ì£¼ê´€ì ì¸ í•´ì„ì´ ì„ì¸ ë‹µë³€ì´ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ
)

# ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ì¸í„°í˜ì´ìŠ¤
# ==================================================================================
async def get_trend_data(country: str, gender: str, age_range: List[str], interests: List[str]) -> dict:
    """
    ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íƒ€ê²Ÿ ê³ ê°ì— ë§ëŠ” íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¸í„°í˜ì´ìŠ¤
    
    Args:
        country: êµ­ê°€ ì •ë³´
        gender: ì„±ë³„
        age_range: ì—°ë ¹ëŒ€ ë¦¬ìŠ¤íŠ¸ 
        interests: ê´€ì‹¬ì‚¬ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        dict: íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¨ íŠ¸ë Œë“œ ë°ì´í„°
        
    Note:
        í˜„ì¬ëŠ” ë¹ˆ dict ë°˜í™˜. ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ API ì—°ë™ ì‹œ ì´ í•¨ìˆ˜ ë‚´ìš©ë§Œ êµì²´í•˜ë©´ ë¨.
    """
    print(f"ğŸ“Š íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ëŒ€ê¸° ì¤‘... (íƒ€ê²Ÿ: {country} {gender} {age_range} {interests})")
    
    # TODO: ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ API í˜¸ì¶œ ë¡œì§ìœ¼ë¡œ êµì²´
    # ì˜ˆì‹œ: 
    # async with httpx.AsyncClient() as client:
    #     response = await client.post("https://trend-db-api.com/query", json={
    #         "country": country, "gender": gender, "age_range": age_range, "interests": interests
    #     })
    #     return response.json()
    
    # í˜„ì¬ëŠ” ë¹ˆ ë°ì´í„° ë°˜í™˜ (LLMì´ ìì²´ íŒë‹¨ìœ¼ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„±í•˜ë„ë¡)
    return {}

# ==================================================================================
"""
    ì‚¬ìš©ì ì…ë ¥ 1ë‹¨ê³„ : LangChainê³¼ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ í™œìš©í•œ ì •êµí•œ íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ ìƒì„±
    1. ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ì¡°íšŒ - ì¶”í›„ êµ¬í˜„
    2. LangChain OutputParserë¡œ êµ¬ì¡°í™”ëœ í˜ë¥´ì†Œë‚˜ ìƒì„±
    3. íŠ¸ë Œë“œ ë°ì´í„° ì—†ì„ ì‹œ LLMì´ ìì²´ íŒë‹¨ìœ¼ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„±
"""
async def generate_persona(customer: TargetCustomer) -> PersonaData:
    # LLMì—ê²Œ ë¦¬ìŠ¤íŠ¸í˜•íƒœë¡œ ì „ë‹¬í•˜ëŠ”ê²ƒë³´ë‹¤ëŠ” ë¬¸ìì—´ë¡œ ì „ë‹¬í•˜ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì ì„
    age_ranges_str = ", ".join(customer.age_range)
    interests_str = ", ".join(customer.interests) if customer.interests else "ì—†ìŒ"
    
    # ì™¸ë¶€ íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ì¡°íšŒ
    print("ğŸ“Š íŠ¸ë Œë“œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤...") # ë””ë²„ê¹…ìš©
    trend_data = await get_trend_data(
        country=customer.country,
        gender=customer.gender,
        age_range=customer.age_range,
        interests=customer.interests
    )
    
    # íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§¤íŒ… (ë¹ˆ ë°ì´í„°ì¸ ê²½ìš° "ë°ì´í„° ì—†ìŒ" í‘œì‹œ)
    import json
    if trend_data:
        trend_data_str = json.dumps(trend_data, indent=2, ensure_ascii=False)
        print("ğŸ“ˆ íŠ¸ë Œë“œ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ")
    else:
        trend_data_str = "íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”."
        print("ğŸ“ˆ íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ - LLM ìì²´ íŒë‹¨ìœ¼ë¡œ ì§„í–‰")
    
    # LangChain OutputParser ì„¤ì •í–ˆë”ë‹ˆ ëë‹¤ê°€ ì•ˆëë‹¤ê°€ í•¨ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì•ˆì— ì¶œë ¥ êµ¬ì¡° ì§€ì¹¨ê³¼ ì§€ì‹œì‚¬í•­ì„ ê°™ì´ ì…ë ¥í•˜ë‹¤ë³´ë‹ˆ í—·ê°ˆë ¤ì„œ ë¹„ì–´ìˆëŠ” ì¶œë ¥ í¬ë§·ìœ¼ë¡œ ë‹µë³€í•  ë•Œê°€ ìˆìŒ
    # OutputParser ëŒ€ì‹  with_structured_output()ì‚¬ìš©ì´ ê¶Œì¥ë¨
    # LLMì˜ ì‘ë‹µì„ PersonaData ëª¨ë¸ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”
    # parser = PydanticOutputParser(pydantic_object=PersonaData)
    
    # LLMì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€: AIì˜ ì—­í• ê³¼ í•µì‹¬ ì§€ì‹œì‚¬í•­ ì •ì˜
    system_template = """
    ë‹¹ì‹ ì€ ìµœì‹  íŠ¸ë Œë“œì— ì •í†µí•œ ì „ë¬¸ ë§ˆì¼€í„°ì´ì ì†Œë¹„ì ì‹¬ë¦¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
    ì£¼ì–´ì§„ íƒ€ê²Ÿ ê³ ê° ì •ë³´ì™€ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬, ê´‘ê³  ìˆí¼ ê¸°íšì— ì§ì ‘ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‚´ì•„ìˆëŠ” í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

    ### ìƒì„± ì§€ì¹¨
    **ì¤‘ìš”**: íŠ¸ë Œë“œ ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë¶€ì¡±í•œ ê²½ìš°, ë‹¹ì‹ ì˜ ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ íƒ€ê²Ÿ ê³ ê°ì¸µì˜ ì¼ë°˜ì ì¸ íŠ¹ì„±ì„ ë¶„ì„í•˜ì—¬ í˜ë¥´ì†Œë‚˜ë¥¼ êµ¬ì„±í•˜ì„¸ìš”.
    ì‘ë‹µì€ ë‹¤ìŒ ì„¸ ë¶€ë¶„ìœ¼ë¡œ ëª…í™•íˆ ë¶„ë¦¬í•´ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”:
    1. **target_customer**: ì…ë ¥ë°›ì€ íƒ€ê²Ÿ ê³ ê° ì •ë³´ ê·¸ëŒ€ë¡œ ë°˜ì˜
    2. **persona_description**: êµ¬ì²´ì ì¸ í˜ë¥´ì†Œë‚˜ ì„¤ëª… (ì´ë¦„, ë‚˜ì´, ì§ì—…, ë¼ì´í”„ìŠ¤íƒ€ì¼, ì†Œë¹„ íŒ¨í„´ ë“±)
    3. **marketing_insights**: ì´ í˜ë¥´ì†Œë‚˜ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•œ ë§ˆì¼€íŒ… ì „ëµ (íš¨ê³¼ì ì¸ ë©”ì‹œì§€, ì„ í˜¸ ê´‘ê³  í˜•ì‹ ë“±)
    """
    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)

     # ë³€í•˜ëŠ” ì‹¤ì œ ë°ì´í„° ë¶€ë¶„ ì •ì˜
    human_template = """
    ### íƒ€ê²Ÿ ê³ ê° ì •ë³´
    - êµ­ê°€/ë¬¸í™”: {country}
    - ì—°ë ¹ëŒ€: {age_ranges}
    - ì„±ë³„: {gender}
    - ì–¸ì–´/ë¬¸í™”ê¶Œ: {language}
    - ê´€ì‹¬ì‚¬: {interests}

    ### íŠ¸ë Œë“œ ë°ì´í„°
    {trend_data}
    """
    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

    # 3. ChatPromptTemplateìœ¼ë¡œ ì‹œìŠ¤í…œê³¼ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì¡°í•©
    prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])

    # Pydantic ëª¨ë¸(PersonaData)ì„ LLMì— ì§ì ‘ ë°”ì¸ë”©í•˜ì—¬ JSON ëª¨ë“œ í™œì„±í™” (Tool Calling ê¸°ëŠ¥)
    # ì²´ì¸ì˜ ìµœì¢… ì¶œë ¥ êµ¬ì¡°ëŠ” PersonaDataê°€ ë¨
    structured_llm = text_llm.with_structured_output(PersonaData)

    # LangChain ì²´ì¸ ì¬êµ¬ì„± 
    chain = prompt | structured_llm

    print("ğŸ¤– LangChainì„ í†µí•œ í˜ë¥´ì†Œë‚˜ ìƒì„± ì¤‘...")
    # ainvokeëŠ” ë¹„ë™ê¸° í˜¸ì¶œ
    result = await chain.ainvoke({
    "country": customer.country,
    "age_ranges": age_ranges_str,
    "gender": customer.gender,
    "language": customer.language,
    "interests": interests_str,
    "trend_data": trend_data_str
    })

    return result

# ==================================================================================
""" 
    í˜ë¥´ì†Œë‚˜, ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸, ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ê´‘ê³  ì»¨ì…‰ ìƒì„±
    ì´ ë‹¨ê³„ì˜ ëª©ì  : ìƒì„±ëœ ê´‘ê³  ì˜ˆì‹œ í…œí”Œë¦¿ì— ë§ì¶° ì‚¬ìš©ìê°€ ì†ì‰½ê²Œ ìˆ˜ì •Â·í™•ì¥í•  ìˆ˜ ìˆëŠ” ê°€ì´ë“œë¼ì¸ì„ ì œê³µ
"""
async def create_ad_concept(persona: PersonaData, reference_images: List[ReferenceImage] = None) -> str:
    
    # ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„ (ìˆëŠ” ê²½ìš°ë§Œ)
    image_analysis = ""
    analyzed_images = []
    if reference_images:
        print(f"ğŸ” {len(reference_images)}ê°œì˜ ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
        # ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ëŠ” ë¦¬ìŠ¤íŠ¸ì•ˆì— ë”•ì…”ë„ˆë¦¬ë¡œ ë‹´ê²¨ ìˆìŒ
        analyzed_images = await analyze_reference_images(reference_images)
        print("âœ… ì°¸ì¡° ì´ë¯¸ì§€ ê²°ê³¼ ë””ë²„ê¹…")
        print(analyzed_images)  # ë””ë²„ê¹…ìš© ì¶œë ¥
        # ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ í”„ë¡¬í”„íŠ¸ì— ë„£ì„ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜
        image_analysis = "\n### ğŸ“¸ ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„\n"
        for img in analyzed_images:
            # ex) product : ë¯¸ë‹ˆë©€í•œ ë””ìì¸ì˜ í°ìƒ‰ ë³‘. ê¹¨ë—í•˜ê³  ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ëŠë‚Œì„ ì¤€ë‹¤.
            image_analysis += f"**{img['tag']}**: {img['analysis']}\n"
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ : AIì˜ ì—­í• ê³¼ ì¶œë ¥ í˜•ì‹ ì§€ì‹œ
    system_template = """
    ë‹¹ì‹ ì€ ë›°ì–´ë‚œ ê´‘ê³  ê¸°íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, íƒ€ê²Ÿ ê³ ê°ì„ ì‚¬ë¡œì¡ì„ íš¨ê³¼ì ì¸ ê´‘ê³  ì»¨ì…‰ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.

    ### ì¤‘ìš” ì§€ì¹¨
    - 'ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„' ì„¹ì…˜ì´ ì…ë ¥ ë°ì´í„°ì— **ìˆëŠ” ê²½ìš°ì—ë§Œ**, í•´ë‹¹ ë‚´ìš©ì„ 'í•µì‹¬ í™œìš© ì „ëµ'ì— ë°˜ì˜í•˜ì„¸ìš”.
    - 'ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„' ì„¹ì…˜ì´ **ì—†ë‹¤ë©´**, ì ˆëŒ€ ì°¸ì¡° ì´ë¯¸ì§€ì— ëŒ€í•´ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
    
    ### ì œì•ˆí•  ê´‘ê³  ì»¨ì…‰ í¬ë§·
    ì•„ë˜ í¬ë§·ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬, ê° í•­ëª©ì— ëŒ€í•´ ê¹Šì´ ìˆëŠ” ë‚´ìš©ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
    **âœ¨ ê´‘ê³  í•œ ì¤„ ìš”ì•½ (Catchy One-liner)**
    : ê´‘ê³  ì „ì²´ë¥¼ ê´€í†µí•˜ëŠ”, ê·€ì— ê½‚íˆëŠ” í•œ ë¬¸ì¥ ìºì¹˜í”„ë ˆì´ì¦ˆ.
    **ğŸ¯ í•µì‹¬ ë©”ì‹œì§€ (Core Message)**
    : ì´ ê´‘ê³ ë¥¼ í†µí•´ íƒ€ê²Ÿ ê³ ê°ì˜ ì–´ë–¤ ê°ì •ì´ë‚˜ ìš•êµ¬ë¥¼ ê±´ë“œë¦´ ê²ƒì¸ì§€ ëª…í™•íˆ ì„œìˆ .
    **ğŸ¬ í¬ë¦¬ì—ì´í‹°ë¸Œ ì»¨ì…‰ (Creative Concept)**
    : ê´‘ê³ ì˜ êµ¬ì²´ì ì¸ ì‹œë‚˜ë¦¬ì˜¤ë‚˜ ìŠ¤í† ë¦¬. ì§§ì§€ë§Œ ê°•ë ¥í•œ ë‚´ëŸ¬í‹°ë¸Œë¥¼ ì œì‹œ.
    **ğŸ¨ ì˜ìƒ ë¶„ìœ„ê¸° (Visual Mood & Tone)**
    : ì˜ìƒì˜ ìƒ‰ê°, ì†ë„, ì‚¬ìš´ë“œ ë“± ì „ì²´ì ì¸ ì‹œê°ì , ì²­ê°ì  ìŠ¤íƒ€ì¼.
    **ğŸ’¡ í•µì‹¬ í™œìš© ì „ëµ (Key Strategy)**
    : (ë§Œì•½ 'ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„' ë‚´ìš©ì´ ìˆë‹¤ë©´) íƒ€ê²Ÿ ê³ ê° ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ì™€ ì°¸ì¡° ì´ë¯¸ì§€ì˜ ê°•ì ì„ ì–´ë–»ê²Œ ê²°í•©í• ì§€ ì„œìˆ .
    : (ë§Œì•½ 'ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„' ë‚´ìš©ì´ ì—†ë‹¤ë©´) ì˜¤ì§ í˜ë¥´ì†Œë‚˜ì˜ íŠ¹ì§•ê³¼ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ë§Œì„ í™œìš©í•œ ì°½ì˜ì ì¸ í™•ì‚° ì „ëµì„ ì œì•ˆ.
    """
    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)

    # ì‚¬ìš©ì ë©”ì‹œì§€: ë¶„ì„í•  ë°ì´í„° ì „ë‹¬
    human_template = """
    ì•„ë˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê´‘ê³  ì»¨ì…‰ ì œì•ˆì„ ì‹œì‘í•´ì£¼ì„¸ìš”.

    ### íƒ€ê²Ÿ ê³ ê° í˜ë¥´ì†Œë‚˜
    {persona_description}

    ### íƒ€ê²Ÿ ê³ ê° ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸
    {marketing_insights}

    {image_analysis}
"""
    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

    # ChatPromptTemplateìœ¼ë¡œ ì¡°í•©
    concept_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
    # Pydantic ëª¨ë¸ ì •ì˜ ì•ˆí•˜ê³  ì¶œë ¥ êµ¬ì¡°ë¥¼ ëª…ì‹œí•˜ì§€ ì•Šì•„ì„œ LLMì´ ììœ ë¡­ê²Œ ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ í•¨
    # ì²´ì¸ì˜ ìµœì¢… ì¶œë ¤ êµ¬ì¡°ëŠ” LLMì˜ ë‹µë³€ì´ ë¨ 
    concept_chain = concept_prompt | text_llm
    
    print("ğŸ’¡ ê´‘ê³  ì»¨ì…‰ ìƒì„± ì¤‘...")
    result = await concept_chain.ainvoke({
        "persona_description": persona.persona_description,
        "marketing_insights": persona.marketing_insights,
        "image_analysis": image_analysis
    })
    
    print("âœ… ê´‘ê³  ì»¨ì…‰ ìƒì„± ì™„ë£Œ")
    #LLMì˜ ë‹µë³€ë§Œ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ content ì†ì„± ì‚¬ìš©
    return {
        "ad_concept": result.content,
        "image_analyses": analyzed_images
    }

# ==================================================================================
"""
    ì‚¬ìš©ìê°€ ì•ì„  ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ê´‘ê³  ì»¨ì…‰ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´‘ê³  ì œì‘ ì•„ì´ë””ì–´ë¥¼ ì‘ì„±
    ì‚¬ìš©ìì˜ ê´‘ê³  ì•„ì´ë””ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì´ ì¥ë©´ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
"""
async def generate_scene_prompts(
    user_description: str, 
    enriched_images: List[ReferenceImageWithDescription], 
    persona_data: dict = None, 
    ad_concept: str = None
) -> StoryboardOutput:

    # í˜ë¥´ì†Œë‚˜ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
    persona_context = ""
    if persona_data:
        persona_context = f"""
### ğŸ¯ Step1ì—ì„œ ìƒì„±ëœ íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ ì •ë³´
**íƒ€ê²Ÿ ê³ ê°:**
- êµ­ê°€: {persona_data.get('target_customer', {}).get('country', 'N/A')}
- ì—°ë ¹ëŒ€: {persona_data.get('target_customer', {}).get('age_range', 'N/A')}
- ì„±ë³„: {persona_data.get('target_customer', {}).get('gender', 'N/A')}
- ê´€ì‹¬ì‚¬: {persona_data.get('target_customer', {}).get('interests', 'N/A')}

**í˜ë¥´ì†Œë‚˜ ì„¤ëª…:**
{persona_data.get('persona_description', 'N/A')}

**ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸:**
{persona_data.get('marketing_insights', 'N/A')}
"""

    # ê´‘ê³  ì»¨ì…‰ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
    concept_context = ""
    if ad_concept:
        concept_context = f"""
### ğŸ’¡ Step2ì—ì„œ ìƒì„±ëœ ê´‘ê³  ì»¨ì…‰
{ad_concept}
"""

    # AI ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ì‹œí‚¬ ë¬¸ìì—´ ì¤€ë¹„
    reference_info = ""
    if enriched_images:
        # ìœ íš¨í•œ ì°¸ì¡° ì´ë¯¸ì§€ë§Œ í•„í„°ë§
        valid_images = []
        for ref_img in enriched_images:
            if (ref_img.uri and 
                ref_img.uri != "string" and 
                ref_img.uri.startswith(("http://", "https://")) and
                ref_img.tag and 
                ref_img.tag != "string"):
                valid_images.append(ref_img)
            else:
                print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ì°¸ì¡° ì´ë¯¸ì§€ ì œì™¸: URI='{ref_img.uri}', TAG='{ref_img.tag}'")
        
        if valid_images:
            reference_info = "\n### ğŸ“¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì°¸ì¡° ì´ë¯¸ì§€ ì •ë³´ (JSON í˜•ì‹)\n"
            for ref_img in valid_images:
                # model_dump_jsonì„ ì‚¬ìš©í•´ Pydantic ê°ì²´ë¥¼ ì½ê¸° ì¢‹ì€ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
                reference_info += f"- @{ref_img.tag}: {ref_img.model_dump_json(indent=2)}\n"
            reference_info += "\n"
        else:
            print("âš ï¸ ëª¨ë“  ì°¸ì¡° ì´ë¯¸ì§€ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            reference_info = ""

    # ì‹œìŠ¤í…œ ë©”ì‹œì§€: AIì˜ ì—­í• ê³¼ ë°ì´í„° í†µí•© ì§€ì‹œì‚¬í•­
    system_template = """
    ë‹¹ì‹ ì€ AI ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„± ì „ë¬¸ê°€ì´ì, AI ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ Step1ì—ì„œ ìƒì„±í•œ í˜ë¥´ì†Œë‚˜ì™€ Step2ì—ì„œ ìƒì„±í•œ ê´‘ê³  ì»¨ì…‰, ê·¸ë¦¬ê³  Step3ì—ì„œ ì…ë ¥í•œ ì•„ì´ë””ì–´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, ì¼ê´€ì„± ìˆê³  íƒ€ê²ŸíŒ…ëœ 3ê°œì˜ ì¥ë©´ìœ¼ë¡œ êµ¬ì„±ëœ ì™„ì „í•œ `StoryboardOutput` JSON ê°ì²´ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

    ### ğŸš¨ğŸš¨ğŸš¨ ìµœìš°ì„  ì›ì¹™: ì „ì²´ ì›Œí¬í”Œë¡œìš° ë°ì´í„° í†µí•© ğŸš¨ğŸš¨ğŸš¨
    - **Step1 í˜ë¥´ì†Œë‚˜ ë°ì´í„°**: íƒ€ê²Ÿ ê³ ê°ì˜ íŠ¹ì„±, ê´€ì‹¬ì‚¬, ì¸êµ¬í†µê³„í•™ì  ì •ë³´ë¥¼ ëª¨ë“  ì¥ë©´ì— ë°˜ì˜
    - **Step2 ê´‘ê³  ì»¨ì…‰**: ìƒì„±ëœ ê´‘ê³  ì „ëµê³¼ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ë¥¼ ì¥ë©´ ì„¤ê³„ì— í†µí•©
    - **Step3 ì‚¬ìš©ì ì•„ì´ë””ì–´**: ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•œ êµ¬ì²´ì ì¸ ì•„ì´ë””ì–´ë¥¼ ìµœì¢… ì‹¤í–‰ ë°©í–¥ìœ¼ë¡œ ì ìš©
    - **ëª¨ë“  ë‹¨ê³„ì˜ ë°ì´í„°ê°€ ì„œë¡œ ì—°ê²°ë˜ê³  ì¼ê´€ì„±ì„ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤**

    ### â­ í†µí•© ì›ì¹™: 3ë‹¨ê³„ ë°ì´í„° ìœµí•©
    1. **í˜ë¥´ì†Œë‚˜ ë°˜ì˜**: íƒ€ê²Ÿ ê³ ê°ì˜ ì—°ë ¹ëŒ€, ì„±ë³„, ê´€ì‹¬ì‚¬, ë¬¸í™”ì  ë°°ê²½ì´ ëª¨ë“  ì¥ë©´ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì•„ë“¤ì–´ì•¼ í•¨
    2. **ê´‘ê³  ì»¨ì…‰ í™œìš©**: Step2ì—ì„œ ìƒì„±ëœ í¬ë¦¬ì—ì´í‹°ë¸Œ ì»¨ì…‰ê³¼ í•µì‹¬ ë©”ì‹œì§€ê°€ ì‹œê°ì ìœ¼ë¡œ êµ¬í˜„ë˜ì–´ì•¼ í•¨
    3. **ì‚¬ìš©ì ì•„ì´ë””ì–´ ì‹¤í˜„**: Step3ì—ì„œ ì…ë ¥í•œ êµ¬ì²´ì ì¸ ì•„ì´ë””ì–´ê°€ ì¥ë©´ì˜ í•µì‹¬ ìš”ì†Œë¡œ êµ¬í˜„ë˜ì–´ì•¼ í•¨

    ### ğŸ¯ ì¥ë©´ë³„ ì„¤ê³„ ì›ì¹™
    **ì¥ë©´ 1 (ë„ì…)**: íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ê°€ ê³µê°í•  ìˆ˜ ìˆëŠ” ìƒí™©/ë¬¸ì œ ì œì‹œ
    **ì¥ë©´ 2 (ì „ê°œ)**: ì‚¬ìš©ì ì•„ì´ë””ì–´ì˜ í•µì‹¬ ìš”ì†Œë¥¼ ê´‘ê³  ì»¨ì…‰ì— ë§ê²Œ ì‹œê°í™”
    **ì¥ë©´ 3 (í´ë¼ì´ë§¥ìŠ¤)**: í˜ë¥´ì†Œë‚˜ì˜ ìš•êµ¬ë¥¼ ì¶©ì¡±ì‹œí‚¤ëŠ” í•´ê²°ì±…/ê²°ê³¼ ì œì‹œ

    ### â­ ì‘ì„± ì›ì¹™
    - **`prompt_text`ëŠ” ì˜ì–´ë¡œ ì‘ì„±**: `scenes` ì•ˆì˜ ëª¨ë“  `prompt_text` í•„ë“œëŠ” ì´ë¯¸ì§€ ìƒì„± AIê°€ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆë„ë¡ **ë°˜ë“œì‹œ ì˜ì–´ë¡œ ì‘ì„±**í•´ì£¼ì„¸ìš”.
    - **ë‚˜ë¨¸ì§€ í•„ë“œëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±**: `video_concept`ê³¼ ê°™ì€ ë‹¤ë¥¸ ëª¨ë“  í…ìŠ¤íŠ¸ í•„ë“œëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.

    ### ğŸš¨ ì°¸ì¡° ì´ë¯¸ì§€ ì²˜ë¦¬ ë°©ë²•
    **1. ì°½ì˜ì  íŒë‹¨ ìš°ì„  (Creative Judgment First):**
    - ì°¸ì¡° ì´ë¯¸ì§€ ì‚¬ìš©ì€ **ì„ íƒ ì‚¬í•­**ì´ë©°, í•„ìˆ˜ê°€ ì•„ë‹™ë‹ˆë‹¤.
    - ì˜¤ì§ í•´ë‹¹ ì¥ë©´ì˜ ì•„ì´ë””ì–´ë¥¼ **ë”ìš± ê°•í™”í•˜ê±°ë‚˜ ëª…í™•í•˜ê²Œ ì „ë‹¬**í•˜ëŠ” ë° ë„ì›€ì´ ëœë‹¤ê³  íŒë‹¨ë  ë•Œë§Œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    - ë§Œì•½ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œìœ¼ë¡œ ì¥ë©´ì„ ë¬˜ì‚¬í•˜ëŠ” ê²ƒì´ ë” ì°½ì˜ì ì´ê±°ë‚˜ íš¨ê³¼ì ì´ë¼ë©´, **ê³¼ê°í•˜ê²Œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.** ì´ ê²½ìš° **`reference_images` í‚¤ë¥¼ ì•„ì˜ˆ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”**(ë¹ˆ ë¦¬ìŠ¤íŠ¸ë„ ê¸ˆì§€).

    **2. ì°¸ì¡° ì´ë¯¸ì§€ ì‚¬ìš© ì‹œ ì¤€ìˆ˜ ì‚¬í•­ (Rules for When You *Do* Use an Image):**
    - **ë‘ ê°€ì§€ ì‘ì—…(`prompt_text`ì— @íƒœê·¸ í¬í•¨, `reference_images` ë¦¬ìŠ¤íŠ¸ ì±„ìš°ê¸°)ì„ í•œ ì„¸íŠ¸ë¡œ ë°˜ë“œì‹œ ìˆ˜í–‰**í•´ì•¼ í•©ë‹ˆë‹¤.
    - ìµœì¢… `reference_images` ë¦¬ìŠ¤íŠ¸ì—ëŠ” `analysis` í•„ë“œë¥¼ ì œì™¸í•˜ê³  `uri`ì™€ `tag`ë§Œ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.

    **3. ì°¸ì¡° ì´ë¯¸ì§€ê°€ ì²˜ìŒë¶€í„° ì—†ëŠ” ê²½ìš° (When No Images are Provided at All):**
    - 'ì‚¬ìš© ê°€ëŠ¥í•œ ì°¸ì¡° ì´ë¯¸ì§€ ì •ë³´'ê°€ ë¹„ì–´ìˆë‹¤ë©´, ëª¨ë“  ì¥ë©´ì—ì„œ `reference_images` í‚¤ë¥¼ ë„£ì§€ ë§ˆì„¸ìš”.

    ### ğŸ“ ìµœì¢… ì¶œë ¥ êµ¬ì¡° (StoryboardOutput)
    ë‹¹ì‹ ì€ ë°˜ë“œì‹œ ì•„ë˜ ì„¤ëª…ëœ `StoryboardOutput` ì „ì²´ êµ¬ì¡°ì— ë§ëŠ” JSON ê°ì²´ í•˜ë‚˜ë§Œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

    - `scenes` (í•„ìˆ˜): `SceneImagePrompt` êµ¬ì¡°ë¥¼ ë”°ë¥´ëŠ” ì¥ë©´ ê°ì²´ë“¤ì˜ ëª©ë¡.
    - `total_scenes` (í•„ìˆ˜): ìƒì„±ëœ ì´ ì¥ë©´ì˜ ìˆ˜ 3.
    - `estimated_duration` (í•„ìˆ˜): ì „ì²´ ì˜ìƒì˜ ì˜ˆìƒ ê¸¸ì´ (ì´ˆ ë‹¨ìœ„ ì •ìˆ˜, ì¥ë©´ë‹¹ 5ì´ˆë¡œ ê³„ì‚°).
    - `video_concept` (í•„ìˆ˜): ê´‘ê³  ì˜ìƒì˜ í•µì‹¬ ì»¨ì…‰ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½.

    [ìµœì¢… í™•ì¸ ì§€ì‹œ]
    ì¶œë ¥í•˜ê¸° ì „, ë‹¹ì‹ ì´ ìƒì„±í•œ JSONì´ ë‹¤ìŒ ì‚¬í•­ì„ ëª¨ë‘ ì¶©ì¡±í•˜ëŠ”ì§€ ë°˜ë“œì‹œ í™•ì¸í•˜ì‹­ì‹œì˜¤:
    - **Step1 í˜ë¥´ì†Œë‚˜ì˜ íƒ€ê²Ÿ ê³ ê° íŠ¹ì„±ì´ ëª¨ë“  ì¥ë©´ì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆê¹Œ?**
    - **Step2 ê´‘ê³  ì»¨ì…‰ì˜ í•µì‹¬ ë©”ì‹œì§€ê°€ ì‹œê°ì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆê¹Œ?**
    - **Step3 ì‚¬ìš©ì ì•„ì´ë””ì–´ê°€ ì¥ë©´ì˜ í•µì‹¬ ìš”ì†Œë¡œ ì‹¤í˜„ë˜ì—ˆìŠµë‹ˆê¹Œ?**
    - **3ê°œ ì¥ë©´ì´ ì„œë¡œ ì—°ê²°ë˜ì–´ í•˜ë‚˜ì˜ ì™„ì „í•œ ìŠ¤í† ë¦¬ë¥¼ êµ¬ì„±í•©ë‹ˆê¹Œ?**
    - `reference_images` ë¦¬ìŠ¤íŠ¸ì— ê°ì²´ê°€ ìˆë‹¤ë©´, ê°™ì€ ì¥ë©´ì˜ `prompt_text`ì— í•´ë‹¹ `@íƒœê·¸`ê°€ ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆê¹Œ?
    - ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì¥ë©´ì—ëŠ” `reference_images` í‚¤ê°€ ì—†ëŠ”ì§€ í™•ì¸í–ˆìŠµë‹ˆê¹Œ?
    """
    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)

    # ì‚¬ìš©ì ë©”ì‹œì§€ í…œí”Œë¦¿
    human_template = """
    ### ğŸ¯ Step1: íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ ì •ë³´ (í•„ìˆ˜ ë°˜ì˜)
    {persona_context}
    
    ### ğŸ’¡ Step2: ê´‘ê³  ì»¨ì…‰ ì •ë³´ (í•„ìˆ˜ ë°˜ì˜)
    {concept_context}
    
    ### âœï¸ Step3: ì‚¬ìš©ì ìµœì¢… ì•„ì´ë””ì–´ (ì‹¤í–‰ ë°©í–¥)
    ì‚¬ìš©ìê°€ ì…ë ¥í•œ êµ¬ì²´ì ì¸ ì•„ì´ë””ì–´: "{user_description}"
    
    ### ğŸ“¸ ì°¸ì¡° ì´ë¯¸ì§€ ì •ë³´ (ì„ íƒì  í™œìš©)
    {reference_info}
    
    ### ğŸš¨ í†µí•© ì§€ì‹œì‚¬í•­ ğŸš¨
    ìœ„ì˜ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì´ ìŠ¤í† ë¦¬ë³´ë“œë¥¼ ìƒì„±í•˜ì„¸ìš”:
    
    1. **í˜ë¥´ì†Œë‚˜ íƒ€ê²ŸíŒ…**: Step1ì˜ íƒ€ê²Ÿ ê³ ê° íŠ¹ì„±(ì—°ë ¹, ì„±ë³„, ê´€ì‹¬ì‚¬)ì´ ëª¨ë“  ì¥ë©´ì— ë°˜ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    2. **ì»¨ì…‰ ì¼ê´€ì„±**: Step2ì˜ ê´‘ê³  ì»¨ì…‰ê³¼ ë§ˆì¼€íŒ… ì „ëµì´ ì‹œê°ì ìœ¼ë¡œ êµ¬í˜„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    3. **ì•„ì´ë””ì–´ ì‹¤í˜„**: Step3ì˜ ì‚¬ìš©ì ì•„ì´ë””ì–´ê°€ í•µì‹¬ ìŠ¤í† ë¦¬ë¼ì¸ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    
    **ëª¨ë“  ì¥ë©´ì´ ì„œë¡œ ì—°ê²°ë˜ì–´ íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ì—ê²Œ ì–´í•„í•˜ëŠ” ì™„ì „í•œ ê´‘ê³  ìŠ¤í† ë¦¬ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.**
    
    ---
    ğŸ¬ ìµœì¢… í™•ì¸ ì²´í¬ë¦¬ìŠ¤íŠ¸:
    âœ… í˜ë¥´ì†Œë‚˜ì˜ íƒ€ê²Ÿ ê³ ê° íŠ¹ì„±ì´ ëª¨ë“  ì¥ë©´ì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆê¹Œ?
    âœ… ê´‘ê³  ì»¨ì…‰ì˜ í•µì‹¬ ë©”ì‹œì§€ê°€ ì‹œê°ì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆê¹Œ?
    âœ… ì‚¬ìš©ì ì•„ì´ë””ì–´ê°€ ìŠ¤í† ë¦¬ì˜ í•µì‹¬ìœ¼ë¡œ ì‹¤í˜„ë˜ì—ˆìŠµë‹ˆê¹Œ?
    âœ… 3ê°œ ì¥ë©´ì´ í•˜ë‚˜ì˜ ì™„ì „í•œ ê´‘ê³  ìŠ¤í† ë¦¬ë¥¼ êµ¬ì„±í•©ë‹ˆê¹Œ?
    
    ìœ„ ëª¨ë“  í•­ëª©ì„ í™•ì¸í•œ í›„, í†µí•©ëœ ì™„ì „í•œ ìŠ¤í† ë¦¬ë³´ë“œ JSON ê°ì²´ë¥¼ ìƒì„±í•´ì£¼ì‹­ì‹œì˜¤.
    """
    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)
    
    # ì²´ì¸ êµ¬ì„±
    storyboard_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
    structured_llm = text_llm.with_structured_output(StoryboardOutput)
    storyboard_chain = storyboard_prompt | structured_llm

    print(f"ğŸ¬ ì¥ë©´ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘... ì‚¬ìš©ì ì…ë ¥: '{user_description}'")
    
    # ì‚¬ìš©ì ì…ë ¥ì„ ë¡œê·¸ë¡œ ëª…í™•íˆ ì¶œë ¥
    print(f"ğŸ“ ì‹¤ì œ ì „ë‹¬ë˜ëŠ” ì‚¬ìš©ì ì…ë ¥: {user_description}")
    print(f"ğŸ“ ì‚¬ìš©ì ì…ë ¥ íƒ€ì…: {type(user_description)}")
    print(f"ğŸ“ ì‚¬ìš©ì ì…ë ¥ ê¸¸ì´: {len(user_description) if user_description else 0} ê¸€ì")
    print(f"ğŸ“¸ ì°¸ì¡° ì´ë¯¸ì§€ ê°œìˆ˜: {len(enriched_images) if enriched_images else 0}")
    
    # í˜ë¥´ì†Œë‚˜ ë° ì»¨ì…‰ ì •ë³´ ë¡œê·¸ ì¶œë ¥
    print(f"ğŸ¯ í˜ë¥´ì†Œë‚˜ ë°ì´í„° ì¡´ì¬: {bool(persona_data)}")
    if persona_data:
        print(f"   íƒ€ê²Ÿ ê³ ê° ì •ë³´: {persona_data.get('target_customer', {})}")
    print(f"ğŸ’¡ ê´‘ê³  ì»¨ì…‰ ì¡´ì¬: {bool(ad_concept)}")
    if ad_concept:
        print(f"   ê´‘ê³  ì»¨ì…‰ ë¯¸ë¦¬ë³´ê¸°: {ad_concept[:100]}...")
    
    result = await storyboard_chain.ainvoke({
        "user_description": user_description,
        "reference_info": reference_info,
        "persona_context": persona_context,
        "concept_context": concept_context,
    })

    print("âœ… ì¥ë©´ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
    print(f"ğŸ“Š ìƒì„±ëœ ì¥ë©´ ìˆ˜: {result.total_scenes}")
    print(f"ğŸ¯ ì²« ë²ˆì§¸ ì¥ë©´ í”„ë¡¬í”„íŠ¸: {result.scenes[0].prompt_text if result.scenes else 'None'}")
    return result

# ==================================================================================
"""ìŠ¤í† ë¦¬ë³´ë“œ ì¥ë©´ ì´ë¯¸ì§€ë¥¼ Runway APIë¡œ ìƒì„±"""
async def generate_images_sequentially(
    scenes: List[SceneImagePrompt],
    api_key: str
) -> List[Dict]:
    """ì—¬ëŸ¬ ì¥ë©´ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ 'ì§ë ¬'ë¡œ ì´ë¯¸ì§€ ìƒì„±ì„ ìš”ì²­í•˜ê³  ëª¨ë“  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json", "X-Runway-Version": "2024-11-06"}
    base_url = "https://api.dev.runwayml.com/v1"
    
    generated_images = []
    total_scenes = len(scenes)
    
    print(f"\nğŸš€ ì´ {total_scenes}ê°œì˜ ì´ë¯¸ì§€ ìƒì„±ì„ ì§ë ¬ë¡œ ì‹œì‘í•©ë‹ˆë‹¤...")

    for i, scene in enumerate(scenes):
        print(f"\n--- [ì¥ë©´ {i+1}/{total_scenes}] ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ ---")
        
        payload = scene.model_dump(by_alias=True, exclude_none=True)
        
        # ğŸ”§ Runway API í˜¸í™˜ì„±ì„ ìœ„í•œ í•„ìˆ˜ ê°’ë“¤ ê°•ì œ ìˆ˜ì •
        # 1. model í•„ë“œ ê°•ì œ ê³ ì • - í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±ìš© ëª¨ë¸ë¡œ ë³€ê²½
        payload["model"] = "gen4_image"
        print(f"ğŸ”§ API ìš”ì²­ ì „ model ê°•ì œ ì„¤ì •: {payload['model']}")
        
        # 2. ratio ê°’ ê°•ì œ ìˆ˜ì •
        if payload.get("ratio") not in ["1280:720", "720:1280", "1024:1024"]:
            old_ratio = payload.get("ratio", "unknown")
            payload["ratio"] = "1280:720"  # ê¸°ë³¸ê°’ìœ¼ë¡œ ê°•ì œ ë³€ê²½
            print(f"ğŸ”„ API ìš”ì²­ ì „ ratio ìˆ˜ì •: {old_ratio} â†’ {payload['ratio']}")
        
        # ì˜ëª»ëœ ì°¸ì¡° ì´ë¯¸ì§€ í•„í„°ë§ ë° ì•ˆì „ì¥ì¹˜
        if payload.get("referenceImages"):
            valid_ref_images = []
            for ref_img_dict in payload["referenceImages"]:
                # 'string'ì´ë‚˜ ì˜ëª»ëœ URI í•„í„°ë§
                if (ref_img_dict.get("uri") and 
                    ref_img_dict.get("uri") != "string" and 
                    ref_img_dict.get("uri").startswith(("http://", "https://")) and
                    ref_img_dict.get("tag") and 
                    ref_img_dict.get("tag") != "string"):
                    ref_img_dict["weight"] = 0.5
                    valid_ref_images.append(ref_img_dict)
                else:
                    print(f"âš ï¸ ì˜ëª»ëœ ì°¸ì¡° ì´ë¯¸ì§€ ì œì™¸: {ref_img_dict.get('uri')}")
            
            # ìœ íš¨í•œ ì°¸ì¡° ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ referenceImages í‚¤ ì œê±°
            if valid_ref_images:
                payload["referenceImages"] = valid_ref_images
            else:
                print("ğŸ”§ ëª¨ë“  ì°¸ì¡° ì´ë¯¸ì§€ê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                payload.pop("referenceImages", None)
        else:
            # ì°¸ì¡° ì´ë¯¸ì§€ê°€ ì—†ê±°ë‚˜ ë¹ˆ ë°°ì—´ì¸ ê²½ìš° í‚¤ ìì²´ë¥¼ ì œê±°
            print("ğŸ”§ ì°¸ì¡° ì´ë¯¸ì§€ê°€ ì—†ì–´ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            payload.pop("referenceImages", None)

        async with httpx.AsyncClient(timeout=180) as client:
            try:
                # 1. ì‘ì—… ìš”ì²­
                print(f"ğŸ“¤ Runway API ìš”ì²­: {scene.prompt_text[:40]}...")
                print(f"ğŸ” ì „ì†¡í•  payload: {payload}")  # ë””ë²„ê¹…ìš© ì¶œë ¥
                response = await client.post(f"{base_url}/text_to_image", headers=headers, json=payload)
                
                if response.status_code != 200:
                    raise Exception(f"API ìš”ì²­ ì‹¤íŒ¨: {response.text}")
                
                task_id = response.json()["id"]
                print(f"  -> ì‘ì—… ID: {task_id}")

                # 2. ì‘ì—… ì™„ë£Œê¹Œì§€ í´ë§
                for attempt in range(36):
                    print(f"â³ ì´ë¯¸ì§€ ìƒì„± ì§„í–‰ í™•ì¸ ì¤‘... ({attempt + 1}/{36})")
                    status_response = await client.get(f"{base_url}/tasks/{task_id}", headers=headers)
                    status_data = status_response.json()
                    status = status_data.get("status")
                    progress = status_data.get("progress", 0)
                    print(f"   ìƒíƒœ: {status}, ì§„í–‰ë„: {progress}%")

                    if status == "SUCCEEDED":
                        print(f"âœ… [ì¥ë©´ {i+1}] ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
                        generated_images.append({
                            "scene_index": i + 1,
                            "status": "success",
                            "url": status_data.get("output", [None])[0],  # ì´ë¯¸ì§€ URLë¡œ ì €ì¥
                            "image_url": status_data.get("output", [None])[0],  # í˜¸í™˜ì„±ì„ ìœ„í•œ ì¶”ê°€ í‚¤
                            "prompt": scene.prompt_text
                        })
                        break
                    elif status == "FAILED":
                        error_msg = status_data.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                        print(f"âŒ [ì¥ë©´ {i+1}] ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {error_msg}")
                        generated_images.append({"scene_index": i + 1, "status": "failed", "error": error_msg, "prompt": scene.prompt_text})
                        break
                    
                    await asyncio.sleep(5)
                else:
                    raise Exception("ì´ë¯¸ì§€ ìƒì„± ì‹œê°„ ì´ˆê³¼")

            except Exception as e:
                print(f"âŒ [ì¥ë©´ {i+1}] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                generated_images.append({"scene_index": i + 1, "status": "error", "error": str(e), "prompt": scene.prompt_text})

    print("\nğŸ‰ ëª¨ë“  ì´ë¯¸ì§€ ìƒì„± ì‘ì—… ì™„ë£Œ!")
    return generated_images

# ==================================================================================
"""ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„ : ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ ê´‘ê³  ì½˜ì…‰íŠ¸ ë° í¬ë¦¬ì—ì´í‹°ë¸Œ ë°©í–¥ì„±ì„ ë„ì¶œ"""
async def analyze_reference_images(reference_images: List[ReferenceImage]) -> List[dict]:
    if not reference_images:
        return []
    # ë¶„ì„ ê²°ê³¼ ì €ì¥í•  ë³€ìˆ˜
    analyzed_result = []
    
    for ref_image in reference_images:
        # ìœ íš¨í•˜ì§€ ì•Šì€ URI í•„í„°ë§ (string, ë¹ˆ ê°’, ì˜ëª»ëœ URL ë“±)
        if (not ref_image.uri or 
            ref_image.uri == "string" or 
            not ref_image.uri.startswith(("http://", "https://")) or
            not ref_image.tag or 
            ref_image.tag == "string"):
            print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ì°¸ì¡° ì´ë¯¸ì§€ ê±´ë„ˆë›°ê¸°: URI='{ref_image.uri}', TAG='{ref_image.tag}'")
            continue
            
        try:
            message = HumanMessage(
                content=[
                    {
                        "type": "text",
                        "text": f"""ì´ ì´ë¯¸ì§€ë¥¼ {ref_image.tag}ë¡œ ê´‘ê³ ì— í™œìš©í•˜ë ¤ê³  í•©ë‹ˆë‹¤.
                        ì£¼ìš” íŠ¹ì§•ê³¼ ê´‘ê³  í™œìš© í¬ì¸íŠ¸ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”"""
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": ref_image.uri,
                            "detail": "auto"  # lowì™€ highê°€ ìˆìŒ , í•µì‹¬ì€ ì´ë¯¸ì§€ì˜ ì„¸ë¶€ì ì¸ ë¶€ë¶„ê¹Œì§€ ë¶„ì„ì´ ê°€ëŠ¥í•˜ëƒë§ˆëƒì˜ ì°¨ì´
                        }
                    }
                ]
            )
            # LLMì— ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­
            result = await vision_llm.ainvoke([message])
            
            analyzed_result.append({
                "tag": ref_image.tag,
                "uri": ref_image.uri,
                "analysis": result.content
            })
            print(f"âœ… @{ref_image.tag} ë¶„ì„ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ @{ref_image.tag} ë¶„ì„ ì‹¤íŒ¨: {e}")
            analyzed_result.append({
                "tag": ref_image.tag,
                "uri": ref_image.uri,
                "analysis": "ì´ë¯¸ì§€ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            })
    
    return analyzed_result

# ==================================================================================
