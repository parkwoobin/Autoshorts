"""
ìŠ¤í† ë¦¬ë³´ë“œ â†’ Runway ì˜ìƒ â†’ TTS â†’ ìë§‰ â†’ ìµœì¢… ì˜ìƒ í†µí•© ì›Œí¬í”Œë¡œìš°
"""
import asyncio
import os
from typing import List, Dict, Any, Optional
from pathlib import Path
import tempfile

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from workflows import generate_scene_prompts, generate_images_sequentially, generate_persona, create_ad_concept
from models import StoryboardOutput, ReferenceImageWithDescription, TargetCustomer
from tts_utils import create_tts_audio, get_recommended_voice, detect_language, TTSConfig
from subtitle_utils import transcribe_audio_with_whisper, add_subtitles_to_video_ffmpeg, SubtitleResult
from video_merger import VideoTransitionMerger

class FullVideoWorkflow:
    """ì™„ì „í•œ ë¹„ë””ì˜¤ ì œì‘ ì›Œí¬í”Œë¡œìš° í´ë˜ìŠ¤"""
    
    def __init__(self, use_static_dir=True):
        self.use_static_dir = use_static_dir
        self.temp_dir = "./static/videos" if use_static_dir else tempfile.mkdtemp()
        os.makedirs(self.temp_dir, exist_ok=True)
        
        # API í‚¤ë“¤ ë¡œë“œ
        from dotenv import load_dotenv
        load_dotenv()
        
        self.api_keys = {
            "elevenlabs": os.getenv("ELEVNLABS_API_KEY"),
            "openai": os.getenv("OPENAI_API_KEY"),
            "runway": os.getenv("RUNWAY_API_KEY")
        }
        
        print("ğŸ¬ ì™„ì „í•œ ë¹„ë””ì˜¤ ì œì‘ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì™„ë£Œ")

    async def create_complete_video_from_storyboard(
        self,
        storyboard: StoryboardOutput,  # 1-4ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ìŠ¤í† ë¦¬ë³´ë“œ
        tts_scripts: List[str] = None,  # ê° ì¥ë©´ë³„ TTS ìŠ¤í¬ë¦½íŠ¸ (ì„ íƒì‚¬í•­)
        voice_preference: Dict[str, str] = None,  # ìŒì„± ì„ í˜¸ë„
        transition_type: str = "fade",  # íŠ¸ëœì§€ì…˜ íƒ€ì…
        add_subtitles: bool = True  # ìë§‰ ì¶”ê°€ ì—¬ë¶€
    ) -> Dict[str, Any]:
        """
        ìŠ¤í† ë¦¬ë³´ë“œë¶€í„° ìµœì¢… ìë§‰ í¬í•¨ ì˜ìƒê¹Œì§€ ì™„ì „í•œ ì œì‘ ê³¼ì •
        
        Args:
            storyboard: ìƒì„±ëœ ìŠ¤í† ë¦¬ë³´ë“œ
            tts_scripts: ê° ì¥ë©´ë³„ TTS ìŠ¤í¬ë¦½íŠ¸
            voice_preference: {"gender": "male/female", "language": "ko/en"}
            transition_type: ë¹„ë””ì˜¤ íŠ¸ëœì§€ì…˜ íƒ€ì…
            add_subtitles: ìë§‰ ì¶”ê°€ ì—¬ë¶€
            
        Returns:
            Dict: ìµœì¢… ê²°ê³¼ ì •ë³´
        """
        print(f"\nğŸ¬ ì™„ì „í•œ ë¹„ë””ì˜¤ ì œì‘ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
        print(f"   ì¥ë©´ ìˆ˜: {len(storyboard.scenes)}")
        print(f"   íŠ¸ëœì§€ì…˜: {transition_type}")
        print(f"   ìë§‰ ì¶”ê°€: {add_subtitles}")
        
        try:
            # 1ë‹¨ê³„: Runway APIë¡œ ìŠ¤í† ë¦¬ë³´ë“œì˜ ê° ì¥ë©´ì„ ì˜ìƒìœ¼ë¡œ ìƒì„±
            print(f"\nğŸ¥ 1ë‹¨ê³„: Runway APIë¡œ {len(storyboard.scenes)}ê°œ ì¥ë©´ ì˜ìƒ ìƒì„±...")
            video_results = await generate_images_sequentially(
                scenes=storyboard.scenes,
                api_key=self.api_keys["runway"]
            )
            
            # ì„±ê³µí•œ ì˜ìƒë“¤ë§Œ í•„í„°ë§
            successful_videos = []
            for result in video_results:
                if result.get("status") == "success" and result.get("image_url"):
                    successful_videos.append(result)
            
            if not successful_videos:
                return {"success": False, "error": "ì˜ìƒ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}
            
            print(f"âœ… {len(successful_videos)}/{len(storyboard.scenes)}ê°œ ì˜ìƒ ìƒì„± ì™„ë£Œ")
            
            # 2ë‹¨ê³„: TTS ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„
            print(f"\nğŸ™ï¸ 2ë‹¨ê³„: TTS ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„...")
            if not tts_scripts:
                # ê¸°ë³¸ TTS ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (ì¥ë©´ë³„ ê°„ë‹¨í•œ ì„¤ëª…)
                tts_scripts = await self.generate_default_tts_scripts(storyboard)
            
            # TTS ìŠ¤í¬ë¦½íŠ¸ì™€ ì˜ìƒ ê°œìˆ˜ ë§ì¶”ê¸°
            tts_scripts = tts_scripts[:len(successful_videos)]
            
            # 3ë‹¨ê³„: ìŒì„± ì„ íƒ
            print(f"\nğŸ¤ 3ë‹¨ê³„: ìµœì  ìŒì„± ì„ íƒ...")
            if not voice_preference:
                voice_preference = {"gender": "female", "language": "ko"}
            
            # ì²« ë²ˆì§¸ ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ê¶Œì¥ ìŒì„± ì„ íƒ
            sample_text = tts_scripts[0] if tts_scripts else "ì•ˆë…•í•˜ì„¸ìš”"
            voice_id = get_recommended_voice(sample_text, voice_preference.get("gender"))
            print(f"   ì„ íƒëœ ìŒì„±: {TTSConfig.VOICES.get(voice_id, voice_id)}")
            
            # 4ë‹¨ê³„: ê° ì˜ìƒì— TTS ì¶”ê°€
            print(f"\nğŸ”Š 4ë‹¨ê³„: {len(successful_videos)}ê°œ ì˜ìƒì— TTS ìŒì„± ì¶”ê°€...")
            videos_with_tts = []
            
            for i, (video_result, tts_script) in enumerate(zip(successful_videos, tts_scripts)):
                scene_num = i + 1
                print(f"   ì¥ë©´ {scene_num}: TTS ì¶”ê°€ ì¤‘...")
                
                try:
                    # ì˜ìƒ ë‹¤ìš´ë¡œë“œ
                    merger = VideoTransitionMerger(use_static_dir=True)
                    video_path = merger._download_video(
                        video_result["image_url"],
                        f"scene_{scene_num}_original.mp4"
                    )
                    
                    # TTS ì¶”ê°€
                    video_with_tts_path = await merger.add_tts_to_video(
                        video_path=video_path,
                        text=tts_script,
                        voice_id=voice_id,
                        tts_volume=0.8,
                        video_volume=0.2,
                        api_key=self.api_keys["elevenlabs"],
                        output_filename=f"scene_{scene_num}_with_tts.mp4"
                    )
                    
                    videos_with_tts.append({
                        "scene_number": scene_num,
                        "video_path": video_with_tts_path,
                        "tts_script": tts_script,
                        "original_video_url": video_result["image_url"]
                    })
                    
                    # ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ ì‚­ì œ
                    try:
                        os.remove(video_path)
                    except:
                        pass
                    
                    print(f"   âœ… ì¥ë©´ {scene_num} TTS ì¶”ê°€ ì™„ë£Œ")
                    
                except Exception as e:
                    print(f"   âŒ ì¥ë©´ {scene_num} TTS ì¶”ê°€ ì‹¤íŒ¨: {e}")
                    continue
            
            if not videos_with_tts:
                return {"success": False, "error": "TTS ì¶”ê°€ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}
            
            # 5ë‹¨ê³„: ì˜ìƒë“¤ì„ íŠ¸ëœì§€ì…˜ê³¼ í•¨ê»˜ í•©ì¹˜ê¸°
            print(f"\nğŸ”— 5ë‹¨ê³„: {len(videos_with_tts)}ê°œ ì˜ìƒì„ íŠ¸ëœì§€ì…˜ê³¼ í•¨ê»˜ í•©ì¹˜ê¸°...")
            
            # íŒŒì¼ ê²½ë¡œë¥¼ URLë¡œ ë³€í™˜
            video_urls = [f"file://{video['video_path']}" for video in videos_with_tts]
            
            merger = VideoTransitionMerger(use_static_dir=True)
            import time
            merged_filename = f"merged_complete_video_{int(time.time() * 1000)}.mp4"
            merged_video_path = merger.merge_videos(
                video_urls=video_urls,
                transition_type=transition_type,
                output_filename=merged_filename
            )
            
            print(f"âœ… ì˜ìƒ í•©ì¹˜ê¸° ì™„ë£Œ: {os.path.basename(merged_video_path)}")
            
            # 6ë‹¨ê³„: ìë§‰ ì¶”ê°€ (ì„ íƒì‚¬í•­)
            final_video_path = merged_video_path
            subtitle_info = None
            
            if add_subtitles:
                print(f"\nğŸ“ 6ë‹¨ê³„: ìë§‰ ìƒì„± ë° ì¶”ê°€...")
                
                # ì „ì²´ TTS ìŠ¤í¬ë¦½íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
                full_script = " ".join(tts_scripts)
                
                # ì²« ë²ˆì§¸ ì¥ë©´ì˜ TTS ìŒì„± íŒŒì¼ë¡œ ìë§‰ ìƒì„± (ëŒ€í‘œ)
                try:
                    # ì„ì‹œ TTS íŒŒì¼ ìƒì„± (ìë§‰ìš©)
                    from tts_utils import create_tts_audio
                    temp_tts_result = await create_tts_audio(
                        text=full_script,
                        voice_id=voice_id,
                        api_key=self.api_keys["elevenlabs"],
                        output_dir="./static/audio"
                    )
                    
                    if temp_tts_result.success:
                        # Whisperë¡œ ìë§‰ ìƒì„±
                        subtitle_result = await transcribe_audio_with_whisper(
                            audio_file_path=temp_tts_result.audio_file_path,
                            language=voice_preference.get("language", "ko"),
                            api_key=self.api_keys["openai"],
                            output_format="srt"
                        )
                        
                        if subtitle_result.success:
                            # FFmpegë¡œ ìë§‰ í•©ì„±
                            final_result = add_subtitles_to_video_ffmpeg(
                                video_file_path=merged_video_path,
                                subtitle_file_path=subtitle_result.subtitle_file_path,
                                language=voice_preference.get("language", "ko")
                            )
                            
                            if final_result.success:
                                final_video_path = final_result.video_with_subtitle_path
                                subtitle_info = {
                                    "subtitle_file": subtitle_result.subtitle_file_path,
                                    "transcription": subtitle_result.transcription
                                }
                                print(f"âœ… ìë§‰ ì¶”ê°€ ì™„ë£Œ")
                            else:
                                print(f"âš ï¸ ìë§‰ í•©ì„± ì‹¤íŒ¨: {final_result.error}")
                        else:
                            print(f"âš ï¸ ìë§‰ ìƒì„± ì‹¤íŒ¨: {subtitle_result.error}")
                        
                        # ì„ì‹œ TTS íŒŒì¼ ì‚­ì œ
                        try:
                            os.remove(temp_tts_result.audio_file_path)
                        except:
                            pass
                    else:
                        print(f"âš ï¸ ìë§‰ìš© TTS ìƒì„± ì‹¤íŒ¨: {temp_tts_result.error}")
                        
                except Exception as e:
                    print(f"âš ï¸ ìë§‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # 7ë‹¨ê³„: ì„ì‹œ íŒŒì¼ ì •ë¦¬
            print(f"\nğŸ§¹ 7ë‹¨ê³„: ì„ì‹œ íŒŒì¼ ì •ë¦¬...")
            cleanup_count = 0
            for video_info in videos_with_tts:
                try:
                    os.remove(video_info["video_path"])
                    cleanup_count += 1
                except:
                    pass
            
            # ìë§‰ì´ ì¶”ê°€ëœ ê²½ìš° ì›ë³¸ í•©ì¹œ ë¹„ë””ì˜¤ë„ ì‚­ì œ
            if add_subtitles and final_video_path != merged_video_path:
                try:
                    os.remove(merged_video_path)
                    cleanup_count += 1
                except:
                    pass
            
            print(f"âœ… {cleanup_count}ê°œ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
            
            # ìµœì¢… ê²°ê³¼ ë°˜í™˜
            final_video_url = f"http://localhost:8000/static/videos/{os.path.basename(final_video_path)}"
            
            result = {
                "success": True,
                "final_video_path": final_video_path,
                "final_video_url": final_video_url,
                "video_concept": storyboard.video_concept,
                "total_scenes": len(successful_videos),
                "tts_scripts": tts_scripts,
                "voice_used": TTSConfig.VOICES.get(voice_id, voice_id),
                "transition_type": transition_type,
                "has_subtitles": add_subtitles and subtitle_info is not None,
                "processing_summary": {
                    "scenes_generated": len(successful_videos),
                    "scenes_with_tts": len(videos_with_tts),
                    "final_video_created": True,
                    "subtitles_added": subtitle_info is not None
                }
            }
            
            if subtitle_info:
                result["subtitle_info"] = subtitle_info
            
            print(f"\nğŸ‰ ì™„ì „í•œ ë¹„ë””ì˜¤ ì œì‘ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!")
            print(f"   ìµœì¢… ì˜ìƒ: {final_video_url}")
            
            return result
            
        except Exception as e:
            error_msg = f"ë¹„ë””ì˜¤ ì œì‘ ì›Œí¬í”Œë¡œìš° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
            print(f"âŒ {error_msg}")
            return {"success": False, "error": error_msg}

    async def generate_default_tts_scripts(self, storyboard: StoryboardOutput) -> List[str]:
        """ìŠ¤í† ë¦¬ë³´ë“œ ê¸°ë°˜ìœ¼ë¡œ ê¸°ë³¸ TTS ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        print("ğŸ“ ê¸°ë³¸ TTS ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
        
        # ê°„ë‹¨í•œ í…œí”Œë¦¿ ê¸°ë°˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        scripts = []
        for i, scene in enumerate(storyboard.scenes, 1):
            if i == 1:
                script = f"ì•ˆë…•í•˜ì„¸ìš”! ë†€ë¼ìš´ AI ì˜ìƒì„ ì†Œê°œí•©ë‹ˆë‹¤."
            elif i == len(storyboard.scenes):
                script = f"ì§€ê¸ˆ ë°”ë¡œ í™•ì¸í•´ë³´ì„¸ìš”!"
            else:
                script = f"ë‹¤ìŒ ì¥ë©´ì„ ê³„ì† í™•ì¸í•´ì£¼ì„¸ìš”."
            
            scripts.append(script)
        
        print(f"âœ… {len(scripts)}ê°œ ê¸°ë³¸ TTS ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ")
        return scripts

    def get_workflow_status(self) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            "api_keys_status": {
                "elevenlabs": bool(self.api_keys["elevenlabs"]),
                "openai": bool(self.api_keys["openai"]),
                "runway": bool(self.api_keys["runway"])
            },
            "temp_dir": self.temp_dir,
            "use_static_dir": self.use_static_dir,
            "available_voices": len(TTSConfig.VOICES),
            "supported_languages": ["ko", "en", "multilingual"]
        }

# ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
def create_video_workflow(use_static_dir=True) -> FullVideoWorkflow:
    """ë¹„ë””ì˜¤ ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return FullVideoWorkflow(use_static_dir=use_static_dir)

# ê°„í¸ ì‚¬ìš©ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜
async def create_complete_video(
    storyboard: StoryboardOutput,
    tts_scripts: List[str] = None,
    voice_gender: str = "female",
    voice_language: str = "ko",
    transition_type: str = "fade",
    add_subtitles: bool = True
) -> Dict[str, Any]:
    """
    ìŠ¤í† ë¦¬ë³´ë“œë¥¼ ìµœì¢… ìë§‰ í¬í•¨ ì˜ìƒìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê°„í¸ í•¨ìˆ˜
    
    Args:
        storyboard: ìƒì„±ëœ ìŠ¤í† ë¦¬ë³´ë“œ
        tts_scripts: TTS ìŠ¤í¬ë¦½íŠ¸ ë¦¬ìŠ¤íŠ¸
        voice_gender: ìŒì„± ì„±ë³„ ("male", "female")
        voice_language: ìŒì„± ì–¸ì–´ ("ko", "en")
        transition_type: íŠ¸ëœì§€ì…˜ íƒ€ì…
        add_subtitles: ìë§‰ ì¶”ê°€ ì—¬ë¶€
        
    Returns:
        Dict: ì²˜ë¦¬ ê²°ê³¼
    """
    workflow = create_video_workflow()
    
    voice_preference = {
        "gender": voice_gender,
        "language": voice_language
    }
    
    return await workflow.create_complete_video_from_storyboard(
        storyboard=storyboard,
        tts_scripts=tts_scripts,
        voice_preference=voice_preference,
        transition_type=transition_type,
        add_subtitles=add_subtitles
    )
