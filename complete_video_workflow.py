"""
ìŠ¤í† ë¦¬ë³´ë“œ â†’ Runway ì˜ìƒ â†’ TTS â†’ ìë§‰ â†’ ìµœì¢… ì˜ìƒ í†µí•© ì›Œí¬í”Œë¡œìš°
"""
from dotenv import load_dotenv
load_dotenv()

import asyncio
import os
import subprocess
import re
from typing import List, Dict, Any, Optional
from pathlib import Path
import tempfile
import httpx

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from workflows import generate_scene_prompts, generate_images_sequentially, generate_persona, create_ad_concept
from models import StoryboardOutput, ReferenceImageWithDescription, TargetCustomer
from tts_utils import create_tts_audio, get_recommended_voice, detect_language, TTSConfig
from subtitle_utils import transcribe_audio_with_whisper, add_subtitles_to_video_ffmpeg, SubtitleResult
from video_merger import VideoTransitionMerger
import time

class FullVideoWorkflow:
    """ì™„ì „í•œ ë¹„ë””ì˜¤ ì œì‘ ì›Œí¬í”Œë¡œìš° í´ë˜ìŠ¤"""
    
    def __init__(self, use_static_dir=True):
        self.use_static_dir = use_static_dir
        self.temp_dir = "./static/videos" if use_static_dir else tempfile.mkdtemp()
        os.makedirs(self.temp_dir, exist_ok=True)
        
        # ìë§‰ ë””ë ‰í† ë¦¬ë„ ìƒì„±
        self.subtitle_dir = "./static/subtitles"
        os.makedirs(self.subtitle_dir, exist_ok=True)
        
        # API í‚¤ë“¤ ë¡œë“œ
        from dotenv import load_dotenv
        load_dotenv()
        
        self.api_keys = {
            "elevenlabs": os.getenv("ELEVNLABS_API_KEY"),
            "openai": os.getenv("OPENAI_API_KEY"),
            "runway": os.getenv("RUNWAY_API_KEY")
        }
        
        print("ğŸ¬ ì™„ì „í•œ ë¹„ë””ì˜¤ ì œì‘ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì™„ë£Œ")

    async def create_complete_video_from_storyboard(
        self,
        storyboard: StoryboardOutput,  # 1-4ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ìŠ¤í† ë¦¬ë³´ë“œ
        tts_scripts: List[str] = None,  # ê° ì¥ë©´ë³„ TTS ìŠ¤í¬ë¦½íŠ¸ (ì„ íƒì‚¬í•­)
        voice_preference: Dict[str, str] = None,  # ìŒì„± ì„ í˜¸ë„
        transition_type: str = "fade",  # íŠ¸ëœì§€ì…˜ íƒ€ì…
        add_subtitles: bool = True  # ìë§‰ ì¶”ê°€ ì—¬ë¶€
    ) -> Dict[str, Any]:
        """
        ìŠ¤í† ë¦¬ë³´ë“œë¶€í„° ìµœì¢… ìë§‰ í¬í•¨ ì˜ìƒê¹Œì§€ ì™„ì „í•œ ì œì‘ ê³¼ì •
        
        Args:
            storyboard: ìƒì„±ëœ ìŠ¤í† ë¦¬ë³´ë“œ
            tts_scripts: ê° ì¥ë©´ë³„ TTS ìŠ¤í¬ë¦½íŠ¸
            voice_preference: {"gender": "male/female", "language": "ko/en"}
            transition_type: ë¹„ë””ì˜¤ íŠ¸ëœì§€ì…˜ íƒ€ì…
            add_subtitles: ìë§‰ ì¶”ê°€ ì—¬ë¶€
            
        Returns:
            Dict: ìµœì¢… ê²°ê³¼ ì •ë³´
        """
        print(f"\nğŸ¬ ì™„ì „í•œ ë¹„ë””ì˜¤ ì œì‘ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
        print(f"   ì¥ë©´ ìˆ˜: {len(storyboard.scenes)}")
        print(f"   íŠ¸ëœì§€ì…˜: {transition_type}")
        print(f"   ìë§‰ ì¶”ê°€: {add_subtitles}")
        
        try:
            # 1ë‹¨ê³„: Runway APIë¡œ ìŠ¤í† ë¦¬ë³´ë“œì˜ ê° ì¥ë©´ì„ ì˜ìƒìœ¼ë¡œ ìƒì„±
            print(f"\nğŸ¥ 1ë‹¨ê³„: Runway APIë¡œ {len(storyboard.scenes)}ê°œ ì¥ë©´ ì˜ìƒ ìƒì„±...")
            video_results = await generate_images_sequentially(
                scenes=storyboard.scenes,
                api_key=self.api_keys["runway"]
            )
            
            # ì„±ê³µí•œ ì˜ìƒë“¤ë§Œ í•„í„°ë§
            successful_videos = []
            for result in video_results:
                if result.get("status") == "success" and result.get("image_url"):
                    successful_videos.append(result)
            
            if not successful_videos:
                return {"success": False, "error": "ì˜ìƒ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}
            
            print(f"âœ… {len(successful_videos)}/{len(storyboard.scenes)}ê°œ ì˜ìƒ ìƒì„± ì™„ë£Œ")
            
            # 2ë‹¨ê³„: TTS ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„
            print(f"\nğŸ™ï¸ 2ë‹¨ê³„: TTS ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„...")
            if not tts_scripts:
                # ê¸°ë³¸ TTS ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (ì¥ë©´ë³„ ê°„ë‹¨í•œ ì„¤ëª…)
                tts_scripts = await self.generate_default_tts_scripts(storyboard)
            
            # TTS ìŠ¤í¬ë¦½íŠ¸ì™€ ì˜ìƒ ê°œìˆ˜ ë§ì¶”ê¸°
            tts_scripts = tts_scripts[:len(successful_videos)]
            
            # 3ë‹¨ê³„: ìŒì„± ì„ íƒ
            print(f"\nğŸ¤ 3ë‹¨ê³„: ìµœì  ìŒì„± ì„ íƒ...")
            if not voice_preference:
                voice_preference = {"gender": "female", "language": "ko"}
            
            # ì²« ë²ˆì§¸ ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ê¶Œì¥ ìŒì„± ì„ íƒ
            sample_text = tts_scripts[0] if tts_scripts else "ì•ˆë…•í•˜ì„¸ìš”"
            voice_id = get_recommended_voice(sample_text, voice_preference.get("gender"))
            print(f"   ì„ íƒëœ ìŒì„±: {TTSConfig.VOICES.get(voice_id, voice_id)}")
            
            # 4ë‹¨ê³„: ê° ì˜ìƒì— TTS ì¶”ê°€
            print(f"\nğŸ”Š 4ë‹¨ê³„: {len(successful_videos)}ê°œ ì˜ìƒì— TTS ìŒì„± ì¶”ê°€...")
            videos_with_tts = []
            
            for i, (video_result, tts_script) in enumerate(zip(successful_videos, tts_scripts)):
                scene_num = i + 1
                print(f"   ì¥ë©´ {scene_num}: TTS ì¶”ê°€ ì¤‘...")
                
                try:
                    # ì˜ìƒ ë‹¤ìš´ë¡œë“œ
                    merger = VideoTransitionMerger(use_static_dir=True)
                    video_path = merger._download_video(
                        video_result["image_url"],
                        f"scene_{scene_num}_original.mp4"
                    )
                    
                    # TTS ì¶”ê°€
                    video_with_tts_path = await merger.add_tts_to_video(
                        video_path=video_path,
                        text=tts_script,
                        voice_id=voice_id,
                        tts_volume=0.8,
                        video_volume=0.2,
                        api_key=self.api_keys["elevenlabs"],
                        output_filename=f"scene_{scene_num}_with_tts.mp4"
                    )
                    
                    videos_with_tts.append({
                        "scene_number": scene_num,
                        "video_path": video_with_tts_path,
                        "tts_script": tts_script,
                        "original_video_url": video_result["image_url"]
                    })
                    
                    # ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ ì‚­ì œ
                    try:
                        os.remove(video_path)
                    except:
                        pass
                    
                    print(f"   âœ… ì¥ë©´ {scene_num} TTS ì¶”ê°€ ì™„ë£Œ")
                    
                except Exception as e:
                    print(f"   âŒ ì¥ë©´ {scene_num} TTS ì¶”ê°€ ì‹¤íŒ¨: {e}")
                    continue
            
            if not videos_with_tts:
                return {"success": False, "error": "TTS ì¶”ê°€ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}
            
            # 5ë‹¨ê³„: ì˜ìƒë“¤ì„ íŠ¸ëœì§€ì…˜ê³¼ í•¨ê»˜ í•©ì¹˜ê¸°
            print(f"\nğŸ”— 5ë‹¨ê³„: {len(videos_with_tts)}ê°œ ì˜ìƒì„ íŠ¸ëœì§€ì…˜ê³¼ í•¨ê»˜ í•©ì¹˜ê¸°...")
            
            # íŒŒì¼ ê²½ë¡œë¥¼ URLë¡œ ë³€í™˜
            video_urls = [f"file://{video['video_path']}" for video in videos_with_tts]
            
            merger = VideoTransitionMerger(use_static_dir=True)
            import time
            merged_filename = f"merged_complete_video_{int(time.time() * 1000)}.mp4"
            merged_video_path = merger.merge_videos(
                video_urls=video_urls,
                transition_type=transition_type,
                output_filename=merged_filename
            )
            
            print(f"âœ… ì˜ìƒ í•©ì¹˜ê¸° ì™„ë£Œ: {os.path.basename(merged_video_path)}")
            
            # 6ë‹¨ê³„: ìë§‰ ì¶”ê°€ (ì„ íƒì‚¬í•­)
            final_video_path = merged_video_path
            subtitle_info = None
            
            if add_subtitles:
                print(f"\nğŸ“ 6ë‹¨ê³„: FFmpegì™€ Whisperë¡œ .srt ìë§‰ ìƒì„± ë° ì¶”ê°€...")
                
                try:
                    # TTS ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œë“¤ ìˆ˜ì§‘
                    tts_audio_files = []
                    for video_info in videos_with_tts:
                        # ê° ì¥ë©´ì˜ TTS ìŠ¤í¬ë¦½íŠ¸ë¡œ ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„±
                        temp_tts_result = await create_tts_audio(
                            text=video_info["tts_script"],
                            voice_id=voice_id,
                            api_key=self.api_keys["elevenlabs"],
                            output_dir="./static/audio"
                        )
                        
                        if temp_tts_result.success:
                            tts_audio_files.append(temp_tts_result.audio_file_path)
                    
                    if tts_audio_files:
                        # FFmpegì™€ Whisperë¡œ .srt ìë§‰ ìƒì„±
                        srt_filename = f"subtitles_{int(time.time() * 1000)}.srt"
                        srt_path = os.path.join("./static/subtitles", srt_filename)
                        
                        subtitle_result = await self.create_srt_from_tts_with_ffmpeg(
                            tts_audio_files=tts_audio_files,
                            output_srt_path=srt_path
                        )
                        
                        if subtitle_result.success:
                            # FFmpegë¡œ ìë§‰ì„ ë¹„ë””ì˜¤ì— í•©ì„±
                            from subtitle_utils import add_subtitles_to_video_ffmpeg
                            final_result = add_subtitles_to_video_ffmpeg(
                                video_file_path=merged_video_path,
                                subtitle_file_path=subtitle_result.subtitle_file_path,
                                language="ko"
                            )
                            
                            if final_result.success:
                                final_video_path = final_result.video_with_subtitle_path
                                subtitle_info = {
                                    "subtitle_file": subtitle_result.subtitle_file_path,
                                    "subtitle_url": f"/static/subtitles/{srt_filename}",
                                    "transcription": subtitle_result.transcription
                                }
                                print(f"âœ… FFmpeg .srt ìë§‰ ìƒì„± ë° í•©ì„± ì™„ë£Œ")
                            else:
                                print(f"âš ï¸ ìë§‰ ë¹„ë””ì˜¤ í•©ì„± ì‹¤íŒ¨: {final_result.error}")
                        else:
                            print(f"âš ï¸ .srt ìë§‰ ìƒì„± ì‹¤íŒ¨: {subtitle_result.error}")
                        
                        # ì„ì‹œ TTS íŒŒì¼ë“¤ ì •ë¦¬
                        for audio_file in tts_audio_files:
                            try:
                                os.remove(audio_file)
                            except:
                                pass
                    else:
                        print(f"âš ï¸ TTS ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
                        
                except Exception as e:
                    print(f"âš ï¸ FFmpeg ìë§‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # 7ë‹¨ê³„: ì„ì‹œ íŒŒì¼ ì •ë¦¬
            print(f"\nğŸ§¹ 7ë‹¨ê³„: ì„ì‹œ íŒŒì¼ ì •ë¦¬...")
            cleanup_count = 0
            for video_info in videos_with_tts:
                try:
                    os.remove(video_info["video_path"])
                    cleanup_count += 1
                except:
                    pass
            
            # ìë§‰ì´ ì¶”ê°€ëœ ê²½ìš° ì›ë³¸ í•©ì¹œ ë¹„ë””ì˜¤ë„ ì‚­ì œ
            if add_subtitles and final_video_path != merged_video_path:
                try:
                    os.remove(merged_video_path)
                    cleanup_count += 1
                except:
                    pass
            
            print(f"âœ… {cleanup_count}ê°œ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
            
            # ìµœì¢… ê²°ê³¼ ë°˜í™˜
            final_video_url = f"http://localhost:8000/static/videos/{os.path.basename(final_video_path)}"
            
            result = {
                "success": True,
                "final_video_path": final_video_path,
                "final_video_url": final_video_url,
                "video_concept": storyboard.video_concept,
                "total_scenes": len(successful_videos),
                "tts_scripts": tts_scripts,
                "voice_used": TTSConfig.VOICES.get(voice_id, voice_id),
                "transition_type": transition_type,
                "has_subtitles": add_subtitles and subtitle_info is not None,
                "processing_summary": {
                    "scenes_generated": len(successful_videos),
                    "scenes_with_tts": len(videos_with_tts),
                    "final_video_created": True,
                    "subtitles_added": subtitle_info is not None
                }
            }
            
            if subtitle_info:
                result["subtitle_info"] = subtitle_info
            
            print(f"\nğŸ‰ ì™„ì „í•œ ë¹„ë””ì˜¤ ì œì‘ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!")
            print(f"   ìµœì¢… ì˜ìƒ: {final_video_url}")
            
            return result
            
        except Exception as e:
            error_msg = f"ë¹„ë””ì˜¤ ì œì‘ ì›Œí¬í”Œë¡œìš° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
            print(f"âŒ {error_msg}")
            return {"success": False, "error": error_msg}

    async def generate_default_tts_scripts(self, storyboard: StoryboardOutput) -> List[str]:
        """ìŠ¤í† ë¦¬ë³´ë“œ ê¸°ë°˜ìœ¼ë¡œ ê¸°ë³¸ TTS ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        print("ğŸ“ ê¸°ë³¸ TTS ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
        
        # ê°„ë‹¨í•œ í…œí”Œë¦¿ ê¸°ë°˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        scripts = []
        for i, scene in enumerate(storyboard.scenes, 1):
            if i == 1:
                script = f"ì•ˆë…•í•˜ì„¸ìš”! ë†€ë¼ìš´ AI ì˜ìƒì„ ì†Œê°œí•©ë‹ˆë‹¤."
            elif i == len(storyboard.scenes):
                script = f"ì§€ê¸ˆ ë°”ë¡œ í™•ì¸í•´ë³´ì„¸ìš”!"
            else:
                script = f"ë‹¤ìŒ ì¥ë©´ì„ ê³„ì† í™•ì¸í•´ì£¼ì„¸ìš”."
            
            scripts.append(script)
        
        print(f"âœ… {len(scripts)}ê°œ ê¸°ë³¸ TTS ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ")
        return scripts

    def get_workflow_status(self) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            "api_keys_status": {
                "elevenlabs": bool(self.api_keys["elevenlabs"]),
                "openai": bool(self.api_keys["openai"]),
                "runway": bool(self.api_keys["runway"])
            },
            "temp_dir": self.temp_dir,
            "use_static_dir": self.use_static_dir,
            "available_voices": len(TTSConfig.VOICES),
            "supported_languages": ["ko", "en", "multilingual"]
        }

    async def create_srt_from_tts_with_ffmpeg(
        self,
        tts_audio_files: List[str],
        output_srt_path: str,
        scene_durations: List[float] = None
    ) -> SubtitleResult:
        """
        TTS ìŒì„± íŒŒì¼ë“¤ì„ FFmpegì™€ Whisperë¡œ .srt ìë§‰ íŒŒì¼ ìƒì„±
        
        Args:
            tts_audio_files: TTS ìŒì„± íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            output_srt_path: ì¶œë ¥ .srt íŒŒì¼ ê²½ë¡œ
            scene_durations: ê° ì¥ë©´ë³„ ì§€ì† ì‹œê°„ (ì´ˆ)
            
        Returns:
            SubtitleResult: ìë§‰ ìƒì„± ê²°ê³¼
        """
        print(f"ğŸ“ TTS ìŒì„±ì—ì„œ FFmpegë¡œ .srt ìë§‰ ìƒì„± ì‹œì‘...")
        print(f"   ì…ë ¥ ìŒì„± íŒŒì¼: {len(tts_audio_files)}ê°œ")
        print(f"   ì¶œë ¥ .srt íŒŒì¼: {output_srt_path}")
        
        try:
            # 1ë‹¨ê³„: FFmpegë¡œ ëª¨ë“  TTS íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
            temp_merged_audio = os.path.join(self.temp_dir, "merged_tts_for_subtitle.wav")
            
            # FFmpeg ëª…ë ¹ì–´ë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ í•©ì¹˜ê¸°
            ffmpeg_exe = r'C:\Users\oi3oi\AppData\Local\Microsoft\WinGet\Packages\BtbN.FFmpeg.GPL_Microsoft.Winget.Source_8wekyb3d8bbwe\ffmpeg-N-120061-gcfd1f81e7d-win64-gpl\bin\ffmpeg.exe'
            
            if len(tts_audio_files) == 1:
                # íŒŒì¼ì´ í•˜ë‚˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                temp_merged_audio = tts_audio_files[0]
            else:
                # ì—¬ëŸ¬ íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
                print("ğŸ”— FFmpegë¡œ TTS ìŒì„± íŒŒì¼ë“¤ í•©ì¹˜ëŠ” ì¤‘...")
                
                # concat í•„í„°ë¥¼ ìœ„í•œ ì…ë ¥ ì¤€ë¹„
                inputs = []
                filter_complex = []
                
                for i, audio_file in enumerate(tts_audio_files):
                    inputs.extend(["-i", audio_file])
                    filter_complex.append(f"[{i}:0]")
                
                concat_cmd = [
                    ffmpeg_exe,
                    *inputs,
                    "-filter_complex", f"{''.join(filter_complex)}concat=n={len(tts_audio_files)}:v=0:a=1[out]",
                    "-map", "[out]",
                    "-y",  # ë®ì–´ì“°ê¸°
                    temp_merged_audio
                ]
                
                result = subprocess.run(
                    concat_cmd,
                    capture_output=True,
                    text=True,
                    encoding='utf-8'
                )
                
                if result.returncode != 0:
                    raise Exception(f"FFmpeg ìŒì„± í•©ì¹˜ê¸° ì‹¤íŒ¨: {result.stderr}")
                
                print("âœ… TTS ìŒì„± íŒŒì¼ í•©ì¹˜ê¸° ì™„ë£Œ")
            
            # 2ë‹¨ê³„: Whisperë¡œ ì „ì‚¬í•˜ì—¬ .srt ìƒì„±
            print("ğŸ¤– Whisper AIë¡œ ìŒì„± ì „ì‚¬ ë° .srt ìƒì„± ì¤‘...")
            
            # OpenAI Whisper API í˜¸ì¶œ
            headers = {
                "Authorization": f"Bearer {self.api_keys['openai']}"
            }
            
            with open(temp_merged_audio, "rb") as audio_file:
                files = {
                    "file": audio_file,
                    "model": (None, "whisper-1"),
                    "response_format": (None, "srt"),  # .srt í˜•ì‹ìœ¼ë¡œ ì§ì ‘ ìš”ì²­
                    "language": (None, "ko")  # í•œêµ­ì–´ë¡œ ì„¤ì •
                }
                
                async with httpx.AsyncClient(timeout=120.0) as client:
                    response = await client.post(
                        "https://api.openai.com/v1/audio/transcriptions",
                        headers=headers,
                        files=files
                    )
                    
                    if response.status_code != 200:
                        raise Exception(f"Whisper API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                    
                    # .srt í˜•ì‹ì˜ ì‘ë‹µ ì§ì ‘ ì €ì¥
                    srt_content = response.text
                    
                    # .srt íŒŒì¼ ì €ì¥
                    os.makedirs(os.path.dirname(output_srt_path), exist_ok=True)
                    with open(output_srt_path, "w", encoding="utf-8") as f:
                        f.write(srt_content)
                    
                    print(f"âœ… .srt ìë§‰ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_srt_path}")
                    
                    # 3ë‹¨ê³„: ì„ì‹œ íŒŒì¼ ì •ë¦¬
                    if temp_merged_audio != tts_audio_files[0]:  # í•©ì¹œ íŒŒì¼ì¸ ê²½ìš°ì—ë§Œ ì‚­ì œ
                        try:
                            os.remove(temp_merged_audio)
                        except:
                            pass
                    
                    # ì „ì‚¬ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ (SRTì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±°)
                    import re
                    transcription_lines = []
                    for line in srt_content.split('\n'):
                        if not re.match(r'^\d+$', line.strip()) and not re.match(r'^[\d:,\s\-\>]+$', line.strip()) and line.strip():
                            transcription_lines.append(line.strip())
                    
                    transcription = ' '.join(transcription_lines)
                    
                    return SubtitleResult(
                        success=True,
                        subtitle_file_path=output_srt_path,
                        transcription=transcription,
                        language="ko"
                    )
        
        except Exception as e:
            error_msg = f"TTSì—ì„œ .srt ìƒì„± ì‹¤íŒ¨: {e}"
            print(f"âŒ {error_msg}")
            return SubtitleResult(success=False, error=error_msg)
            
# ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
def create_video_workflow(use_static_dir=True) -> FullVideoWorkflow:
    """ë¹„ë””ì˜¤ ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return FullVideoWorkflow(use_static_dir=use_static_dir)

# ê°„í¸ ì‚¬ìš©ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜
async def create_complete_video(
    storyboard: StoryboardOutput,
    tts_scripts: List[str] = None,
    voice_gender: str = "female",
    voice_language: str = "ko",
    transition_type: str = "fade",
    add_subtitles: bool = True
) -> Dict[str, Any]:
    """
    ìŠ¤í† ë¦¬ë³´ë“œë¥¼ ìµœì¢… ìë§‰ í¬í•¨ ì˜ìƒìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê°„í¸ í•¨ìˆ˜
    
    Args:
        storyboard: ìƒì„±ëœ ìŠ¤í† ë¦¬ë³´ë“œ
        tts_scripts: TTS ìŠ¤í¬ë¦½íŠ¸ ë¦¬ìŠ¤íŠ¸
        voice_gender: ìŒì„± ì„±ë³„ ("male", "female")
        voice_language: ìŒì„± ì–¸ì–´ ("ko", "en")
        transition_type: íŠ¸ëœì§€ì…˜ íƒ€ì…
        add_subtitles: ìë§‰ ì¶”ê°€ ì—¬ë¶€
        
    Returns:
        Dict: ì²˜ë¦¬ ê²°ê³¼
    """
    workflow = create_video_workflow()
    
    voice_preference = {
        "gender": voice_gender,
        "language": voice_language
    }
    
    return await workflow.create_complete_video_from_storyboard(
        storyboard=storyboard,
        tts_scripts=tts_scripts,
        voice_preference=voice_preference,
        transition_type=transition_type,
        add_subtitles=add_subtitles
    )
