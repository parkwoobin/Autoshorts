"""
ê°„ì†Œí™”ëœ ë¹„ë””ì˜¤ ì„œë²„: íŠ¸ëœì§€ì…˜ ë° ë¹„ë””ì˜¤ í•©ì¹˜ê¸° ì „ìš©
ë…ë¦½ì ì¸ FastAPI ì„œë²„
"""
import uvicorn
import os
import httpx
import asyncio
import re
import time
import traceback
import shutil
from fastapi import FastAPI, HTTPException, Body
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
from typing import List, Optional

# ë¡œì»¬ ëª¨ë“ˆ import
from video_models import (
    VideoGenerationInput, VideoGenerationResult, VideoMergeRequest, 
    VideoMergeResult, TransitionMergeRequest, SubtitleCustomRequest,
    BGMGenerationRequest, TTSSubtitleRequest  # BGMê³¼ TTS ëª¨ë¸ ì¶”ê°€
)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

print("ğŸ”‘ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ")
print(f"   ELEVENLABS_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('ELEVENLABS_API_KEY') else 'âŒ ì—†ìŒ'}")
print(f"   OPENAI_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('OPENAI_API_KEY') else 'âŒ ì—†ìŒ'}")
print(f"   RUNWAY_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('RUNWAY_API_KEY') else 'âŒ ì—†ìŒ'}")
print(f"   SUNO_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('SUNO_API_KEY') else 'âŒ ì—†ìŒ'}")

# ë¹„ë””ì˜¤ ì„œë²„ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ import
from video_server_utils import (
    create_merger_instance,
    generate_output_filename,
    create_video_response,
    get_transition_description
)
from video_models import VideoMergeRequest, VideoConfig, TransitionMergeRequest, SubtitleCustomRequest

# ë¹„ë””ì˜¤ ì²˜ë¦¬ ìƒíƒœ ì¶”ì ì„ ìœ„í•œ ê¸€ë¡œë²Œ ë³€ìˆ˜
video_processing_status = {
    "is_processing": False,
    "current_step": "",
    "progress": 0,
    "total_steps": 0,
    "current_file": "",
    "start_time": None,
    "estimated_completion": None
}

# TTSì™€ ìë§‰ ê´€ë ¨ importëŠ” try-exceptë¡œ ì²˜ë¦¬
try:
    from tts_utils import create_tts_audio, create_multiple_tts_audio, get_elevenlabs_api_key
    TTS_AVAILABLE = True
except ImportError:
    print("âš ï¸ TTS ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. TTS ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    TTS_AVAILABLE = False

try:
    from subtitle_utils import generate_subtitles_with_whisper, merge_video_with_subtitles, merge_video_with_tts_and_subtitles
    SUBTITLE_AVAILABLE = True
except ImportError:
    print("âš ï¸ ìë§‰ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìë§‰ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    SUBTITLE_AVAILABLE = False

# SUNO BGM ìƒì„± í•¨ìˆ˜ë“¤
async def generate_suno_bgm(keyword: str = "happy", duration: int = 70):
    """SUNO APIë¥¼ ì‚¬ìš©í•œ BGM ìƒì„± (ìµœëŒ€ 70ì´ˆ)"""
    # ìµœëŒ€ 70ì´ˆë¡œ ì œí•œ
    if duration > 70:
        duration = 70
        print(f"âš ï¸ BGM ê¸¸ì´ê°€ 70ì´ˆë¡œ ì œí•œë©ë‹ˆë‹¤.")
    
    api_key = os.getenv('SUNO_API_KEY')
    if not api_key:
        raise HTTPException(status_code=500, detail="SUNO_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    api_endpoint = "https://api.sunoapi.org/api/v1/generate"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # Custom Mode í˜ì´ë¡œë“œ
    payload = {
        "prompt": f"{keyword} upbeat band music with energetic guitar riffs, uplifting drums, positive vibes",
        "style": f"{keyword} rock band",
        "title": f"Happy {keyword.title()} Band Music",
        "customMode": True,
        "instrumental": True,
        "model": "V4",
        "callBackUrl": "https://api.example.com/callback"
    }
    
    async with httpx.AsyncClient(timeout=180.0) as client:
        response = await client.post(api_endpoint, headers=headers, json=payload)
        
        if response.status_code == 200:
            data = response.json()
            if "data" in data and data["data"] is not None and "taskId" in data["data"]:
                return data["data"]["taskId"]
            else:
                raise HTTPException(status_code=500, detail="íƒœìŠ¤í¬ IDë¥¼ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            error_text = response.text
            raise HTTPException(status_code=response.status_code, detail=f"SUNO API ì˜¤ë¥˜: {error_text}")

async def check_suno_task_and_download(task_id: str):
    """SUNO íƒœìŠ¤í¬ ìƒíƒœ í™•ì¸ ë° BGM ë‹¤ìš´ë¡œë“œ"""
    api_key = os.getenv('SUNO_API_KEY')
    status_endpoint = f"https://api.sunoapi.org/api/v1/generate/record-info?taskId={task_id}"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    async with httpx.AsyncClient(timeout=60.0) as client:
        response = await client.get(status_endpoint, headers=headers)
        
        if response.status_code == 200:
            data = response.json()
            print(f"ğŸ” SUNO API ì‘ë‹µ: {data}")
            
            if not data or "data" not in data or data["data"] is None:
                return {"success": False, "status": "pending", "message": "ì‘ë‹µ ë°ì´í„°ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ì…ë‹ˆë‹¤..."}
            
            data_obj = data["data"]
            status = data_obj.get("status", "unknown")
            
            if "response" not in data_obj or data_obj["response"] is None:
                return {"success": False, "status": status, "message": "BGM ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."}
            
            response_data = data_obj["response"]
            
            if "sunoData" not in response_data or response_data["sunoData"] is None:
                return {"success": False, "status": status, "message": "BGM ë°ì´í„°ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ì…ë‹ˆë‹¤..."}
            
            suno_data = response_data["sunoData"]
            
            if status == "SUCCESS" and suno_data and len(suno_data) > 0:
                # ì²« ë²ˆì§¸ í´ë¦½ ë‹¤ìš´ë¡œë“œ (ë‘ ê°œê°€ ìˆì„ ê²½ìš° ë” ì§§ì€ ë²„ì „ ì„ íƒ)
                if len(suno_data) >= 2:
                    clip = suno_data[0] if suno_data[0].get('duration', 0) < suno_data[1].get('duration', 0) else suno_data[1]
                else:
                    clip = suno_data[0]
                
                audio_url = clip.get('audioUrl')
                
                if audio_url:
                    # BGM ë‹¤ìš´ë¡œë“œ
                    audio_response = await client.get(audio_url)
                    if audio_response.status_code == 200:
                        # íŒŒì¼ ì €ì¥
                        os.makedirs("static/audio", exist_ok=True)
                        bgm_filename = f"suno_bgm_{task_id[:8]}.mp3"
                        bgm_path = os.path.join("static/audio", bgm_filename)
                        
                        with open(bgm_path, "wb") as f:
                            f.write(audio_response.content)
                        
                        return {
                            "success": True,
                            "bgm_path": bgm_path,
                            "bgm_filename": bgm_filename,
                            "duration": clip.get('duration', 0),
                            "title": clip.get('title', ''),
                            "tags": clip.get('tags', '')
                        }
                    else:
                        raise HTTPException(status_code=500, detail="BGM ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
                else:
                    raise HTTPException(status_code=500, detail="ì˜¤ë””ì˜¤ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                return {"success": False, "status": status, "message": "BGM ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."}
                
        else:
            error_text = response.text
            raise HTTPException(status_code=response.status_code, detail=f"íƒœìŠ¤í¬ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {error_text}")

# FastAPI app ìƒì„±
app = FastAPI(title="Video Server", description="ë¹„ë””ì˜¤ ìƒì„± ë° í•©ì¹˜ê¸° ì„œë²„")

# ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì • (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
import os
static_dir = os.path.join(os.path.dirname(__file__), "static")
app.mount("/static", StaticFiles(directory=static_dir), name="static")

# client.pyì˜ ëª¨ë¸ë“¤ê³¼ ì›Œí¬í”Œë¡œìš° í•¨ìˆ˜ë“¤ import (1-4ë‹¨ê³„ìš©)
try:
    from models import (
        TargetCustomer, PersonaData, UserVideoInput,
        ReferenceImage, SceneImagePrompt, ReferenceImageWithDescription
    )
    from workflows import (
        generate_persona, create_ad_concept,
        generate_scene_prompts, generate_images_sequentially
    )
    CLIENT_MODELS_AVAILABLE = True
    print("âœ… client.py ëª¨ë¸ë“¤ê³¼ ì›Œí¬í”Œë¡œìš° í•¨ìˆ˜ë“¤ import ì™„ë£Œ")
except ImportError as e:
    CLIENT_MODELS_AVAILABLE = False
    print(f"âš ï¸ client.py ëª¨ë¸ë“¤ import ì‹¤íŒ¨: {e}")

# ì „ì—­ ë³€ìˆ˜ë¡œ í”„ë¡œì íŠ¸ ë°ì´í„° ì €ì¥ (client.pyì™€ ë™ì¼)
current_project = {
    "persona": None,
    "reference_images": [],
    "analyzed_images": None,
    "ad_concept": None,
    "user_video_input": None,
    "storyboard": None,
    "images": None,
    "generated_videos": None,
    "tts_result": None
}

def check_environment_variables():
    """í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ì²´í¬"""
    required_vars = {
        "ELEVENLABS_API_KEY": "ElevenLabs TTS ì„œë¹„ìŠ¤ìš©",
        "OPENAI_API_KEY": "OpenAI LLM ì„œë¹„ìŠ¤ìš©", 
        "RUNWAY_API_KEY": "Runway ë¹„ë””ì˜¤ ìƒì„±ìš©",
        "SUNO_API_KEY": "SUNO ìŒì„± ìƒì„±ìš©"
    }
    
    missing_vars = []
    for var_name, description in required_vars.items():
        if not os.getenv(var_name):
            missing_vars.append(f"{var_name} ({description})")
    
    if missing_vars:
        print("âŒ ëˆ„ë½ëœ í™˜ê²½ë³€ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤:")
        for var in missing_vars:
            print(f"   - {var}")
        print("\nğŸ’¡ .env íŒŒì¼ì— ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•´ì£¼ì„¸ìš”:")
        for var_name in required_vars.keys():
            if not os.getenv(var_name):
                print(f"   {var_name}=your_api_key_here")
    else:
        print("âœ… ëª¨ë“  í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")

# ì„œë²„ ì‹œì‘ ì‹œ í™˜ê²½ë³€ìˆ˜ ì²´í¬
check_environment_variables()

# ==================================================================================
# 1-4ë‹¨ê³„: client.py ì›Œí¬í”Œë¡œìš° í†µí•©
# ==================================================================================

@app.post("/step1/target-customer")
async def submit_target_customer(customer: TargetCustomer):
    """1ë‹¨ê³„: íƒ€ê²Ÿ ê³ ê° ì •ë³´ë¥¼ ë°›ì•„ LLMìœ¼ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„±"""
    if not CLIENT_MODELS_AVAILABLE:
        raise HTTPException(status_code=500, detail="client.py ëª¨ë¸ë“¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    try:
        # LLMìœ¼ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„±
        persona_data = await generate_persona(customer)
        # í”„ë¡œì íŠ¸ ìƒíƒœì— ì €ì¥
        current_project["persona"] = persona_data.model_dump()
        
        print(f"âœ… 1ë‹¨ê³„ ì™„ë£Œ: í˜ë¥´ì†Œë‚˜ ìƒì„± ì„±ê³µ")
        print(f"   íƒ€ê²Ÿ ê³ ê°: {customer.country}, {customer.age_range}")
        
        return {
            "step": "1ë‹¨ê³„_í˜ë¥´ì†Œë‚˜_ìƒì„±",
            "success": True,
            "message": "íƒ€ê²Ÿ ê³ ê° ë¶„ì„í•˜ì—¬ í˜ë¥´ì†Œë‚˜ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "persona": persona_data
        }
    except Exception as e:
        print(f"âŒ 1ë‹¨ê³„ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"1ë‹¨ê³„ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.post("/step2/generate-ad-concept-with-images")
async def generate_ad_concept_with_images(reference_images: Optional[List[ReferenceImage]] = Body(None)):
    """2ë‹¨ê³„: Reference Image ì—…ë¡œë“œ + Persona â†’ Overall Ad Concept ìƒì„±"""
    if not CLIENT_MODELS_AVAILABLE:
        raise HTTPException(status_code=500, detail="client.py ëª¨ë¸ë“¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    if not current_project["persona"]:
        raise HTTPException(status_code=400, detail="ë¨¼ì € 1ë‹¨ê³„ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
    
    try:
        persona = PersonaData(**current_project["persona"])
        
        processed_reference_images = []
        if reference_images:
            current_project["reference_images"] = [img.model_dump() for img in reference_images]
            processed_reference_images = reference_images
        else:
            current_project["reference_images"] = []
        
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ê´‘ê³  ì»¨ì…‰ ìƒì„±
        concept_result = await create_ad_concept(persona, processed_reference_images)
        ad_concept = concept_result["ad_concept"]
        image_analyses_result = concept_result["image_analyses"]

        # í˜„ì¬ í”„ë¡œì íŠ¸ ìƒíƒœì— ê°ê° ì €ì¥
        current_project["ad_concept"] = ad_concept
        current_project["analyzed_images"] = image_analyses_result
        
        print(f"âœ… 2ë‹¨ê³„ ì™„ë£Œ: ê´‘ê³  ì»¨ì…‰ ìƒì„± ì„±ê³µ")
        print(f"   ì°¸ì¡° ì´ë¯¸ì§€: {len(processed_reference_images)}ê°œ")
        print(f"   ê´‘ê³  ì»¨ì…‰: {ad_concept[:50]}...")
        
        return {
            "step": "2ë‹¨ê³„_ê´‘ê³ _ì»¨ì…‰_ìƒì„±",
            "success": True,
            "message": "ì°¸ì¡° ì´ë¯¸ì§€ ë¶„ì„ ë° ê´‘ê³  ì»¨ì…‰ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "ad_concept": ad_concept,
            "uploaded_images_count": len(processed_reference_images),
            "image_analyses": image_analyses_result
        }
    except Exception as e:
        print(f"âŒ 2ë‹¨ê³„ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"2ë‹¨ê³„ ê´‘ê³  ì»¨ì…‰ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.post("/step3/video-input")
async def set_user_video_input(video_input: UserVideoInput):
    """3ë‹¨ê³„: ì‚¬ìš©ìê°€ ê´‘ê³  ì»¨ì…‰ì„ ìˆ˜ì •í•˜ì—¬ ìµœì¢… í™•ì •í•œ ë¹„ë””ì˜¤ ë‚´ìš© ì…ë ¥"""
    if not CLIENT_MODELS_AVAILABLE:
        raise HTTPException(status_code=500, detail="client.py ëª¨ë¸ë“¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    if not current_project["persona"]:
        raise HTTPException(status_code=400, detail="ë¨¼ì € 1ë‹¨ê³„ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
    
    try:
        # ì‚¬ìš©ìê°€ ì…ë ¥í•˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš°, 2ë‹¨ê³„ ad_conceptì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
        if not video_input.user_description or not video_input.user_description.strip():
            if current_project.get("ad_concept"):
                video_input.user_description = current_project["ad_concept"]
            else:
                raise HTTPException(status_code=400, detail="ê´‘ê³  ì»¨ì…‰ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 2ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # ì‚¬ìš©ì ì…ë ¥ ì €ì¥
        current_project["user_video_input"] = video_input.model_dump()
        stored_reference_images = current_project.get("analyzed_images", [])
        
        print(f"âœ… 3ë‹¨ê³„ ì™„ë£Œ: ì‚¬ìš©ì ë¹„ë””ì˜¤ ì…ë ¥ ì €ì¥")
        print(f"   ì‚¬ìš©ì ì„¤ëª…: {video_input.user_description[:50]}...")
        
        return {
            "step": "3ë‹¨ê³„_ì‚¬ìš©ì_ë¹„ë””ì˜¤_ì…ë ¥",
            "success": True,
            "message": "ê´‘ê³  ì˜ìƒ ì œì‘ì„ ìœ„í•œ ìµœì¢… í”„ë¡¬í”„íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "video_input": video_input,
            "reference_images": stored_reference_images,
        }
    except Exception as e:
        print(f"âŒ 3ë‹¨ê³„ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"3ë‹¨ê³„ ì‚¬ìš©ì ì…ë ¥ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

@app.post("/step3/generate-storyboard")
async def generate_storyboard_prompts():
    """3ë‹¨ê³„: LLMì´ ê´‘ê³  ì˜ìƒ ì œì‘ ì•„ì´ë””ì–´ë¥¼ ë³´ê³  ì¥ë©´ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±"""
    if not CLIENT_MODELS_AVAILABLE:
        raise HTTPException(status_code=500, detail="client.py ëª¨ë¸ë“¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # í•„ìš”í•œ ë°ì´í„°ê°€ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
    if not current_project["persona"]:
        raise HTTPException(status_code=400, detail="ë¨¼ì € 1ë‹¨ê³„(í˜ë¥´ì†Œë‚˜ ìƒì„±)ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
    
    if not current_project["user_video_input"]:
        raise HTTPException(status_code=400, detail="ì‚¬ìš©ìë¡œë¶€í„° ê´‘ê³  ì˜ìƒ ì œì‘ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥ë°›ìœ¼ì„¸ìš”.")
    
    try:
        # ëª¨ë“  í•„ìš”í•œ ë°ì´í„° ìˆ˜ì§‘
        persona_data = current_project.get("persona")
        ad_concept = current_project.get("ad_concept", "")
        user_input = current_project.get("user_video_input")
        analyzed_images = current_project.get("analyzed_images", [])

        # ì‚¬ìš©ì ì…ë ¥ ë°ì´í„° ì¶”ì¶œ
        user_input_text = user_input["user_description"]
        
        print(f"ğŸ¬ 3ë‹¨ê³„: ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„± ì‹œì‘...")
        print(f"   ì‚¬ìš©ì ì…ë ¥: {user_input_text[:50]}...")
        print(f"   ì°¸ì¡° ì´ë¯¸ì§€: {len(analyzed_images)}ê°œ")
        
        # ì°¸ì¡° ì´ë¯¸ì§€ ê°ì²´ ë³€í™˜
        enriched_images = [
            ReferenceImageWithDescription(**img_data) for img_data in analyzed_images
        ]
        
        # LLMìœ¼ë¡œ ì¥ë©´ë³„ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±
        storyboard_prompts = await generate_scene_prompts(
            user_description=user_input_text,
            enriched_images=enriched_images,
            persona_data=persona_data,
            ad_concept=ad_concept
        )
        
        # ìŠ¤í† ë¦¬ë³´ë“œ ì €ì¥
        current_project["storyboard"] = storyboard_prompts.model_dump()
        
        print(f"âœ… 3ë‹¨ê³„ ì™„ë£Œ: ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„± ì„±ê³µ")
        print(f"   ìƒì„±ëœ ì¥ë©´: {len(storyboard_prompts.scenes)}ê°œ")
        
        return {
            "step": "3ë‹¨ê³„_ìŠ¤í† ë¦¬ë³´ë“œ_ìƒì„±",
            "success": True,
            "message": "ìŠ¤í† ë¦¬ë³´ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "storyboard": storyboard_prompts
        }
    except Exception as e:
        print(f"âŒ 3ë‹¨ê³„ ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"3ë‹¨ê³„ ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.post("/step4/generate-images")
async def run_image_generation(
    scenes_input: Optional[List[SceneImagePrompt]] = Body(None, alias="scenes")
):
    """4ë‹¨ê³„: ìŠ¤í† ë¦¬ë³´ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ DALL-E 3 ì´ë¯¸ì§€ ìƒì„±"""
    if not CLIENT_MODELS_AVAILABLE:
        raise HTTPException(status_code=500, detail="client.py ëª¨ë¸ë“¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    try:
        # ìƒì„±í•  ì¥ë©´ ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„
        scenes_to_process = []
        
        # ìš°ì„ ìˆœìœ„: ì €ì¥ëœ ìŠ¤í† ë¦¬ë³´ë“œ > ìš”ì²­ ë³¸ë¬¸
        if current_project.get("storyboard"):
            print("âœ… ì €ì¥ëœ ìŠ¤í† ë¦¬ë³´ë“œì—ì„œ ì¥ë©´ì„ ê°€ì ¸ì™€ ì´ë¯¸ì§€ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            storyboard_data = current_project["storyboard"]
            scenes_to_process = [SceneImagePrompt(**scene_data) for scene_data in storyboard_data.get("scenes", [])]
            print(f"ğŸ“Š ì´ {len(scenes_to_process)}ê°œ ì¥ë©´ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            
            # Runway API í˜¸í™˜ì„±ì„ ìœ„í•œ ratio ê°’ ê²€ì¦ ë° ìˆ˜ì •
            valid_ratios = ["1280:720", "720:1280", "1024:1024"]
            for scene in scenes_to_process:
                if scene.ratio not in valid_ratios:
                    old_ratio = scene.ratio
                    scene.ratio = "1280:720"  # ê¸°ë³¸ê°’ìœ¼ë¡œ ë³€ê²½
                    print(f"ğŸ”„ ratio ìˆ˜ì •: {old_ratio} â†’ {scene.ratio}")
                    
        elif scenes_input:
            print("â„¹ï¸ ìš”ì²­ ë³¸ë¬¸ì—ì„œ ì§ì ‘ ë°›ì€ ì¥ë©´ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            scenes_to_process = scenes_input
        else:
            raise HTTPException(
                status_code=400, 
                detail="ìƒì„±í•  ì¥ë©´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 3ë‹¨ê³„(ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±)ë¥¼ ì™„ë£Œí•˜ê±°ë‚˜ scenes ë°ì´í„°ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."
            )

        if not scenes_to_process:
            raise HTTPException(status_code=400, detail="ìƒì„±í•  ì¥ë©´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # API í‚¤ í™•ì¸
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            raise HTTPException(status_code=500, detail="OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        print(f"ğŸ¨ 4ë‹¨ê³„: DALL-E 3 ì´ë¯¸ì§€ ìƒì„± ì‹œì‘...")
        
        # DALL-E 3 ì´ë¯¸ì§€ ìƒì„±
        generated_images = await generate_images_sequentially(
            scenes=scenes_to_process,
            api_key=openai_api_key
        )
        
        # ê²°ê³¼ í†µê³„ ê³„ì‚°
        successful_count = sum(1 for r in generated_images if r.get('status') == 'success')
        failed_count = len(generated_images) - successful_count
        total_scenes = len(generated_images)
        success_rate = f"{(successful_count / total_scenes) * 100:.1f}%" if total_scenes > 0 else "0%"

        # 4ë‹¨ê³„ ê²°ê³¼ë¥¼ current_projectì— ì €ì¥ (5ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•¨)
        current_project["images"] = generated_images
        print(f"âœ… 4ë‹¨ê³„ ì™„ë£Œ: DALL-E 3 ì´ë¯¸ì§€ ìƒì„± ì„±ê³µ ({successful_count}ê°œ ì„±ê³µ)")

        return {
            "step": "4ë‹¨ê³„_ì´ë¯¸ì§€_ìƒì„±",
            "success": True,
            "message": "ìŠ¤í† ë¦¬ë³´ë“œ ì´ë¯¸ì§€ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "generated_images": generated_images,
            "summary": {
                "total_scenes": total_scenes,
                "successful": successful_count,
                "failed": failed_count,
                "success_rate": success_rate
            }
        }
    except Exception as e:
        print(f"âŒ 4ë‹¨ê³„ ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"4ë‹¨ê³„ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.post("/step5/generate-videos")
async def run_video_generation():
    """5ë‹¨ê³„: 4ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ë“¤ì„ Runway APIë¡œ ë¹„ë””ì˜¤ ë³€í™˜"""
    return await generate_videos()

# ==================================================================================
# ê¸°ì¡´ 5-8ë‹¨ê³„ ì—”ë“œí¬ì¸íŠ¸ë“¤
# ==================================================================================

@app.get("/tts-selector", response_class=HTMLResponse)
async def tts_voice_selector():
    """TTS ìŒì„± ì„ íƒ ì›¹ ì¸í„°í˜ì´ìŠ¤"""
    try:
        with open("static/tts_voice_selector.html", "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    except FileNotFoundError:
        return HTMLResponse(
            content="<h1>TTS Voice Selector not found</h1>", 
            status_code=404
        )

@app.get("/video/processing-status")
async def get_processing_status():
    """ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ì²˜ë¦¬ ìƒíƒœ í™•ì¸ (ê°„ë‹¨í•œ í˜•íƒœ)"""
    
    processing_info = {
        "is_processing": video_processing_status["is_processing"],
        "current_step": video_processing_status["current_step"],
        "progress": video_processing_status["progress"],
        "current_file": video_processing_status["current_file"]
    }
    
    if video_processing_status["start_time"] and video_processing_status["is_processing"]:
        elapsed_time = time.time() - video_processing_status["start_time"]
        processing_info["elapsed_time_seconds"] = int(elapsed_time)
        processing_info["elapsed_time_formatted"] = f"{int(elapsed_time // 60)}ë¶„ {int(elapsed_time % 60)}ì´ˆ"
        
        # ë‚¨ì€ ì‹œê°„ ì¶”ì • (ê°„ë‹¨í•œ ë°©ì‹)
        if video_processing_status["progress"] > 0:
            estimated_total_time = elapsed_time * (100 / video_processing_status["progress"])
            remaining_time = max(0, estimated_total_time - elapsed_time)
            processing_info["estimated_remaining_seconds"] = int(remaining_time)
            processing_info["estimated_remaining_formatted"] = f"{int(remaining_time // 60)}ë¶„ {int(remaining_time % 60)}ì´ˆ"
    
    return processing_info

@app.get("/video/status")
async def get_video_status():
    """ë¹„ë””ì˜¤ ê¸°ëŠ¥ ìƒíƒœ í™•ì¸"""
    
    # í˜„ì¬ ì²˜ë¦¬ ìƒíƒœ ì •ë³´ ê³„ì‚°
    processing_info = {
        "is_processing": video_processing_status["is_processing"],
        "current_step": video_processing_status["current_step"],
        "progress": video_processing_status["progress"],
        "current_file": video_processing_status["current_file"]
    }
    
    if video_processing_status["start_time"]:
        elapsed_time = time.time() - video_processing_status["start_time"]
        processing_info["elapsed_time_seconds"] = int(elapsed_time)
        processing_info["elapsed_time_formatted"] = f"{int(elapsed_time // 60)}ë¶„ {int(elapsed_time % 60)}ì´ˆ"
    
    return {
        "status": "active",
        "message": "ğŸ¬ ShortPilot AI ë¹„ë””ì˜¤ ìƒì„± íŒŒì´í”„ë¼ì¸ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "processing_status": processing_info,
        "available_endpoints": {
            "GET /video/status": "ğŸ  í˜„ì¬ í˜ì´ì§€ - ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸",
            "GET /video/processing-status": "â³ ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ì²˜ë¦¬ ìƒíƒœ í™•ì¸ (ì§„í–‰ë¥ , ë‚¨ì€ ì‹œê°„ ë“±)",
            
            "ğŸ“Š 1ë‹¨ê³„: í˜ë¥´ì†Œë‚˜ ë¶„ì„": {
                "POST /step1/target-customer": "íƒ€ê²Ÿ ê³ ê° ì •ë³´ â†’ LLM í˜ë¥´ì†Œë‚˜ ìƒì„±"
            },
            
            "ğŸ’¡ 2ë‹¨ê³„: ê´‘ê³  ì»¨ì…‰ ìƒì„±": {
                "POST /step2/generate-ad-concept-with-images": "í˜ë¥´ì†Œë‚˜ + ì°¸ì¡° ì´ë¯¸ì§€ â†’ ê´‘ê³  ì»¨ì…‰ ìƒì„±"
            },
            
            "âœï¸ 3ë‹¨ê³„: ì‚¬ìš©ì ì…ë ¥ & ìŠ¤í† ë¦¬ë³´ë“œ": {
                "POST /step3/video-input": "ì‚¬ìš©ì ê´‘ê³  ì•„ì´ë””ì–´ ì…ë ¥",
                "POST /step3/generate-storyboard": "ì‚¬ìš©ì ì•„ì´ë””ì–´ â†’ LLM ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±"
            },
            
            "ğŸ¨ 4ë‹¨ê³„: ì´ë¯¸ì§€ ìƒì„±": {
                "POST /step4/generate-images": "ìŠ¤í† ë¦¬ë³´ë“œ â†’ DALL-E 3 ì´ë¯¸ì§€ ìƒì„±"
            },
            
            "ğŸ¬ 5ë‹¨ê³„: ì´ë¯¸ì§€ â†’ ë¹„ë””ì˜¤ ë³€í™˜": {
                "POST /video/generate-videos": "Runway APIë¥¼ í†µí•œ 4ë‹¨ê³„ ì´ë¯¸ì§€ë“¤ â†’ ë¹„ë””ì˜¤ ë³€í™˜"
            },
            
            "ğŸµ 5.5ë‹¨ê³„: BGM ìƒì„±": {
                "POST /bgm/generate-and-wait": "ğŸ†• í‚¤ì›Œë“œ ê¸°ë°˜ BGM ìƒì„± ë° ìë™ ì™„ì„± (ìµœëŒ€ 70ì´ˆ, íŒŒì¼ê¹Œì§€ ìë™ ë‹¤ìš´ë¡œë“œ)"
            },
            
            "âœ‚ï¸ 6ë‹¨ê³„: ë¹„ë””ì˜¤ + BGM í•©ì¹˜ê¸°": {
                "POST /video/merge-with-transitions": "5ë‹¨ê³„ ë¹„ë””ì˜¤ë“¤ì„ ëœë¤ íŠ¸ëœì§€ì…˜ìœ¼ë¡œ í•©ì¹˜ê¸° (BGM on/off ì„ íƒ ê°€ëŠ¥)"
            },
            
            "ğŸ™ï¸ 7ë‹¨ê³„: TTS ìŒì„± ìƒì„±": {
                "POST /video/create-tts-from-storyboard": "OpenAI LLM + ElevenLabsë¥¼ í†µí•œ ìŠ¤í† ë¦¬ë³´ë“œ ê¸°ë°˜ TTS ë‚´ë ˆì´ì…˜ ìë™ ìƒì„±"
            },
            
            "ğŸµ SUNO BGM ì‹œìŠ¤í…œ": {
                "GET /bgm/status/{task_id}": "BGM ìƒì„± ìƒíƒœ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ"
            },
            
            "ğŸ“ 8ë‹¨ê³„: ì™„ì „í•œ ì˜ìƒ ì œì‘": {
                "POST /video/generate-subtitles": "8-1ë‹¨ê³„: TTS ì˜¤ë””ì˜¤ì—ì„œ Whisperë¡œ ìë§‰ íŒŒì¼(.srt) ìƒì„±",
                "POST /video/merge-with-tts-subtitles": "8-2ë‹¨ê³„: ë¹„ë””ì˜¤ + TTS + ìë§‰ ì™„ì „ í•©ì¹˜ê¸°",
                "POST /video/merge-with-custom-subtitles": "ğŸ¨ ì»¤ìŠ¤í…€ ìë§‰: SRT íŒŒì¼ê³¼ í°íŠ¸ ì„¤ì •ìœ¼ë¡œ ìë§‰ ì»¤ìŠ¤í„°ë§ˆì´ì§•"
            },
            
            "ğŸ› ï¸ ìœ í‹¸ë¦¬í‹°": {
                "GET /tts-selector": "TTS ìŒì„± ì„ íƒ ì›¹ ì¸í„°í˜ì´ìŠ¤"
            }
        },
        "workflow_steps": {
            "1ë‹¨ê³„": "íƒ€ê²Ÿ ê³ ê° ì •ë³´ â†’ LLM í˜ë¥´ì†Œë‚˜ ìƒì„±",
            "2ë‹¨ê³„": "í˜ë¥´ì†Œë‚˜ + ì°¸ì¡° ì´ë¯¸ì§€ â†’ ê´‘ê³  ì»¨ì…‰ ìƒì„±",
            "3ë‹¨ê³„": "ì‚¬ìš©ì ì•„ì´ë””ì–´ â†’ LLM ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±",
            "4ë‹¨ê³„": "ìŠ¤í† ë¦¬ë³´ë“œ â†’ DALL-E 3 ì´ë¯¸ì§€ ìƒì„±",
            "5ë‹¨ê³„": "ì´ë¯¸ì§€ â†’ ë¹„ë””ì˜¤ ë³€í™˜ (Runway API)",
            "5.5ë‹¨ê³„": "í‚¤ì›Œë“œ ê¸°ë°˜ BGM ìƒì„± (SUNO API)",
            "6ë‹¨ê³„": "ë¹„ë””ì˜¤ + BGM íŠ¸ëœì§€ì…˜ í•©ì¹˜ê¸°",
            "7ë‹¨ê³„": "TTS ë‚´ë ˆì´ì…˜ ìƒì„± (OpenAI + ElevenLabs)",
            "8ë‹¨ê³„": "ìµœì¢… ì˜ìƒ ì™„ì„± (TTS + ìë§‰ë§Œ, BGMì€ 6ë‹¨ê³„ í¬í•¨)"
        },
        "features": [
            "ğŸ¬ ì™„ì „í•œ AI ë¹„ë””ì˜¤ ìƒì„± íŒŒì´í”„ë¼ì¸ (1-8ë‹¨ê³„)",
            "ğŸ¤– OpenAI GPT-4 ê¸°ë°˜ ì½˜í…ì¸  ìƒì„±",
            "ï¿½ DALL-E 3 ìŠ¤í† ë¦¬ë³´ë“œ ì´ë¯¸ì§€ ìƒì„±",
            "ï¿½ğŸ¥ Runway API ì´ë¯¸ì§€â†’ë¹„ë””ì˜¤ ë³€í™˜",
            "ğŸ™ï¸ ElevenLabs TTS ìŒì„± ìƒì„±",
            "ğŸ“ Whisper AI ìë™ ìë§‰ ìƒì„±",
            "ğŸµ SUNO AI API í‚¤ì›Œë“œ ê¸°ë°˜ 70s ìŒì„± ìƒì„±",
            "âœ‚ï¸ 9ê°€ì§€ íŠ¸ëœì§€ì…˜ íš¨ê³¼ (ëœë¤ ì„ íƒ)",
            "ğŸš€ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì²˜ë¦¬ (ë‹¤ìš´ë¡œë“œ ì—†ìŒ)",
            "ğŸ“± ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ ì¬ìƒ ê°€ëŠ¥",
            "ğŸ¨ Frame-level animation ì§€ì›",
            "ğŸ”§ 0.1ì´ˆ ì •ë°€ë„ ìë§‰ ì‹±í¬",
            "ğŸ¤ ë‹¤ì¤‘ ì˜¤ë””ì˜¤ íŠ¸ë™ ë¯¹ì‹± (TTS + BGM)",
            "ğŸ“Š ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§"
        ],
        "tech_stack": {
            "AI_Models": ["OpenAI GPT-4o-mini", "DALL-E 3", "Whisper", "SUNO V4"],
            "Video_APIs": ["Runway Gen4 Turbo"],
            "Audio_APIs": ["ElevenLabs TTS"],
            "Backend": ["FastAPI", "Python", "FFmpeg"],
            "Processing": ["ë¹„ë™ê¸° ì²˜ë¦¬", "ìŠ¤íŠ¸ë¦¬ë°", "ì‹¤ì‹œê°„ ìƒíƒœ í™•ì¸"]
        }
    }

@app.post("/video/create-tts-from-storyboard")
async def create_tts_from_storyboard():
    """7ë‹¨ê³„: current_projectì˜ ìŠ¤í† ë¦¬ë³´ë“œ ê¸°ë°˜ ì¥ë©´ë³„ TTS ìƒì„±"""
    try:
        print(f"ğŸ™ï¸ 7ë‹¨ê³„: ìŠ¤í† ë¦¬ë³´ë“œ ê¸°ë°˜ ì¥ë©´ë³„ TTS ë‚´ë ˆì´ì…˜ ìƒì„± ì‹œì‘...")
        
        # current_projectì—ì„œ í•„ìš”í•œ ë°ì´í„° í™•ì¸
        if not current_project.get("persona"):
            raise HTTPException(status_code=400, detail="1ë‹¨ê³„ í˜ë¥´ì†Œë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 1ë‹¨ê³„ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        
        if not current_project.get("ad_concept"):
            raise HTTPException(status_code=400, detail="2ë‹¨ê³„ ê´‘ê³  ì»¨ì…‰ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 2ë‹¨ê³„ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        
        if not current_project.get("storyboard"):
            raise HTTPException(status_code=400, detail="3ë‹¨ê³„ ìŠ¤í† ë¦¬ë³´ë“œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 3ë‹¨ê³„ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        
        # current_project ë°ì´í„° ì¶”ì¶œ
        persona_data = current_project["persona"]
        ad_concept = current_project["ad_concept"]
        storyboard_data = current_project["storyboard"]
        
        # í˜ë¥´ì†Œë‚˜ ì •ë³´ ì¶”ì¶œ
        persona_description = persona_data.get("persona_description", "")
        marketing_insights = persona_data.get("marketing_insights", "")
        target_customer = persona_data.get("target_customer", {})
        
        # ìŠ¤í† ë¦¬ë³´ë“œ ì¥ë©´ë“¤ ì¶”ì¶œ
        scenes = storyboard_data.get("scenes", [])
        
        if not scenes:
            raise HTTPException(status_code=400, detail="ìŠ¤í† ë¦¬ë³´ë“œì— ì¥ë©´ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"âœ… current_project ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
        print(f"   ğŸ“Š í˜ë¥´ì†Œë‚˜: {persona_description[:50]}{'...' if len(persona_description) > 50 else ''}")
        print(f"   ğŸ’¡ ê´‘ê³  ì»¨ì…‰: {ad_concept[:50]}{'...' if len(ad_concept) > 50 else ''}")
        print(f"   ğŸ¬ ìŠ¤í† ë¦¬ë³´ë“œ ì¥ë©´ ìˆ˜: {len(scenes)}ê°œ")

        # ê° ì¥ë©´ë³„ë¡œ TTS ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        tts_scripts = []
        
        for i, scene in enumerate(scenes, 1):
            scene_description = scene.get("scene_description", "")
            scene_prompt = scene.get("prompt_text", "")
            
            print(f"\nğŸ¤ [{i}/{len(scenes)}] ì¥ë©´ {i} TTS ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
            print(f"   ğŸ“ ì¥ë©´ ì„¤ëª…: {scene_description[:60]}...")
            
            # ê° ì¥ë©´ì— ë§ëŠ” OpenAI LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
            llm_prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ê´‘ê³  ë‚´ë ˆì´ì…˜ ì‘ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ì¥ë©´ì— ë”± ë§ëŠ” ì§§ê³  ì„íŒ©íŠ¸ ìˆëŠ” TTS ë‚´ë ˆì´ì…˜ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

**íƒ€ê²Ÿ ê³ ê° (í˜ë¥´ì†Œë‚˜):**
{persona_description}

**ì „ì²´ ê´‘ê³  ì»¨ì…‰:**
{ad_concept}

**í˜„ì¬ ì¥ë©´ ì •ë³´ (ì¥ë©´ {i}):**
- ì¥ë©´ ì„¤ëª…: {scene_description}
- ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸: {scene_prompt}

**TTS ìš”êµ¬ì‚¬í•­:**
- ì´ ì¥ë©´ì— ë”± ë§ëŠ” ë‚´ë ˆì´ì…˜ 1ë¬¸ì¥
- 20-35ì ì´ë‚´ (3ì´ˆ ë¶„ëŸ‰)
- ê°„ê²°í•˜ê³  ì„íŒ©íŠ¸ ìˆê²Œ
- íƒ€ê²Ÿ ê³ ê°ì—ê²Œ ì–´í•„í•  ìˆ˜ ìˆëŠ” í†¤
- ì „ì²´ ê´‘ê³  ì»¨ì…‰ê³¼ ì¼ì¹˜í•´ì•¼ í•¨

**ì¶œë ¥ í˜•ì‹:**
ì¥ë©´ì— ë§ëŠ” TTS ë‚´ë ˆì´ì…˜ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.

TTS ë‚´ë ˆì´ì…˜:"""
            
            # OpenAI API í˜¸ì¶œ
            headers = {
                "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "gpt-4o-mini",
                "messages": [
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ê´‘ê³  ë‚´ë ˆì´ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê° ì¥ë©´ì— ë§ëŠ” ë§¤ë ¥ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” í•œêµ­ì–´ ë‚´ë ˆì´ì…˜ì„ ì‘ì„±í•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": llm_prompt
                    }
                ],
                "max_tokens": 200,
                "temperature": 0.7
            }
            
            try:
                print(f"   ğŸŒ OpenAI API í˜¸ì¶œ ì¤‘...")
                async with httpx.AsyncClient(timeout=60.0) as client:
                    response = await client.post(
                        "https://api.openai.com/v1/chat/completions",
                        headers=headers,
                        json=payload
                    )
                    
                    if response.status_code != 200:
                        error_text = response.text
                        print(f"   âŒ OpenAI API ì˜¤ë¥˜: {error_text}")
                        generated_text = f"ì¥ë©´ {i} ë‚´ë ˆì´ì…˜"  # ê¸°ë³¸ê°’
                    else:
                        response_data = response.json()
                        generated_text = response_data["choices"][0]["message"]["content"].strip()
                        
                        # "TTS ë‚´ë ˆì´ì…˜:" ì ‘ë‘ì‚¬ ì œê±°
                        if generated_text.startswith("TTS ë‚´ë ˆì´ì…˜:"):
                            generated_text = generated_text.replace("TTS ë‚´ë ˆì´ì…˜:", "").strip()
                        
                        # ê¸¸ì´ ì œí•œ (35ì)
                        if len(generated_text) > 35:
                            generated_text = generated_text[:35]
                            # ë§ˆì§€ë§‰ ê³µë°±ì—ì„œ ìë¥´ê¸°
                            last_space = generated_text.rfind(' ')
                            if last_space > 25:
                                generated_text = generated_text[:last_space]
                        
                        print(f"   âœ… ì¥ë©´ {i} TTS ìƒì„± ì™„ë£Œ: {generated_text}")
                        
            except Exception as api_error:
                print(f"   âŒ ì¥ë©´ {i} OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {api_error}")
                generated_text = f"ì¥ë©´ {i} ë‚´ë ˆì´ì…˜"
            
            # TTS ìŠ¤í¬ë¦½íŠ¸ ì •ë³´ ì €ì¥
            tts_scripts.append({
                "scene_number": i,
                "scene_description": scene_description,
                "text": generated_text,
                "estimated_duration": min(len(generated_text) * 0.08, 3.5),
                "char_count": len(generated_text),
                "scene_data": scene
            })

        print(f"\nâœ… ì´ {len(tts_scripts)}ê°œ ì¥ë©´ë³„ TTS ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ:")
        for script in tts_scripts:
            duration_est = script.get('estimated_duration', 3.0)
            char_count = script.get('char_count', 0)
            print(f"   - ì¥ë©´ {script['scene_number']}: {script['text']} ({char_count}ì, ì˜ˆìƒ {duration_est:.1f}ì´ˆ)")

        # ElevenLabs TTS ë³€í™˜
        print(f"\nğŸ¤ ElevenLabs TTS ë³€í™˜ ì‹œì‘...")
        successful_tts = []
        failed_tts = []
        
        try:
            if TTS_AVAILABLE:
                script_texts = [script["text"] for script in tts_scripts]
                
                # TTS ì˜¤ë””ì˜¤ ìƒì„±
                api_key = get_elevenlabs_api_key()
                output_dir = os.path.abspath("static/audio")
                tts_results = await create_multiple_tts_audio(
                    text_list=script_texts,
                    voice_id='21m00Tcm4TlvDq8ikWAM',  # ê¸°ë³¸ ìŒì„±
                    api_key=api_key,
                    output_dir=output_dir
                )
                
                # ê²°ê³¼ ì²˜ë¦¬
                for i, (script, result) in enumerate(zip(tts_scripts, tts_results)):
                    if result.success:
                        audio_filename = os.path.basename(result.audio_file_path)
                        audio_url = f"/static/audio/{audio_filename}"
                        
                        successful_tts.append({
                            "scene_number": script["scene_number"],
                            "scene_description": script["scene_description"],
                            "text": script["text"],
                            "audio_url": audio_url,
                            "audio_file_path": result.audio_file_path,
                            "audio_filename": audio_filename,
                            "duration": result.duration,
                            "file_size": result.file_size,
                            "estimated_duration": script["estimated_duration"]
                        })
                        print(f"   âœ… ì¥ë©´ {script['scene_number']} TTS ì™„ë£Œ: {audio_filename}")
                    else:
                        failed_tts.append({
                            "scene_number": script["scene_number"],
                            "scene_description": script["scene_description"],
                            "text": script["text"],
                            "error": result.error
                        })
                        print(f"   âŒ ì¥ë©´ {script['scene_number']} TTS ì‹¤íŒ¨: {result.error}")
            else:
                print("âŒ TTS ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë§Œ ìƒì„±ë©ë‹ˆë‹¤.")
                # TTS ëª¨ë“ˆ ì—†ìœ¼ë©´ ìŠ¤í¬ë¦½íŠ¸ë§Œ ë°˜í™˜
                for script in tts_scripts:
                    successful_tts.append({
                        "scene_number": script["scene_number"],
                        "scene_description": script["scene_description"],
                        "text": script["text"],
                        "audio_url": None,
                        "audio_file_path": None,
                        "note": "TTS ëª¨ë“ˆ ì—†ìŒ"
                    })
            
        except Exception as tts_error:
            print(f"âŒ TTS ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {tts_error}")
            # TTS ì‹¤íŒ¨ ì‹œ ìŠ¤í¬ë¦½íŠ¸ë§Œ ë°˜í™˜
            for script in tts_scripts:
                failed_tts.append({
                    "scene_number": script["scene_number"],
                    "scene_description": script["scene_description"],
                    "text": script["text"],
                    "error": str(tts_error)
                })

        # 7ë‹¨ê³„ ê²°ê³¼ë¥¼ current_projectì— ì €ì¥ (8ë‹¨ê³„ì—ì„œ ì‚¬ìš©)
        current_project["tts_result"] = {
            "tts_scripts": tts_scripts,
            "successful_tts": successful_tts,
            "failed_tts": failed_tts,
            "total_scenes": len(scenes)
        }
        
        # 7ë‹¨ê³„ ì™„ë£Œ í›„ TTS íŒŒì¼ëª…ë“¤ì„ TXT íŒŒì¼ë¡œ ì €ì¥
        print(f"ğŸ“ 7ë‹¨ê³„ ì™„ë£Œëœ TTS íŒŒì¼ëª… ì €ì¥ ì¤‘...")
        tts_file_list_file = "tts_file_list.txt"
        try:
            with open(tts_file_list_file, 'w', encoding='utf-8') as f:
                for tts in successful_tts:
                    if tts.get("audio_file_path"):
                        f.write(tts["audio_file_path"] + '\n')
                        f.write(f"TEXT:{tts['text']}\n")  # ì›ë³¸ í…ìŠ¤íŠ¸ë„ í•¨ê»˜ ì €ì¥
                        f.write(f"DURATION:{tts.get('duration', 3.0)}\n")  # ê¸¸ì´ ì •ë³´ë„ ì €ì¥
                        f.write("---\n")  # êµ¬ë¶„ì
            
            print(f"âœ… 7ë‹¨ê³„ TTS íŒŒì¼ëª… ì €ì¥ ì„±ê³µ!")
            print(f"   íŒŒì¼ ìœ„ì¹˜: {os.path.abspath(tts_file_list_file)}")
            print(f"   ì €ì¥ëœ TTS íŒŒì¼: {len(successful_tts)}ê°œ")
            
        except Exception as e:
            print(f"âŒ 7ë‹¨ê³„ TTS íŒŒì¼ëª… ì €ì¥ ì‹¤íŒ¨: {e}")
        
        print(f"\nâœ… 7ë‹¨ê³„ ì™„ë£Œ: ì¥ë©´ë³„ TTS ìƒì„± ì„±ê³µ!")
        print(f"   ğŸ“Š ì„±ê³µ: {len(successful_tts)}ê°œ, ì‹¤íŒ¨: {len(failed_tts)}ê°œ")
        print(f"   ğŸ“ˆ ì„±ê³µë¥ : {(len(successful_tts) / len(tts_scripts)) * 100:.1f}%")
        
        return {
            "step": "7ë‹¨ê³„_ì¥ë©´ë³„_TTS_ìƒì„±",
            "success": True,
            "message": f"ìŠ¤í† ë¦¬ë³´ë“œ ê¸°ë°˜ ì¥ë©´ë³„ TTS ë‚´ë ˆì´ì…˜ ìƒì„± ì™„ë£Œ! {len(successful_tts)}ê°œ ì¥ë©´ ì²˜ë¦¬",
            "source_data": {
                "persona_description": persona_description[:100] + "..." if len(persona_description) > 100 else persona_description,
                "ad_concept": ad_concept[:100] + "..." if len(ad_concept) > 100 else ad_concept,
                "total_scenes": len(scenes)
            },
            "tts_scripts": tts_scripts,
            "successful_tts": successful_tts,
            "failed_tts": failed_tts,
            "summary": {
                "total_scenes": len(tts_scripts),
                "successful": len(successful_tts),
                "failed": len(failed_tts),
                "success_rate": f"{(len(successful_tts) / len(tts_scripts)) * 100:.1f}%" if tts_scripts else "0%"
            },
            "workflow_integration": {
                "used_step1_persona": True,
                "used_step2_ad_concept": True,
                "used_step3_storyboard": True,
                "scene_based_generation": True
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ 7ë‹¨ê³„ ì¥ë©´ë³„ TTS ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"7ë‹¨ê³„ ì¥ë©´ë³„ TTS ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )

def _create_srt_content(self, sequence_number: int, start_time: float, end_time: float, text: str) -> str:
    """SRT í¬ë§·ìœ¼ë¡œ ìë§‰ ë‚´ìš© ìƒì„±"""
    def seconds_to_srt_time(seconds: float) -> str:
        """ì´ˆë¥¼ SRT ì‹œê°„ í¬ë§·(HH:MM:SS,mmm)ìœ¼ë¡œ ë³€í™˜"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    start_srt = seconds_to_srt_time(start_time)
    end_srt = seconds_to_srt_time(end_time)
    
    return f"""{sequence_number}
{start_srt} --> {end_srt}
{text}

"""

def create_srt_content(sequence_number: int, start_time: float, end_time: float, text: str) -> str:
    """SRT í¬ë§·ìœ¼ë¡œ ìë§‰ ë‚´ìš© ìƒì„±"""
    def seconds_to_srt_time(seconds: float) -> str:
        """ì´ˆë¥¼ SRT ì‹œê°„ í¬ë§·(HH:MM:SS,mmm)ìœ¼ë¡œ ë³€í™˜"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    start_srt = seconds_to_srt_time(start_time)
    end_srt = seconds_to_srt_time(end_time)
    
    return f"""{sequence_number}
{start_srt} --> {end_srt}
{text}

"""
async def generate_videos():
    """5ë‹¨ê³„: 4ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ë“¤ì„ ë¹„ë””ì˜¤ë¡œ ë³€í™˜"""
    
    # video_server.pyì˜ current_projectì—ì„œ 4ë‹¨ê³„ ì´ë¯¸ì§€ë“¤ ê°€ì ¸ì˜¤ê¸°
    if not current_project.get("images"):
        raise HTTPException(
            status_code=400,
            detail="4ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 4ë‹¨ê³„ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”."
        )
    
    # 4ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ URLë“¤ ì¶”ì¶œ
    image_data_list = current_project["images"]
    image_urls = []
    
    print(f"ğŸ”§ current_project['images'] ë‚´ìš©: {len(image_data_list)}ê°œ")
    
    for i, img_data in enumerate(image_data_list):
        print(f"ğŸ”§ ì´ë¯¸ì§€ {i+1} ë°ì´í„°: {type(img_data)} - {str(img_data)[:100]}...")
        
        # ë‹¤ì–‘í•œ í˜•íƒœì˜ ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬
        if isinstance(img_data, dict):
            if img_data.get("url"):
                    image_urls.append(img_data["url"])
        # ë‹¤ì–‘í•œ í˜•íƒœì˜ ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬
        if isinstance(img_data, dict):
            if img_data.get("url"):
                image_urls.append(img_data["url"])
            elif img_data.get("image_url"):
                image_urls.append(img_data["image_url"])
            elif img_data.get("generated_image_url"):
                image_urls.append(img_data["generated_image_url"])
        elif isinstance(img_data, str):
            image_urls.append(img_data)
    
    if not image_urls:
        print(f"âŒ ì¶”ì¶œëœ URLì´ ì—†ìŠµë‹ˆë‹¤.")
        raise HTTPException(
            status_code=400,
            detail="4ë‹¨ê³„ ì´ë¯¸ì§€ ë°ì´í„°ì—ì„œ ìœ íš¨í•œ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    
    print(f"âœ… 4ë‹¨ê³„ì—ì„œ ê°€ì ¸ì˜¨ ì´ë¯¸ì§€: {len(image_urls)}ê°œ")
    
    print("ğŸ¬ 5ë‹¨ê³„: 4ë‹¨ê³„ ì´ë¯¸ì§€ë“¤ â†’ ë¹„ë””ì˜¤ ë³€í™˜ ì‹œì‘...")
    
    # video_models.py ì„¤ì • ì‚¬ìš©
    from video_models import ImageToVideoRequest, VideoGenerationResult
    
    video_request = ImageToVideoRequest(
        image_urls=image_urls,
        duration_per_scene=5,
        resolution="720:1280",
        model="gen4_turbo"
    )
    
    print(f"ğŸ¬ Runway API ì„¤ì •:")
    print(f"   - ëª¨ë¸: {video_request.model}")
    print(f"   - í•´ìƒë„: {video_request.resolution}")
    print(f"   - ì¥ë©´ë‹¹ ê¸¸ì´: {video_request.duration_per_scene}ì´ˆ")
    
    # Runway APIë¥¼ í†µí•œ ì´ë¯¸ì§€ â†’ ë™ì˜ìƒ ë³€í™˜
    generated_videos = []
    
    try:
        runway_api_key = os.getenv("RUNWAY_API_KEY")
        
        if not runway_api_key:
            raise HTTPException(
                status_code=500,
                detail="RUNWAY_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        
        print("ğŸš€ Runway APIë¥¼ í†µí•œ ì´ë¯¸ì§€ â†’ ë™ì˜ìƒ ë³€í™˜ ì‹œì‘...")
        
        headers = {
            "Authorization": f"Bearer {runway_api_key}",
            "Content-Type": "application/json",
            "X-Runway-Version": "2024-11-06"
        }
        
        base_url = "https://api.dev.runwayml.com/v1"
        
        async with httpx.AsyncClient(timeout=300) as client:
            for i, image_url in enumerate(image_urls, 1):
                print(f"\nğŸ¬ [{i}/{len(image_urls)}] ì´ë¯¸ì§€ â†’ ë™ì˜ìƒ ë³€í™˜ ì¤‘...")
                print(f"   ğŸ–¼ï¸ ì†ŒìŠ¤ ì´ë¯¸ì§€: {image_url}")
                
                payload = {
                    "model": video_request.model,
                    "promptImage": image_url,
                    "duration": video_request.duration_per_scene,
                    "ratio": video_request.resolution,
                    "seed": 42
                }
                
                try:
                    # ë™ì˜ìƒ ìƒì„± ì‘ì—… ìš”ì²­
                    print(f"ğŸ“¤ Runway API ìš”ì²­: ì´ë¯¸ì§€ â†’ ë™ì˜ìƒ ë³€í™˜...")
                    response = await client.post(f"{base_url}/image_to_video", headers=headers, json=payload)
                    
                    if response.status_code != 200:
                        raise Exception(f"API ìš”ì²­ ì‹¤íŒ¨: {response.text}")
                    
                    task_id = response.json()["id"]
                    print(f"  -> ì‘ì—… ID: {task_id}")

                    # ì‘ì—… ì™„ë£Œê¹Œì§€ í´ë§
                    for attempt in range(60):
                        await asyncio.sleep(5)
                        
                        status_response = await client.get(f"{base_url}/tasks/{task_id}", headers=headers)
                        status_data = status_response.json()
                        
                        if status_data["status"] == "SUCCEEDED":
                            video_url = status_data["output"][0]
                            print(f"  âœ… ë™ì˜ìƒ ìƒì„± ì™„ë£Œ: {video_url}")
                            
                            result = VideoGenerationResult(
                                scene_number=i,
                                status="success",
                                video_url=video_url,
                                duration=video_request.duration_per_scene,
                                resolution=video_request.resolution
                            )
                            generated_videos.append(result.model_dump())
                            break
                        elif status_data["status"] == "FAILED":
                            print(f"  âŒ ë™ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {status_data.get('failure')}")
                            result = VideoGenerationResult(
                                scene_number=i,
                                status="error",
                                error=f"ìƒì„± ì‹¤íŒ¨: {status_data.get('failure')}",
                                duration=video_request.duration_per_scene,
                                resolution=video_request.resolution
                            )
                            generated_videos.append(result.model_dump())
                            break
                        else:
                            print(f"  â³ ì‘ì—… ì§„í–‰ ì¤‘... ({attempt + 1}/60) ìƒíƒœ: {status_data['status']}")
                
                except Exception as video_error:
                    print(f"  âŒ ì¥ë©´ {i} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {video_error}")
                    result = VideoGenerationResult(
                        scene_number=i,
                        status="error",
                        error=str(video_error),
                        duration=video_request.duration_per_scene,
                        resolution=video_request.resolution
                    )
                    generated_videos.append(result.model_dump())
    
    except Exception as api_error:
        print(f"âš ï¸ Runway API í˜¸ì¶œ ì‹¤íŒ¨: {api_error}")
        raise HTTPException(
            status_code=500,
            detail=f"Runway API í˜¸ì¶œ ì‹¤íŒ¨: {str(api_error)}"
        )
    
    # ê²°ê³¼ í†µê³„ ê³„ì‚°
    successful_count = sum(1 for v in generated_videos if v.get('status') == 'success')
    failed_count = len(generated_videos) - successful_count
    success_rate = f"{(successful_count / len(generated_videos)) * 100:.1f}%" if generated_videos else "0%"
    
    # 5ë‹¨ê³„ ê²°ê³¼ë¥¼ current_projectì— ì €ì¥
    current_project["generated_videos"] = generated_videos
    print(f"âœ… 5ë‹¨ê³„ ê²°ê³¼ë¥¼ current_projectì— ì €ì¥í–ˆìŠµë‹ˆë‹¤. ({successful_count}ê°œ ì„±ê³µ)")
    
    return {
        "step": "5ë‹¨ê³„_ë¹„ë””ì˜¤_ìƒì„±",
        "success": True,
        "message": "ì´ë¯¸ì§€ â†’ ë¹„ë””ì˜¤ ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
        "generated_videos": generated_videos,
        "summary": {
            "total_scenes": len(generated_videos),
            "successful": successful_count,
            "failed": failed_count,
            "success_rate": success_rate
        }
    }

# 5.5ë‹¨ê³„: BGM ìƒì„± (6ë‹¨ê³„ ì „ì— BGM ì¤€ë¹„)
@app.post("/bgm/generate-and-wait")
async def generate_bgm_and_wait(
    keyword: str = "happy",
    duration: int = 70,
    max_wait_minutes: int = 5
):
    """
    SUNO APIë¥¼ ì‚¬ìš©í•œ BGM ìƒì„± ë° ìë™ ëŒ€ê¸° (íŒŒì¼ê¹Œì§€ ì™„ì „íˆ ìƒì„±)
    """
    try:
        print(f"ğŸµ SUNO BGM ìë™ ìƒì„± ì‹œì‘: í‚¤ì›Œë“œ='{keyword}', ê¸¸ì´={duration}ì´ˆ")
        
        if not os.getenv('SUNO_API_KEY'):
            raise HTTPException(status_code=500, detail="SUNO_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # 1ë‹¨ê³„: SUNO BGM ìƒì„± ìš”ì²­
        task_id = await generate_suno_bgm(keyword, duration)
        print(f"âœ… BGM ìƒì„± ìš”ì²­ ì™„ë£Œ: task_id = {task_id}")
        
        # 2ë‹¨ê³„: ìµœëŒ€ max_wait_minutesë¶„ê°„ ëŒ€ê¸°í•˜ë©° ìƒíƒœ í™•ì¸
        max_attempts = max_wait_minutes * 4  # 15ì´ˆë§ˆë‹¤ ì²´í¬
        attempt = 0
        
        while attempt < max_attempts:
            attempt += 1
            print(f"ğŸ”„ [{attempt}/{max_attempts}] BGM ìƒì„± ìƒíƒœ í™•ì¸ ì¤‘... ({attempt * 15}ì´ˆ ê²½ê³¼)")
            
            try:
                result = await check_suno_task_and_download(task_id)
                
                if result["success"]:
                    print(f"ğŸ‰ BGM ìƒì„± ë° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                    print(f"ğŸ“ íŒŒì¼ ìœ„ì¹˜: {result['bgm_path']}")
                    
                    return {
                        "success": True,
                        "message": f"BGM ìƒì„± ë° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! ({attempt * 15}ì´ˆ ì†Œìš”)",
                        "task_id": task_id,
                        "bgm_file": result["bgm_filename"],
                        "bgm_url": f"http://localhost:8001/static/audio/{result['bgm_filename']}",
                        "duration": result["duration"],
                        "title": result["title"],
                        "tags": result["tags"],
                        "file_path": result["bgm_path"],
                        "total_wait_time": f"{attempt * 15}ì´ˆ"
                    }
                else:
                    print(f"   â³ ì•„ì§ ìƒì„± ì¤‘... (ìƒíƒœ: {result.get('status', 'unknown')})")
                    
            except Exception as e:
                print(f"   âš ï¸ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # 15ì´ˆ ëŒ€ê¸°
            if attempt < max_attempts:
                await asyncio.sleep(15)
        
        # ì‹œê°„ ì´ˆê³¼
        return {
            "success": False,
            "message": f"BGM ìƒì„± ì‹œê°„ ì´ˆê³¼ ({max_wait_minutes}ë¶„). ìˆ˜ë™ìœ¼ë¡œ /bgm/status/{task_id} ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
            "task_id": task_id,
            "status_check_url": f"/bgm/status/{task_id}",
            "retry_after": 30
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ BGM ìë™ ìƒì„± ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"BGM ìë™ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )

@app.post("/video/merge-with-transitions")
async def merge_videos_with_transitions(
    enable_bgm: bool = True,        # BGM í¬í•¨ ì—¬ë¶€
    bgm_volume: float = 0.4,        # BGM ë³¼ë¥¨ (0.1-1.0)
    transition_duration: float = 1.0  # íŠ¸ëœì§€ì…˜ ì‹œê°„ (ì´ˆ)
):
    """
    6ë‹¨ê³„: 5ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ì˜ìƒë“¤ì„ ëœë¤ íŠ¸ëœì§€ì…˜ìœ¼ë¡œ í•©ì¹˜ê¸° (BGM ì„ íƒ ê°€ëŠ¥)
    """
    
    # ì²˜ë¦¬ ìƒíƒœ ì´ˆê¸°í™”
    video_processing_status.update({
        "is_processing": True,
        "current_step": "6ë‹¨ê³„: ë¹„ë””ì˜¤ í•©ì¹˜ê¸° ì¤€ë¹„ ì¤‘",
        "progress": 0,
        "total_steps": 100,
        "current_file": "",
        "start_time": time.time(),
        "estimated_completion": None
    })
    
    try:
        # ì˜ˆì‹œ ì˜ìƒ URLë“¤ (5ë‹¨ê³„ ì˜ìƒì´ ì—†ì„ ë•Œ ì‚¬ìš©) - ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
        example_video_urls = []
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸: ì˜ìƒ í™•ì¸ ì¤‘
        video_processing_status.update({
            "current_step": "6ë‹¨ê³„: ìƒì„±ëœ ì˜ìƒ í™•ì¸ ì¤‘",
            "progress": 10
        })
        
        # video_server.pyì˜ í˜„ì¬ í”„ë¡œì íŠ¸ ìƒíƒœì—ì„œ ìƒì„±ëœ ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        video_urls = []
        use_example_videos = False
        
        if not current_project.get("generated_videos"):
            print("âŒ 5ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
            raise HTTPException(
                status_code=400, 
                detail="íŠ¸ëœì§€ì…˜ ì˜ìƒì„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 5ë‹¨ê³„ì—ì„œ ì˜ìƒì„ ìƒì„±í•˜ì„¸ìš”."
            )
        else:
            print("ğŸ“‹ 6ë‹¨ê³„: 5ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ì˜ìƒë“¤ì„ í™•ì¸í•©ë‹ˆë‹¤...")
            
            # ìƒì„±ëœ ì˜ìƒ URLë“¤ ì¶”ì¶œ
            generated_videos = current_project["generated_videos"]
            
            # ì„±ê³µì ìœ¼ë¡œ ìƒì„±ëœ ì˜ìƒ URLë“¤ë§Œ ì¶”ì¶œ
            for video in generated_videos:
                if video.get("status") == "success" and video.get("video_url"):
                    video_urls.append(video["video_url"])
            
            if not video_urls:
                print("âŒ 5ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ìœ íš¨í•œ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
                raise HTTPException(
                    status_code=400, 
                    detail="íŠ¸ëœì§€ì…˜ ì˜ìƒì„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 5ë‹¨ê³„ì—ì„œ ì˜ìƒì„ ë‹¤ì‹œ ìƒì„±í•˜ì„¸ìš”."
                )
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸: ë³‘í•© ì¤€ë¹„
        video_processing_status.update({
            "current_step": "6ë‹¨ê³„: ë¹„ë””ì˜¤ ë³‘í•© ì¤€ë¹„ ì¤‘",
            "progress": 20
        })
        
        # ì˜ìƒì´ ìˆëŠ”ì§€ ìµœì¢… í™•ì¸
        if not video_urls:
            raise ValueError("ë³‘í•©í•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. 5ë‹¨ê³„ì—ì„œ ì˜ìƒì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.")
        
        if use_example_videos:
            print(f"ğŸ¬ ì˜ˆì‹œ ì˜ìƒ {len(video_urls)}ê°œë¥¼ ëœë¤ íŠ¸ëœì§€ì…˜ìœ¼ë¡œ í•©ì¹©ë‹ˆë‹¤...")
        else:
            print(f"ğŸ¬ ì´ {len(video_urls)}ê°œ ì‹¤ì œ ìƒì„± ì˜ìƒì„ ëœë¤ íŠ¸ëœì§€ì…˜ìœ¼ë¡œ í•©ì¹©ë‹ˆë‹¤...")
            
            # ì‹¤ì œ ì˜ìƒ URLë“¤ ì¶œë ¥
            for i, url in enumerate(video_urls, 1):
                print(f"   ì˜ìƒ {i}: {url}")
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸: ë³‘í•© ì‹œì‘
        video_processing_status.update({
            "current_step": "6ë‹¨ê³„: ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë° ë³‘í•© ì¤‘",
            "progress": 30,
            "current_file": f"{len(video_urls)}ê°œ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘"
        })
        
        # SUNO BGM íŒŒì¼ ì°¾ê¸° - request.enable_bgmì— ë”°ë¼ ì„ íƒì  ì²˜ë¦¬
        selected_bgm_file = None
        bgm_audio_dir = "static/audio"
        
        if enable_bgm:  # BGMì´ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ BGM íŒŒì¼ ê²€ìƒ‰
            try:
                if os.path.exists(bgm_audio_dir):
                    # SUNO APIë¡œ ìƒì„±ëœ BGM íŒŒì¼ë§Œ ì°¾ê¸° (suno_bgm_ ì ‘ë‘ì‚¬)
                    suno_bgm_files = [f for f in os.listdir(bgm_audio_dir) 
                                     if f.startswith('suno_bgm_') and f.endswith('.mp3')]
                    if suno_bgm_files:
                        # ê°€ì¥ ìµœê·¼ì— ìƒì„±ëœ SUNO BGM íŒŒì¼ ì‚¬ìš©
                        suno_bgm_files.sort(key=lambda x: os.path.getctime(os.path.join(bgm_audio_dir, x)), reverse=True)
                        selected_bgm_file = os.path.join(bgm_audio_dir, suno_bgm_files[0])
                        print(f"âœ… SUNO BGM íŒŒì¼ ë°œê²¬: {suno_bgm_files[0]} (BGMê³¼ í•¨ê»˜ í•©ì¹  ì˜ˆì •)")
                    else:
                        print("â„¹ï¸ SUNO BGM íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. BGM ì—†ì´ íŠ¸ëœì§€ì…˜ë§Œ ì ìš©í•©ë‹ˆë‹¤.")
                else:
                    print("â„¹ï¸ BGM ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. BGM ì—†ì´ íŠ¸ëœì§€ì…˜ë§Œ ì ìš©í•©ë‹ˆë‹¤.")
            except Exception as e:
                print(f"âš ï¸ BGM ê²€ìƒ‰ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}. BGM ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
                selected_bgm_file = None
        else:
            print("ğŸ”‡ BGMì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. BGM ì—†ì´ íŠ¸ëœì§€ì…˜ë§Œ ì ìš©í•©ë‹ˆë‹¤.")
            selected_bgm_file = None
        
        # ì‹¤ì œ ì˜ìƒ URLë“¤ì„ ì‚¬ìš©í•œ íŠ¸ëœì§€ì…˜ í•©ì¹˜ê¸°
        merger = create_merger_instance(use_static_dir=True, enable_bgm=False)  # BGM ì²˜ë¦¬ëŠ” ë³„ë„ë¡œ
        
        # BGM ì—¬ë¶€ì— ë”°ë¼ íŒŒì¼ëª… ê²°ì •
        if selected_bgm_file:
            output_filename = generate_output_filename("merged_ai_videos_with_bgm")
        else:
            output_filename = generate_output_filename("merged_ai_videos")
        
        # ìµœì¢… ë¹„ë””ì˜¤ ê²½ë¡œ ì´ˆê¸°í™”
        final_video_path = None
        
        video_source = "ì˜ˆì‹œ ì˜ìƒ" if use_example_videos else "ì‹¤ì œ ìƒì„±ëœ ì˜ìƒ"
        bgm_status = f"SUNO BGM í¬í•¨ (ë³¼ë¥¨: {int(bgm_volume*100)}%)" if selected_bgm_file else "BGM ì—†ìŒ (íŠ¸ëœì§€ì…˜ë§Œ)"
        print(f"ğŸš€ {video_source} URLë“¤ë¡œ íŠ¸ëœì§€ì…˜ í•©ì¹˜ê¸° ì‹œì‘... ({bgm_status})")
        
        # ë¨¼ì € íŠ¸ëœì§€ì…˜ ë¹„ë””ì˜¤ ìƒì„± (BGM ì˜µì…˜ í¬í•¨)
        print(f"ğŸ¬ íŠ¸ëœì§€ì…˜ íš¨ê³¼ë¡œ ë¹„ë””ì˜¤ í•©ì¹˜ëŠ” ì¤‘...")
        video_processing_status.update({
            "current_step": f"6ë‹¨ê³„: íŠ¸ëœì§€ì…˜ íš¨ê³¼ ì ìš© ì¤‘ ({bgm_status})",
            "progress": 50,
            "current_file": f"íŠ¸ëœì§€ì…˜: {len(video_urls)}ê°œ ì˜ìƒ"
        })
        
        temp_video_path = merger.merge_videos_with_frame_transitions(
            video_urls,
            output_filename,
            bgm_file=selected_bgm_file,  # BGMì„ ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬
            bgm_volume=bgm_volume  # BGM ë³¼ë¥¨ë„ ì „ë‹¬
        )
        
        print(f"âœ… ë¹„ë””ì˜¤ í•©ì¹˜ê¸° ì™„ë£Œ!")
        
        # ìµœì¢… ë¹„ë””ì˜¤ ê²½ë¡œ ì„¤ì •
        final_video_path = temp_video_path
        
        video_url = merger.get_video_url(output_filename)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸: í›„ì²˜ë¦¬
        video_processing_status.update({
            "current_step": "6ë‹¨ê³„: íŒŒì¼ ì €ì¥ ë° í›„ì²˜ë¦¬ ì¤‘",
            "progress": 90,
            "current_file": output_filename
        })
        
        print(f"ğŸ‰ 6ë‹¨ê³„ ì™„ë£Œ: ì˜ìƒì´ ì„±ê³µì ìœ¼ë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤!")
        print(f"ğŸ“± ë¸Œë¼ìš°ì €ì—ì„œ í™•ì¸: {video_url}")
        
        # 6ë‹¨ê³„ ì™„ë£Œ í›„ íŠ¸ëœì§€ì…˜ ì˜ìƒ ë¡œê·¸ë¥¼ TXT íŒŒì¼ë¡œ ì €ì¥
        print(f"ğŸ“ 6ë‹¨ê³„ ì™„ë£Œëœ íŠ¸ëœì§€ì…˜ ì˜ìƒ ë¡œê·¸ ì €ì¥ ì¤‘...")
        transition_video_log_file = "transition_video_log.txt"
        try:
            if final_video_path:
                if os.path.isabs(final_video_path):
                    actual_video_path = final_video_path
                else:
                    actual_video_path = os.path.abspath(final_video_path)
            else:
                actual_video_path = os.path.abspath(os.path.join("static", "videos", output_filename))
            
            with open(transition_video_log_file, 'w', encoding='utf-8') as f:
                f.write(f"TRANSITION_VIDEO:{actual_video_path}\n")
                f.write(f"CREATED_TIME:{time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"SOURCE_VIDEOS:{len(video_urls)}\n")
                f.write(f"BGM_ENABLED:{enable_bgm}\n")
                if selected_bgm_file:
                    f.write(f"BGM_FILE:{selected_bgm_file}\n")
                    f.write(f"BGM_VOLUME:{bgm_volume}\n")
                f.write(f"OUTPUT_FILENAME:{output_filename}\n")
                f.write(f"VIDEO_URL:{video_url}\n")
                f.write("SOURCE_VIDEO_URLS:\n")
                for i, url in enumerate(video_urls, 1):
                    f.write(f"  {i}: {url}\n")
                f.write("---\n")
            
            print(f"âœ… 6ë‹¨ê³„ íŠ¸ëœì§€ì…˜ ì˜ìƒ ë¡œê·¸ ì €ì¥ ì„±ê³µ!")
            print(f"   íŒŒì¼ ìœ„ì¹˜: {os.path.abspath(transition_video_log_file)}")
            print(f"   ì €ì¥ëœ ì˜ìƒ: {actual_video_path}")
            print(f"   ì†ŒìŠ¤ ì˜ìƒ ìˆ˜: {len(video_urls)}ê°œ")
            
            # ê¸°ì¡´ merged_video_list.txtë„ ìœ ì§€ (í˜¸í™˜ì„±ì„ ìœ„í•´)
            merged_video_list_file = "merged_video_list.txt"
            with open(merged_video_list_file, 'w', encoding='utf-8') as f:
                f.write(actual_video_path + '\n')
            
        except Exception as e:
            print(f"âŒ 6ë‹¨ê³„ íŠ¸ëœì§€ì…˜ ì˜ìƒ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸: ì™„ë£Œ
        video_processing_status.update({
            "is_processing": False,
            "current_step": "6ë‹¨ê³„: ì™„ë£Œ",
            "progress": 100,
            "current_file": output_filename
        })
        
        return {
            "step": f"6ë‹¨ê³„_ì˜ìƒ_{'BGMí¬í•¨_' if selected_bgm_file else 'BGMì—†ìŒ_'}í•©ì¹˜ê¸°",
            "status": "success",
            "message": f"{video_source}ì´ {'BGMê³¼ í•¨ê»˜ (ë³¼ë¥¨: ' + str(int(bgm_volume*100)) + '%)' if selected_bgm_file else 'BGM ì—†ì´'} ì„±ê³µì ìœ¼ë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤.",
            "video_source": video_source,
            "input_videos": len(video_urls),
            "bgm_settings": {
                "enabled": enable_bgm,
                "included": bool(selected_bgm_file),
                "volume_percent": int(bgm_volume*100) if selected_bgm_file else 0,
                "file": os.path.basename(selected_bgm_file) if selected_bgm_file else None
            },
            "transition_settings": {
                "duration": transition_duration
            },
            "output_file": output_filename,
            "url": video_url,
            "duration": "estimated_duration",
            "workflow_complete": True,
            "used_example_videos": use_example_videos
        }
        
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ìƒíƒœ ì´ˆê¸°í™”
        video_processing_status.update({
            "is_processing": False,
            "current_step": f"6ë‹¨ê³„: ì˜¤ë¥˜ ë°œìƒ - {str(e)}",
            "progress": 0,
            "current_file": ""
        })
        
        print(f"âŒ 6ë‹¨ê³„ ë¹„ë””ì˜¤ ë³‘í•© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=f"ë¹„ë””ì˜¤ ë³‘í•© ì‹¤íŒ¨: {str(e)}")

# ì»¤ìŠ¤í…€ ìë§‰ ì—”ë“œí¬ì¸íŠ¸
@app.post("/video/merge-with-custom-subtitles")
async def merge_video_with_custom_subtitles(
    position: str = "bottom",           # í¬ì§€ì…˜
    font_size: int = 2,                 # í°íŠ¸ ì‚¬ì´ì¦ˆ
    font_name: str = "Malgun Gothic",   # í°íŠ¸ ì´ë¦„
    font_color: str = "&Hffffff",       # í°íŠ¸ìƒ‰
    scale: int = 30,                    # ë¹„ìœ¨ (x, y í†µí•©)
    outline_color: str = "&H000000",    # ì•„ì›ƒë¼ì¸ ìƒ‰
    outline_width: int = 2,             # ì•„ì›ƒë¼ì¸ êµµê¸°
    enable_bold: bool = True            # ë³¼ë“œ
):
    """
    ì»¤ìŠ¤í…€ ìë§‰ ì ìš©: SRT íŒŒì¼ê³¼ í°íŠ¸ ì„¤ì •ìœ¼ë¡œ ìë§‰ ì»¤ìŠ¤í„°ë§ˆì´ì§•
    - ê¸°ì¡´ ë¹„ë””ì˜¤ì— ì‚¬ìš©ì ì§€ì • SRT íŒŒì¼ê³¼ í°íŠ¸ ì„¤ì • ì ìš©
    - í°íŠ¸ í¬ê¸°, ìƒ‰ìƒ, ìœ„ì¹˜, ìŠ¤ì¼€ì¼ ë“± ì„¸ë¶€ ì¡°ì • ê°€ëŠ¥
    """
    try:
        print(f"ğŸ¨ ì»¤ìŠ¤í…€ ìë§‰ ì ìš© ì‹œì‘...")
        
        if not SUBTITLE_AVAILABLE:
            raise HTTPException(
                status_code=500,
                detail="ìë§‰ ëª¨ë“ˆì´ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        # í•„ìˆ˜ íŒŒì¼ë“¤ ì‚¬ì „ ê²€ì¦
        tts_file_list_file = "tts_file_list.txt"
        if not os.path.exists(tts_file_list_file) or os.path.getsize(tts_file_list_file) == 0:
            raise HTTPException(
                status_code=400,
                detail="TTS íŒŒì¼ ëª©ë¡ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë¨¼ì € 7ë‹¨ê³„ TTS ìƒì„±ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”."
            )
        
        transition_video_log_file = "transition_video_log.txt"
        if not os.path.exists(transition_video_log_file) or os.path.getsize(transition_video_log_file) == 0:
            raise HTTPException(
                status_code=400,
                detail="íŠ¸ëœì§€ì…˜ ì˜ìƒ ë¡œê·¸ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë¨¼ì € 6ë‹¨ê³„ íŠ¸ëœì§€ì…˜ ì˜ìƒ ìƒì„±ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”."
            )
        
        print(f"âœ… í•„ìˆ˜ íŒŒì¼ ê²€ì¦ ì™„ë£Œ - TTS ëª©ë¡ê³¼ íŠ¸ëœì§€ì…˜ ë¡œê·¸ ì¡´ì¬")
        
        # 1. íŠ¸ëœì§€ì…˜ ì˜ìƒ ë¡œê·¸ì—ì„œ ë¹„ë””ì˜¤ íŒŒì¼ ì°¾ê¸° (ìš°ì„ )
        transition_video_log_file = "transition_video_log.txt"
        video_file_path = None
        
        if os.path.exists(transition_video_log_file):
            try:
                with open(transition_video_log_file, 'r', encoding='utf-8') as f:
                    log_content = f.read()
                    
                # ë¡œê·¸ì—ì„œ íŠ¸ëœì§€ì…˜ ì˜ìƒ ê²½ë¡œ ì¶”ì¶œ
                for line in log_content.split('\n'):
                    if line.startswith('TRANSITION_VIDEO:'):
                        transition_video_path = line.split(':', 1)[1].strip()
                        if os.path.exists(transition_video_path):
                            video_file_path = transition_video_path
                            print(f"âœ… íŠ¸ëœì§€ì…˜ ì˜ìƒ ë¡œê·¸ì—ì„œ ë¹„ë””ì˜¤ ì‚¬ìš©: {os.path.basename(video_file_path)}")
                            break
                            
            except Exception as e:
                print(f"âš ï¸ íŠ¸ëœì§€ì…˜ ì˜ìƒ ë¡œê·¸ ì½ê¸° ì‹¤íŒ¨: {e}")
        
        # íŠ¸ëœì§€ì…˜ ë¡œê·¸ì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
        if not video_file_path:
            video_dir = "static/videos"
            video_files = []
            
            if os.path.exists(video_dir):
                for file in os.listdir(video_dir):
                    if file.endswith(".mp4") and not file.startswith("custom_subtitle_"):
                        video_path = os.path.join(video_dir, file)
                        video_files.append((video_path, os.path.getmtime(video_path)))
            
            if not video_files:
                raise HTTPException(
                    status_code=404,
                    detail="ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŠ¸ëœì§€ì…˜ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ì„¸ìš”."
                )
            
            # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
            video_files.sort(key=lambda x: x[1], reverse=True)
            video_file_path = video_files[0][0]
            print(f"âœ… ìµœê·¼ ë¹„ë””ì˜¤ íŒŒì¼ ì‚¬ìš© (í´ë°±): {os.path.basename(video_file_path)}")
        
        print(f"ğŸ“¹ ì‚¬ìš©í•  ë¹„ë””ì˜¤: {os.path.basename(video_file_path)}")
        
        # video_dir ë³€ìˆ˜ ì •ì˜ (TTS íŒŒì¼ ê²€ìƒ‰ì„ ìœ„í•´)
        video_dir = "static/videos"
        
        # 2. SRT íŒŒì¼ ì²˜ë¦¬ (ìë™ TTS íŒŒì¼ì—ì„œ ìƒì„±)
        subtitle_file_path = None
        # ìë™ ìƒì„±ëœ SRT íŒŒì¼ ì°¾ê¸°
        from subtitle_utils import transcribe_audio_with_whisper, create_sequential_subtitle_file
        
        # TTS íŒŒì¼ ì°¾ê¸°
        tts_files = []
        for file in os.listdir(video_dir):
            if file.startswith("combined_tts_") and file.endswith(".mp3"):
                tts_path = os.path.join(video_dir, file)
                tts_files.append((tts_path, os.path.getmtime(tts_path)))
        
        if not tts_files:
            raise HTTPException(
                status_code=404,
                detail="TTS íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € TTSë¥¼ ìƒì„±í•˜ì„¸ìš”."
            )
        
        # ê°€ì¥ ìµœê·¼ TTS íŒŒì¼ ì‚¬ìš©
        tts_files.sort(key=lambda x: x[1], reverse=True)
        combined_tts_path = tts_files[0][0]
        print(f"ğŸ™ï¸ ì‚¬ìš©í•  TTS: {os.path.basename(combined_tts_path)}")
        
        # Whisperë¡œ ìë§‰ ìƒì„±
        subtitle_result = await transcribe_audio_with_whisper(
            audio_file_path=combined_tts_path,
            language="ko",
            output_format="srt"
        )
        
        if not subtitle_result.success:
            raise HTTPException(
                status_code=500,
                detail=f"ìë§‰ ìƒì„± ì‹¤íŒ¨: {subtitle_result.error}"
            )
        
        # ìˆœì°¨ì  ìë§‰ íŒŒì¼ ìƒì„±
        sequential_subtitle_path = subtitle_result.subtitle_file_path.replace('.srt', '_custom.srt')
        subtitle_file_path = create_sequential_subtitle_file(
            subtitle_result.subtitle_file_path,
            sequential_subtitle_path,
            max_chars=15,
            line_duration=2.0,
            gap_duration=0.5,
            words_per_line=5
        )
        print(f"âœ… ìë§‰ ìƒì„± ì™„ë£Œ: {os.path.basename(subtitle_file_path)}")
        
        # ìë§‰ ìƒì„± ì™„ë£Œ í›„ txt íŒŒì¼ë“¤ê³¼ srt íŒŒì¼ë“¤ ì •ë¦¬
        print(f"ğŸ§¹ ì»¤ìŠ¤í…€ ìë§‰ ìƒì„± ì™„ë£Œ - íŒŒì¼ë“¤ ì •ë¦¬ ì¤‘...")
        txt_files_to_clean = [
            "tts_file_list.txt",
            "merged_video_list.txt",
            "transition_video_log.txt",  # íŠ¸ëœì§€ì…˜ ë¡œê·¸ë„ ì •ë¦¬
            "subtitle_file_list.txt"     # ìë§‰ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë„ ì •ë¦¬
        ]
        
        # SRT íŒŒì¼ë“¤ë„ ì •ë¦¬ (static/videos ë””ë ‰í† ë¦¬ì—ì„œ)
        video_dir = "static/videos"
        srt_files_to_clean = []
        if os.path.exists(video_dir):
            for file in os.listdir(video_dir):
                if file.endswith(".srt"):
                    srt_files_to_clean.append(os.path.join(video_dir, file))
        
        # TXT íŒŒì¼ë“¤ ì •ë¦¬
        for txt_file in txt_files_to_clean:
            if os.path.exists(txt_file):
                try:
                    with open(txt_file, 'w', encoding='utf-8') as f:
                        f.write("")  # íŒŒì¼ ë‚´ìš© ë¹„ìš°ê¸°
                    print(f"   âœ… {txt_file} ë‚´ìš© ì •ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    print(f"   âš ï¸ {txt_file} ì •ë¦¬ ì‹¤íŒ¨: {e}")
            else:
                print(f"   ğŸ“‹ {txt_file} íŒŒì¼ ì—†ìŒ (ì •ë¦¬ ë¶ˆí•„ìš”)")
        
        # SRT íŒŒì¼ë“¤ ì‚­ì œ
        for srt_file in srt_files_to_clean:
            if os.path.exists(srt_file):
                try:
                    os.remove(srt_file)
                    print(f"   âœ… {os.path.basename(srt_file)} ì‚­ì œ ì™„ë£Œ")
                except Exception as e:
                    print(f"   âš ï¸ {os.path.basename(srt_file)} ì‚­ì œ ì‹¤íŒ¨: {e}")
            else:
                print(f"   ğŸ“‹ {os.path.basename(srt_file)} íŒŒì¼ ì—†ìŒ (ì‚­ì œ ë¶ˆí•„ìš”)")
        
        # 3. ì»¤ìŠ¤í…€ ìë§‰ ìŠ¤íƒ€ì¼ ìƒì„±
        def create_custom_subtitle_style():
            # ëª¨ë“  ìœ„ì¹˜ì—ì„œ ì¤‘ì•™ ì •ë ¬ ì‚¬ìš© (Alignment=2 = í•˜ë‹¨ ì¤‘ì•™)
            alignment = 2  # í•­ìƒ ì¤‘ì•™ ì •ë ¬
            
            # ìœ„ì¹˜ë³„ ì—¬ë°± ì„¤ì • (ì •ë ¬ì€ í•­ìƒ ì¤‘ì•™)
            if position == "top":
                margin_v_val = 50  # ìƒë‹¨ ì—¬ë°±
            elif position == "middle":
                margin_v_val = 0   # ì¤‘ì•™ ì—¬ë°±
            elif position == "bottom":
                margin_v_val = 80  # í•˜ë‹¨ ì—¬ë°±
            else:  # custom - ê¸°ë³¸ê°’ ì‚¬ìš©
                margin_v_val = 80  # ê¸°ë³¸ ì—¬ë°±
            
            # ê³ ì • ì—¬ë°±ê°’ ì„¤ì •
            margin_l_val = 300
            margin_r_val = 300
            
            style_options = [
                f"FontSize={font_size}",
                f"FontName={font_name}",
                f"PrimaryColour={font_color}",
                f"Alignment={alignment}",
                f"MarginV={margin_v_val}",
                f"MarginL={margin_l_val}",
                f"MarginR={margin_r_val}",
                "WrapStyle=0",
                f"ScaleX={scale}",  # í†µí•©ëœ ìŠ¤ì¼€ì¼ ì‚¬ìš©
                f"ScaleY={scale}",  # í†µí•©ëœ ìŠ¤ì¼€ì¼ ì‚¬ìš©
                f"Bold={1 if enable_bold else 0}",  # Bold ì„¤ì •
                "PlayResX=1920",
                "PlayResY=1080",
            ]
            
            # ì•„ì›ƒë¼ì¸ í•­ìƒ ì ìš© (enable_outline ì œê±°)
            style_options.extend([
                f"OutlineColour={outline_color}",
                "BorderStyle=1",
                f"Outline={outline_width}",  # ì™¸ê³½ì„  ë‘ê»˜ ì„¤ì •
                "Shadow=0"
            ])
            
            return ",".join(style_options)
        
        # 4. ìµœì¢… ë¹„ë””ì˜¤ ìƒì„± (TTS ì˜¤ë””ì˜¤ í¬í•¨)
        output_filename = f"custom_subtitle_video_{int(time.time())}.mp4"
        output_path = os.path.join(video_dir, output_filename)
        
        # FFmpeg ê²½ë¡œ ì„¤ì •
        ffmpeg_path = "ffmpeg"
        
        # ìë§‰ íŒŒì¼ ê²½ë¡œë¥¼ Windows í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        subtitle_path_fixed = subtitle_file_path.replace("\\", "/").replace(":", "\\:")
        
        # ì»¤ìŠ¤í…€ ìë§‰ ìŠ¤íƒ€ì¼ ì ìš©
        custom_style = create_custom_subtitle_style()
        
        # TTS íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        tts_files = []
        for file in os.listdir(video_dir):
            if file.startswith("combined_tts_") and file.endswith(".mp3"):
                tts_path = os.path.join(video_dir, file)
                tts_files.append((tts_path, os.path.getmtime(tts_path)))
        
        # TTS íŒŒì¼ì´ ìˆìœ¼ë©´ ì˜¤ë””ì˜¤ì™€ í•¨ê»˜ í•©ì¹˜ê¸°
        if tts_files:
            # ê°€ì¥ ìµœê·¼ TTS íŒŒì¼ ì‚¬ìš©
            tts_files.sort(key=lambda x: x[1], reverse=True)
            combined_tts_path = tts_files[0][0]
            print(f"ğŸ™ï¸ TTS ì˜¤ë””ì˜¤ ì¶”ê°€: {os.path.basename(combined_tts_path)}")
            
            # subprocess ëª¨ë“ˆ import
            import subprocess
            
            # ë¹„ë””ì˜¤ì— ê¸°ì¡´ ì˜¤ë””ì˜¤ê°€ ìˆëŠ”ì§€ í™•ì¸
            probe_cmd = [ffmpeg_path, '-i', video_file_path, '-hide_banner', '-f', 'null', '-']
            probe_result = subprocess.run(probe_cmd, capture_output=True, text=True)
            has_audio = 'Audio:' in probe_result.stderr
            
            if has_audio:
                # ê¸°ì¡´ BGM + TTS ë¯¹ì‹±
                final_cmd = [
                    ffmpeg_path,
                    '-i', video_file_path,  # ì…ë ¥ ë¹„ë””ì˜¤ (BGM í¬í•¨)
                    '-i', combined_tts_path,  # TTS ì˜¤ë””ì˜¤
                    '-filter_complex', f"[0:v]subtitles='{subtitle_path_fixed}':force_style='{custom_style}'[v_out]; [0:a]volume=0.4[bg_audio]; [1:a]volume=5.0[tts_audio]; [bg_audio][tts_audio]amix=inputs=2:duration=longest:dropout_transition=0[aout]",
                    '-map', '[v_out]',  # ìë§‰ì´ í¬í•¨ëœ ë¹„ë””ì˜¤
                    '-map', '[aout]',   # ë¯¹ì‹±ëœ ì˜¤ë””ì˜¤ (BGM + TTS)
                    '-c:v', 'libx264',  # ë¹„ë””ì˜¤ ì½”ë±
                    '-c:a', 'aac',      # ì˜¤ë””ì˜¤ ì½”ë±
                    '-preset', 'medium',
                    '-crf', '23',
                    output_path,
                    '-y'
                ]
                print(f"ğŸµ BGM + TTS ì˜¤ë””ì˜¤ ë¯¹ì‹± ì²˜ë¦¬")
            else:
                # TTSë§Œ ì¶”ê°€
                final_cmd = [
                    ffmpeg_path,
                    '-i', video_file_path,  # ì…ë ¥ ë¹„ë””ì˜¤ (ì˜¤ë””ì˜¤ ì—†ìŒ)
                    '-i', combined_tts_path,  # TTS ì˜¤ë””ì˜¤
                    '-filter_complex', f"[0:v]subtitles='{subtitle_path_fixed}':force_style='{custom_style}'[v_out]",
                    '-map', '[v_out]',  # ìë§‰ì´ í¬í•¨ëœ ë¹„ë””ì˜¤
                    '-map', '1:a',      # TTS ì˜¤ë””ì˜¤
                    '-c:v', 'libx264',  # ë¹„ë””ì˜¤ ì½”ë±
                    '-c:a', 'aac',      # ì˜¤ë””ì˜¤ ì½”ë±
                    '-preset', 'medium',
                    '-crf', '23',
                    output_path,
                    '-y'
                ]
                print(f"ğŸ™ï¸ TTS ì˜¤ë””ì˜¤ë§Œ ì¶”ê°€")
        else:
            # TTS íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë§‰ë§Œ ì¶”ê°€ (ê¸°ì¡´ ë°©ì‹)
            final_cmd = [
                ffmpeg_path,
                '-i', video_file_path,  # ì…ë ¥ ë¹„ë””ì˜¤
                '-vf', f"subtitles='{subtitle_path_fixed}':force_style='{custom_style}'",  # ì»¤ìŠ¤í…€ ìë§‰ ì ìš©
                '-c:a', 'copy',  # ì˜¤ë””ì˜¤ ë³µì‚¬
                '-c:v', 'libx264',  # ë¹„ë””ì˜¤ ì½”ë±
                '-preset', 'medium',
                '-crf', '23',
                output_path,
                '-y'
            ]
            print(f"ğŸ“ ìë§‰ë§Œ ì¶”ê°€ (TTS íŒŒì¼ ì—†ìŒ)")
        
        print(f"ğŸ¬ ì»¤ìŠ¤í…€ ìë§‰ ì ìš© ì¤‘...")
        print(f"   í°íŠ¸: {font_name} ({font_size}px)")
        print(f"   ìŠ¤ì¼€ì¼: {scale}% x {scale}%")
        print(f"   ìœ„ì¹˜: {position}")
        print(f"   Bold: {enable_bold}")
        print(f"   ì•„ì›ƒë¼ì¸: {outline_color} (êµµê¸°: {outline_width})")
        
        import subprocess
        result = subprocess.run(final_cmd, capture_output=True, text=True, timeout=300)
        
        if result.returncode != 0:
            error_msg = f"FFmpeg ì²˜ë¦¬ ì‹¤íŒ¨:\n   ë°˜í™˜ ì½”ë“œ: {result.returncode}\n   í‘œì¤€ ì¶œë ¥: {result.stdout}\n   í‘œì¤€ ì˜¤ë¥˜: {result.stderr}"
            print(f"âŒ {error_msg}")
            raise HTTPException(status_code=500, detail="ì»¤ìŠ¤í…€ ìë§‰ ì ìš© ì‹¤íŒ¨")
        
        # ì„±ê³µ ì‘ë‹µ
        file_size = os.path.getsize(output_path)
        file_size_mb = file_size / (1024 * 1024)
        
        print(f"âœ… ì»¤ìŠ¤í…€ ìë§‰ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ íŒŒì¼: {output_filename} ({file_size_mb:.2f} MB)")
        
        # ì»¤ìŠ¤í…€ ìë§‰ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ í›„ ëª¨ë“  íŒŒì¼ë“¤ ì •ë¦¬
        print(f"ğŸ§¹ ì»¤ìŠ¤í…€ ìë§‰ ë¹„ë””ì˜¤ ì™„ë£Œ - ëª¨ë“  íŒŒì¼ë“¤ ì •ë¦¬ ì¤‘...")
        txt_files_to_clean = [
            "tts_file_list.txt",
            "merged_video_list.txt",
            "transition_video_log.txt",  # íŠ¸ëœì§€ì…˜ ë¡œê·¸ë„ ì •ë¦¬
            "subtitle_file_list.txt"     # ìë§‰ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë„ ì •ë¦¬
        ]
        
        video_dir = "static/videos"
        srt_files_to_clean = []
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ TTS ë¦¬ìŠ¤íŠ¸ íŒŒì¼ë“¤ê³¼ SRT íŒŒì¼ë“¤ë„ ì •ë¦¬
        if os.path.exists(video_dir):
            for file in os.listdir(video_dir):
                if file.startswith("tts_list_") and file.endswith(".txt"):
                    txt_files_to_clean.append(os.path.join(video_dir, file))
                elif file.endswith(".srt"):
                    srt_files_to_clean.append(os.path.join(video_dir, file))
        
        # TXT íŒŒì¼ë“¤ ì •ë¦¬
        for txt_file in txt_files_to_clean:
            if os.path.exists(txt_file):
                try:
                    with open(txt_file, 'w', encoding='utf-8') as f:
                        f.write("")  # íŒŒì¼ ë‚´ìš© ë¹„ìš°ê¸°
                    print(f"   âœ… {os.path.basename(txt_file)} ë‚´ìš© ì •ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    print(f"   âš ï¸ {os.path.basename(txt_file)} ì •ë¦¬ ì‹¤íŒ¨: {e}")
            else:
                print(f"   ğŸ“‹ {os.path.basename(txt_file)} íŒŒì¼ ì—†ìŒ (ì •ë¦¬ ë¶ˆí•„ìš”)")
        
        # SRT íŒŒì¼ë“¤ ì‚­ì œ
        for srt_file in srt_files_to_clean:
            if os.path.exists(srt_file):
                try:
                    os.remove(srt_file)
                    print(f"   âœ… {os.path.basename(srt_file)} ì‚­ì œ ì™„ë£Œ")
                except Exception as e:
                    print(f"   âš ï¸ {os.path.basename(srt_file)} ì‚­ì œ ì‹¤íŒ¨: {e}")
            else:
                print(f"   ğŸ“‹ {os.path.basename(srt_file)} íŒŒì¼ ì—†ìŒ (ì‚­ì œ ë¶ˆí•„ìš”)")
        
        return {
            "step": "ì»¤ìŠ¤í…€_ìë§‰_ì ìš©",
            "success": True,
            "message": "ì»¤ìŠ¤í…€ ìë§‰ì´ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "output_file": f"static/videos/{output_filename}",
            "video_url": f"http://localhost:8001/static/videos/{output_filename}",
            "file_size_mb": round(file_size_mb, 2),
            "subtitle_settings": {
                "font_name": font_name,
                "font_size": font_size,
                "font_color": font_color,
                "scale": scale,
                "position": position,
                "enable_bold": enable_bold,
                "outline_color": outline_color,
                "outline_width": outline_width,
                "srt_file": os.path.basename(subtitle_file_path) if subtitle_file_path else "ìë™ìƒì„±"
            }
        }
        
    except Exception as e:
        error_msg = f"ì»¤ìŠ¤í…€ ìë§‰ ì ìš© ì‹¤íŒ¨: {e}"
        print(f"âŒ {error_msg}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=error_msg)

@app.get("/bgm/status/{task_id}")
async def check_bgm_status(task_id: str):
    """
    SUNO BGM ìƒì„± ìƒíƒœ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ
    """
    try:
        print(f"ğŸ” SUNO BGM ìƒíƒœ í™•ì¸: {task_id}")
        
        if not os.getenv('SUNO_API_KEY'):
            raise HTTPException(status_code=500, detail="SUNO_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # íƒœìŠ¤í¬ ìƒíƒœ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ
        result = await check_suno_task_and_download(task_id)
        
        if result["success"]:
            return {
                "success": True,
                "status": "completed",
                "message": "BGM ìƒì„± ì™„ë£Œ ë° ë‹¤ìš´ë¡œë“œ ì„±ê³µ",
                "task_id": task_id,
                "bgm_file": result["bgm_filename"],
                "bgm_url": f"http://localhost:8001/static/audio/{result['bgm_filename']}",
                "duration": result["duration"],
                "title": result["title"],
                "tags": result["tags"],
                "file_path": result["bgm_path"]
            }
        else:
            return {
                "success": False,
                "status": result.get("status", "processing"),
                "message": result.get("message", "BGM ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."),
                "task_id": task_id,
                "retry_after": 30
            }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ BGM ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"BGM ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )

def start_video_server():
    """ë¹„ë””ì˜¤ ì„œë²„ ì‹œì‘ í•¨ìˆ˜"""
    print("ğŸš€ ë¹„ë””ì˜¤ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ì„œë²„ ì‹œì‘ ì‹œ ê¸°ì¡´ ì‘ì—… íŒŒì¼ë“¤ ì •ë¦¬
    print("ğŸ§¹ ì„œë²„ ì‹œì‘ - ê¸°ì¡´ ì‘ì—… íŒŒì¼ë“¤ ì •ë¦¬ ì¤‘...")
    cleanup_files = [
        "tts_file_list.txt",
        "merged_video_list.txt", 
        "transition_video_log.txt",
        "subtitle_file_list.txt"
    ]
    
    for cleanup_file in cleanup_files:
        if os.path.exists(cleanup_file):
            try:
                with open(cleanup_file, 'w', encoding='utf-8') as f:
                    f.write("")  # íŒŒì¼ ë‚´ìš© ë¹„ìš°ê¸°
                print(f"   âœ… {cleanup_file} ì •ë¦¬ ì™„ë£Œ")
            except Exception as e:
                print(f"   âš ï¸ {cleanup_file} ì •ë¦¬ ì‹¤íŒ¨: {e}")
        else:
            print(f"   ğŸ“‹ {cleanup_file} íŒŒì¼ ì—†ìŒ")
    
    # SRT íŒŒì¼ë“¤ë„ ì •ë¦¬
    video_dir = "static/videos"
    if os.path.exists(video_dir):
        srt_count = 0
        for file in os.listdir(video_dir):
            if file.endswith(".srt"):
                try:
                    os.remove(os.path.join(video_dir, file))
                    srt_count += 1
                except Exception as e:
                    print(f"   âš ï¸ {file} ì‚­ì œ ì‹¤íŒ¨: {e}")
        if srt_count > 0:
            print(f"   âœ… SRT íŒŒì¼ {srt_count}ê°œ ì •ë¦¬ ì™„ë£Œ")
        else:
            print(f"   ğŸ“‹ ì •ë¦¬í•  SRT íŒŒì¼ ì—†ìŒ")
    
    print("ğŸ“¡ ì„œë²„ ì •ë³´:")
    print("   - í˜¸ìŠ¤íŠ¸: 0.0.0.0")
    print("   - í¬íŠ¸: 8004")
    print("   - ëª¨ë“œ: í”„ë¡œë•ì…˜")
    print("ğŸ“± ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8004/video/status ì— ì ‘ì†í•˜ì—¬ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8004,
        reload=False,
        log_level="info"
    )

if __name__ == "__main__":
    start_video_server()
